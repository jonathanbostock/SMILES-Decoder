{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 50733,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0019711036209173515,
      "grad_norm": 2.625277519226074,
      "learning_rate": 2e-05,
      "loss": 3.8366,
      "step": 100
    },
    {
      "epoch": 0.003942207241834703,
      "grad_norm": 2.8475937843322754,
      "learning_rate": 4e-05,
      "loss": 1.8471,
      "step": 200
    },
    {
      "epoch": 0.005913310862752055,
      "grad_norm": 3.7422471046447754,
      "learning_rate": 6e-05,
      "loss": 1.4172,
      "step": 300
    },
    {
      "epoch": 0.007884414483669406,
      "grad_norm": 3.773056983947754,
      "learning_rate": 8e-05,
      "loss": 1.2108,
      "step": 400
    },
    {
      "epoch": 0.009855518104586758,
      "grad_norm": 4.448311805725098,
      "learning_rate": 0.0001,
      "loss": 1.0454,
      "step": 500
    },
    {
      "epoch": 0.01182662172550411,
      "grad_norm": 4.874833106994629,
      "learning_rate": 9.980092767702507e-05,
      "loss": 0.9128,
      "step": 600
    },
    {
      "epoch": 0.013797725346421461,
      "grad_norm": 3.7175631523132324,
      "learning_rate": 9.960185535405013e-05,
      "loss": 0.8034,
      "step": 700
    },
    {
      "epoch": 0.015768828967338812,
      "grad_norm": 4.5221123695373535,
      "learning_rate": 9.94027830310752e-05,
      "loss": 0.7127,
      "step": 800
    },
    {
      "epoch": 0.017739932588256166,
      "grad_norm": 4.162259578704834,
      "learning_rate": 9.920371070810026e-05,
      "loss": 0.6479,
      "step": 900
    },
    {
      "epoch": 0.019711036209173517,
      "grad_norm": 4.150048732757568,
      "learning_rate": 9.900463838512532e-05,
      "loss": 0.596,
      "step": 1000
    },
    {
      "epoch": 0.021682139830090867,
      "grad_norm": 4.196019172668457,
      "learning_rate": 9.880556606215037e-05,
      "loss": 0.5515,
      "step": 1100
    },
    {
      "epoch": 0.02365324345100822,
      "grad_norm": 3.1790192127227783,
      "learning_rate": 9.860649373917544e-05,
      "loss": 0.5305,
      "step": 1200
    },
    {
      "epoch": 0.025624347071925572,
      "grad_norm": 3.5443193912506104,
      "learning_rate": 9.84074214162005e-05,
      "loss": 0.4949,
      "step": 1300
    },
    {
      "epoch": 0.027595450692842922,
      "grad_norm": 3.425950765609741,
      "learning_rate": 9.820834909322556e-05,
      "loss": 0.4568,
      "step": 1400
    },
    {
      "epoch": 0.029566554313760273,
      "grad_norm": 3.98945689201355,
      "learning_rate": 9.800927677025064e-05,
      "loss": 0.4349,
      "step": 1500
    },
    {
      "epoch": 0.031537657934677624,
      "grad_norm": 4.00391149520874,
      "learning_rate": 9.78102044472757e-05,
      "loss": 0.4154,
      "step": 1600
    },
    {
      "epoch": 0.03350876155559498,
      "grad_norm": 2.869098663330078,
      "learning_rate": 9.761113212430077e-05,
      "loss": 0.3991,
      "step": 1700
    },
    {
      "epoch": 0.03547986517651233,
      "grad_norm": 3.498234510421753,
      "learning_rate": 9.741205980132583e-05,
      "loss": 0.3818,
      "step": 1800
    },
    {
      "epoch": 0.03745096879742968,
      "grad_norm": 3.272519111633301,
      "learning_rate": 9.72129874783509e-05,
      "loss": 0.3654,
      "step": 1900
    },
    {
      "epoch": 0.03942207241834703,
      "grad_norm": 3.2855751514434814,
      "learning_rate": 9.701391515537596e-05,
      "loss": 0.3466,
      "step": 2000
    },
    {
      "epoch": 0.04139317603926439,
      "grad_norm": 3.5750033855438232,
      "learning_rate": 9.681484283240102e-05,
      "loss": 0.3326,
      "step": 2100
    },
    {
      "epoch": 0.043364279660181734,
      "grad_norm": 3.3823018074035645,
      "learning_rate": 9.661577050942609e-05,
      "loss": 0.3224,
      "step": 2200
    },
    {
      "epoch": 0.04533538328109909,
      "grad_norm": 4.303157329559326,
      "learning_rate": 9.641669818645114e-05,
      "loss": 0.31,
      "step": 2300
    },
    {
      "epoch": 0.04730648690201644,
      "grad_norm": 2.4415621757507324,
      "learning_rate": 9.62176258634762e-05,
      "loss": 0.3015,
      "step": 2400
    },
    {
      "epoch": 0.04927759052293379,
      "grad_norm": 3.140583038330078,
      "learning_rate": 9.601855354050127e-05,
      "loss": 0.2909,
      "step": 2500
    },
    {
      "epoch": 0.051248694143851144,
      "grad_norm": 2.456796407699585,
      "learning_rate": 9.581948121752633e-05,
      "loss": 0.2797,
      "step": 2600
    },
    {
      "epoch": 0.05321979776476849,
      "grad_norm": 3.0014262199401855,
      "learning_rate": 9.562040889455139e-05,
      "loss": 0.2699,
      "step": 2700
    },
    {
      "epoch": 0.055190901385685845,
      "grad_norm": 3.4339046478271484,
      "learning_rate": 9.542133657157646e-05,
      "loss": 0.2621,
      "step": 2800
    },
    {
      "epoch": 0.0571620050066032,
      "grad_norm": 2.410825490951538,
      "learning_rate": 9.522226424860152e-05,
      "loss": 0.2601,
      "step": 2900
    },
    {
      "epoch": 0.059133108627520546,
      "grad_norm": 3.1925601959228516,
      "learning_rate": 9.502319192562658e-05,
      "loss": 0.2536,
      "step": 3000
    },
    {
      "epoch": 0.0611042122484379,
      "grad_norm": 2.1993682384490967,
      "learning_rate": 9.482411960265165e-05,
      "loss": 0.2416,
      "step": 3100
    },
    {
      "epoch": 0.06307531586935525,
      "grad_norm": 2.2945919036865234,
      "learning_rate": 9.462504727967671e-05,
      "loss": 0.2354,
      "step": 3200
    },
    {
      "epoch": 0.06504641949027261,
      "grad_norm": 2.739434242248535,
      "learning_rate": 9.442597495670177e-05,
      "loss": 0.2297,
      "step": 3300
    },
    {
      "epoch": 0.06701752311118996,
      "grad_norm": 2.5167171955108643,
      "learning_rate": 9.422690263372684e-05,
      "loss": 0.2206,
      "step": 3400
    },
    {
      "epoch": 0.0689886267321073,
      "grad_norm": 2.6764161586761475,
      "learning_rate": 9.40278303107519e-05,
      "loss": 0.2174,
      "step": 3500
    },
    {
      "epoch": 0.07095973035302466,
      "grad_norm": 2.67992901802063,
      "learning_rate": 9.382875798777697e-05,
      "loss": 0.2107,
      "step": 3600
    },
    {
      "epoch": 0.07293083397394201,
      "grad_norm": 2.0554146766662598,
      "learning_rate": 9.362968566480203e-05,
      "loss": 0.2095,
      "step": 3700
    },
    {
      "epoch": 0.07490193759485936,
      "grad_norm": 2.267643451690674,
      "learning_rate": 9.34306133418271e-05,
      "loss": 0.2006,
      "step": 3800
    },
    {
      "epoch": 0.07687304121577672,
      "grad_norm": 2.2475666999816895,
      "learning_rate": 9.323154101885216e-05,
      "loss": 0.201,
      "step": 3900
    },
    {
      "epoch": 0.07884414483669407,
      "grad_norm": 2.272321939468384,
      "learning_rate": 9.303246869587722e-05,
      "loss": 0.1941,
      "step": 4000
    },
    {
      "epoch": 0.08081524845761141,
      "grad_norm": 2.1718387603759766,
      "learning_rate": 9.283339637290228e-05,
      "loss": 0.1864,
      "step": 4100
    },
    {
      "epoch": 0.08278635207852877,
      "grad_norm": 2.520338296890259,
      "learning_rate": 9.263432404992735e-05,
      "loss": 0.1869,
      "step": 4200
    },
    {
      "epoch": 0.08475745569944612,
      "grad_norm": 2.371729850769043,
      "learning_rate": 9.243525172695241e-05,
      "loss": 0.1842,
      "step": 4300
    },
    {
      "epoch": 0.08672855932036347,
      "grad_norm": 2.682912588119507,
      "learning_rate": 9.223617940397748e-05,
      "loss": 0.1775,
      "step": 4400
    },
    {
      "epoch": 0.08869966294128083,
      "grad_norm": 2.007791519165039,
      "learning_rate": 9.203710708100253e-05,
      "loss": 0.1743,
      "step": 4500
    },
    {
      "epoch": 0.09067076656219818,
      "grad_norm": 2.257371664047241,
      "learning_rate": 9.183803475802759e-05,
      "loss": 0.1675,
      "step": 4600
    },
    {
      "epoch": 0.09264187018311552,
      "grad_norm": 2.1756889820098877,
      "learning_rate": 9.163896243505265e-05,
      "loss": 0.168,
      "step": 4700
    },
    {
      "epoch": 0.09461297380403288,
      "grad_norm": 2.8523049354553223,
      "learning_rate": 9.143989011207772e-05,
      "loss": 0.1629,
      "step": 4800
    },
    {
      "epoch": 0.09658407742495023,
      "grad_norm": 2.323627233505249,
      "learning_rate": 9.124081778910278e-05,
      "loss": 0.1614,
      "step": 4900
    },
    {
      "epoch": 0.09855518104586758,
      "grad_norm": 1.8234975337982178,
      "learning_rate": 9.104174546612784e-05,
      "loss": 0.1575,
      "step": 5000
    },
    {
      "epoch": 0.10052628466678493,
      "grad_norm": 2.0927727222442627,
      "learning_rate": 9.084267314315291e-05,
      "loss": 0.1529,
      "step": 5100
    },
    {
      "epoch": 0.10249738828770229,
      "grad_norm": 2.1022706031799316,
      "learning_rate": 9.064360082017797e-05,
      "loss": 0.1511,
      "step": 5200
    },
    {
      "epoch": 0.10446849190861963,
      "grad_norm": 1.815754771232605,
      "learning_rate": 9.044452849720304e-05,
      "loss": 0.1459,
      "step": 5300
    },
    {
      "epoch": 0.10643959552953698,
      "grad_norm": 2.124363899230957,
      "learning_rate": 9.02454561742281e-05,
      "loss": 0.1445,
      "step": 5400
    },
    {
      "epoch": 0.10841069915045434,
      "grad_norm": 2.1102588176727295,
      "learning_rate": 9.004638385125316e-05,
      "loss": 0.143,
      "step": 5500
    },
    {
      "epoch": 0.11038180277137169,
      "grad_norm": 1.9071934223175049,
      "learning_rate": 8.984731152827823e-05,
      "loss": 0.139,
      "step": 5600
    },
    {
      "epoch": 0.11235290639228904,
      "grad_norm": 2.172372817993164,
      "learning_rate": 8.964823920530329e-05,
      "loss": 0.1382,
      "step": 5700
    },
    {
      "epoch": 0.1143240100132064,
      "grad_norm": 2.485466241836548,
      "learning_rate": 8.944916688232835e-05,
      "loss": 0.1391,
      "step": 5800
    },
    {
      "epoch": 0.11629511363412375,
      "grad_norm": 1.9435245990753174,
      "learning_rate": 8.925009455935342e-05,
      "loss": 0.1324,
      "step": 5900
    },
    {
      "epoch": 0.11826621725504109,
      "grad_norm": 2.1500260829925537,
      "learning_rate": 8.905102223637848e-05,
      "loss": 0.1308,
      "step": 6000
    },
    {
      "epoch": 0.12023732087595845,
      "grad_norm": 2.403726816177368,
      "learning_rate": 8.885194991340354e-05,
      "loss": 0.1274,
      "step": 6100
    },
    {
      "epoch": 0.1222084244968758,
      "grad_norm": 2.019498109817505,
      "learning_rate": 8.865287759042861e-05,
      "loss": 0.1271,
      "step": 6200
    },
    {
      "epoch": 0.12417952811779315,
      "grad_norm": 2.0257697105407715,
      "learning_rate": 8.845380526745367e-05,
      "loss": 0.1238,
      "step": 6300
    },
    {
      "epoch": 0.1261506317387105,
      "grad_norm": 1.7043967247009277,
      "learning_rate": 8.825473294447874e-05,
      "loss": 0.1205,
      "step": 6400
    },
    {
      "epoch": 0.12812173535962784,
      "grad_norm": 1.9797766208648682,
      "learning_rate": 8.80556606215038e-05,
      "loss": 0.1184,
      "step": 6500
    },
    {
      "epoch": 0.13009283898054522,
      "grad_norm": 1.9474446773529053,
      "learning_rate": 8.785658829852886e-05,
      "loss": 0.1163,
      "step": 6600
    },
    {
      "epoch": 0.13206394260146256,
      "grad_norm": 1.708380103111267,
      "learning_rate": 8.765751597555393e-05,
      "loss": 0.1135,
      "step": 6700
    },
    {
      "epoch": 0.1340350462223799,
      "grad_norm": 1.673538327217102,
      "learning_rate": 8.745844365257898e-05,
      "loss": 0.1144,
      "step": 6800
    },
    {
      "epoch": 0.13600614984329726,
      "grad_norm": 1.6634092330932617,
      "learning_rate": 8.725937132960404e-05,
      "loss": 0.1101,
      "step": 6900
    },
    {
      "epoch": 0.1379772534642146,
      "grad_norm": 1.394388198852539,
      "learning_rate": 8.70602990066291e-05,
      "loss": 0.1079,
      "step": 7000
    },
    {
      "epoch": 0.13994835708513195,
      "grad_norm": 1.7308493852615356,
      "learning_rate": 8.686122668365417e-05,
      "loss": 0.1071,
      "step": 7100
    },
    {
      "epoch": 0.14191946070604933,
      "grad_norm": 2.0570461750030518,
      "learning_rate": 8.666215436067923e-05,
      "loss": 0.1072,
      "step": 7200
    },
    {
      "epoch": 0.14389056432696667,
      "grad_norm": 2.102423667907715,
      "learning_rate": 8.64630820377043e-05,
      "loss": 0.105,
      "step": 7300
    },
    {
      "epoch": 0.14586166794788402,
      "grad_norm": 1.7586302757263184,
      "learning_rate": 8.626400971472936e-05,
      "loss": 0.0995,
      "step": 7400
    },
    {
      "epoch": 0.14783277156880137,
      "grad_norm": 1.6739357709884644,
      "learning_rate": 8.606493739175442e-05,
      "loss": 0.0987,
      "step": 7500
    },
    {
      "epoch": 0.14980387518971872,
      "grad_norm": 1.860729455947876,
      "learning_rate": 8.58658650687795e-05,
      "loss": 0.0994,
      "step": 7600
    },
    {
      "epoch": 0.15177497881063606,
      "grad_norm": 1.6921483278274536,
      "learning_rate": 8.566679274580456e-05,
      "loss": 0.0997,
      "step": 7700
    },
    {
      "epoch": 0.15374608243155344,
      "grad_norm": 1.6889185905456543,
      "learning_rate": 8.546772042282963e-05,
      "loss": 0.0935,
      "step": 7800
    },
    {
      "epoch": 0.15571718605247079,
      "grad_norm": 1.4955209493637085,
      "learning_rate": 8.526864809985469e-05,
      "loss": 0.093,
      "step": 7900
    },
    {
      "epoch": 0.15768828967338813,
      "grad_norm": 1.869748830795288,
      "learning_rate": 8.506957577687974e-05,
      "loss": 0.0939,
      "step": 8000
    },
    {
      "epoch": 0.15965939329430548,
      "grad_norm": 1.9549884796142578,
      "learning_rate": 8.48705034539048e-05,
      "loss": 0.0917,
      "step": 8100
    },
    {
      "epoch": 0.16163049691522283,
      "grad_norm": 1.593195915222168,
      "learning_rate": 8.467143113092987e-05,
      "loss": 0.0887,
      "step": 8200
    },
    {
      "epoch": 0.16360160053614017,
      "grad_norm": 1.7339671850204468,
      "learning_rate": 8.447235880795493e-05,
      "loss": 0.0905,
      "step": 8300
    },
    {
      "epoch": 0.16557270415705755,
      "grad_norm": 1.4904398918151855,
      "learning_rate": 8.427328648498e-05,
      "loss": 0.089,
      "step": 8400
    },
    {
      "epoch": 0.1675438077779749,
      "grad_norm": 1.8049910068511963,
      "learning_rate": 8.407421416200506e-05,
      "loss": 0.0863,
      "step": 8500
    },
    {
      "epoch": 0.16951491139889224,
      "grad_norm": 1.553981900215149,
      "learning_rate": 8.387514183903012e-05,
      "loss": 0.0857,
      "step": 8600
    },
    {
      "epoch": 0.1714860150198096,
      "grad_norm": 1.6371713876724243,
      "learning_rate": 8.367606951605519e-05,
      "loss": 0.085,
      "step": 8700
    },
    {
      "epoch": 0.17345711864072694,
      "grad_norm": 1.8104900121688843,
      "learning_rate": 8.347699719308025e-05,
      "loss": 0.0831,
      "step": 8800
    },
    {
      "epoch": 0.17542822226164428,
      "grad_norm": 1.6710360050201416,
      "learning_rate": 8.327792487010531e-05,
      "loss": 0.0816,
      "step": 8900
    },
    {
      "epoch": 0.17739932588256166,
      "grad_norm": 1.418978214263916,
      "learning_rate": 8.307885254713038e-05,
      "loss": 0.0803,
      "step": 9000
    },
    {
      "epoch": 0.179370429503479,
      "grad_norm": 1.8135998249053955,
      "learning_rate": 8.287978022415543e-05,
      "loss": 0.0813,
      "step": 9100
    },
    {
      "epoch": 0.18134153312439635,
      "grad_norm": 1.4781619310379028,
      "learning_rate": 8.268070790118049e-05,
      "loss": 0.0782,
      "step": 9200
    },
    {
      "epoch": 0.1833126367453137,
      "grad_norm": 1.8195995092391968,
      "learning_rate": 8.248163557820556e-05,
      "loss": 0.0785,
      "step": 9300
    },
    {
      "epoch": 0.18528374036623105,
      "grad_norm": 1.4872703552246094,
      "learning_rate": 8.228256325523063e-05,
      "loss": 0.0791,
      "step": 9400
    },
    {
      "epoch": 0.1872548439871484,
      "grad_norm": 1.5911272764205933,
      "learning_rate": 8.20834909322557e-05,
      "loss": 0.0715,
      "step": 9500
    },
    {
      "epoch": 0.18922594760806577,
      "grad_norm": 1.5030591487884521,
      "learning_rate": 8.188441860928076e-05,
      "loss": 0.0777,
      "step": 9600
    },
    {
      "epoch": 0.19119705122898312,
      "grad_norm": 1.4983588457107544,
      "learning_rate": 8.168534628630582e-05,
      "loss": 0.0728,
      "step": 9700
    },
    {
      "epoch": 0.19316815484990046,
      "grad_norm": 1.8478084802627563,
      "learning_rate": 8.148627396333089e-05,
      "loss": 0.0739,
      "step": 9800
    },
    {
      "epoch": 0.1951392584708178,
      "grad_norm": 1.1888831853866577,
      "learning_rate": 8.128720164035595e-05,
      "loss": 0.0691,
      "step": 9900
    },
    {
      "epoch": 0.19711036209173516,
      "grad_norm": 1.4991182088851929,
      "learning_rate": 8.108812931738102e-05,
      "loss": 0.0717,
      "step": 10000
    },
    {
      "epoch": 0.1990814657126525,
      "grad_norm": 1.492864727973938,
      "learning_rate": 8.088905699440608e-05,
      "loss": 0.07,
      "step": 10100
    },
    {
      "epoch": 0.20105256933356985,
      "grad_norm": 1.7285507917404175,
      "learning_rate": 8.068998467143114e-05,
      "loss": 0.0668,
      "step": 10200
    },
    {
      "epoch": 0.20302367295448723,
      "grad_norm": 1.7010762691497803,
      "learning_rate": 8.04909123484562e-05,
      "loss": 0.0667,
      "step": 10300
    },
    {
      "epoch": 0.20499477657540457,
      "grad_norm": 1.225642204284668,
      "learning_rate": 8.029184002548126e-05,
      "loss": 0.0666,
      "step": 10400
    },
    {
      "epoch": 0.20696588019632192,
      "grad_norm": 1.5943633317947388,
      "learning_rate": 8.009276770250632e-05,
      "loss": 0.0642,
      "step": 10500
    },
    {
      "epoch": 0.20893698381723927,
      "grad_norm": 1.45468008518219,
      "learning_rate": 7.989369537953138e-05,
      "loss": 0.0651,
      "step": 10600
    },
    {
      "epoch": 0.21090808743815662,
      "grad_norm": 1.1266263723373413,
      "learning_rate": 7.969462305655645e-05,
      "loss": 0.0614,
      "step": 10700
    },
    {
      "epoch": 0.21287919105907396,
      "grad_norm": 1.187904715538025,
      "learning_rate": 7.949555073358151e-05,
      "loss": 0.0636,
      "step": 10800
    },
    {
      "epoch": 0.21485029467999134,
      "grad_norm": 1.058699607849121,
      "learning_rate": 7.929647841060658e-05,
      "loss": 0.0621,
      "step": 10900
    },
    {
      "epoch": 0.21682139830090869,
      "grad_norm": 1.2454622983932495,
      "learning_rate": 7.909740608763164e-05,
      "loss": 0.0642,
      "step": 11000
    },
    {
      "epoch": 0.21879250192182603,
      "grad_norm": 1.1575109958648682,
      "learning_rate": 7.88983337646567e-05,
      "loss": 0.0617,
      "step": 11100
    },
    {
      "epoch": 0.22076360554274338,
      "grad_norm": 1.380799412727356,
      "learning_rate": 7.869926144168177e-05,
      "loss": 0.0611,
      "step": 11200
    },
    {
      "epoch": 0.22273470916366073,
      "grad_norm": 1.304769515991211,
      "learning_rate": 7.850018911870683e-05,
      "loss": 0.0599,
      "step": 11300
    },
    {
      "epoch": 0.22470581278457807,
      "grad_norm": 1.484604001045227,
      "learning_rate": 7.83011167957319e-05,
      "loss": 0.0593,
      "step": 11400
    },
    {
      "epoch": 0.22667691640549545,
      "grad_norm": 0.9701250791549683,
      "learning_rate": 7.810204447275696e-05,
      "loss": 0.0573,
      "step": 11500
    },
    {
      "epoch": 0.2286480200264128,
      "grad_norm": 1.152548909187317,
      "learning_rate": 7.790297214978202e-05,
      "loss": 0.0565,
      "step": 11600
    },
    {
      "epoch": 0.23061912364733014,
      "grad_norm": 1.2413651943206787,
      "learning_rate": 7.770389982680709e-05,
      "loss": 0.0571,
      "step": 11700
    },
    {
      "epoch": 0.2325902272682475,
      "grad_norm": 1.518649697303772,
      "learning_rate": 7.750482750383215e-05,
      "loss": 0.0565,
      "step": 11800
    },
    {
      "epoch": 0.23456133088916484,
      "grad_norm": 1.0421522855758667,
      "learning_rate": 7.730575518085721e-05,
      "loss": 0.0539,
      "step": 11900
    },
    {
      "epoch": 0.23653243451008218,
      "grad_norm": 1.2200472354888916,
      "learning_rate": 7.710668285788228e-05,
      "loss": 0.0541,
      "step": 12000
    },
    {
      "epoch": 0.23850353813099956,
      "grad_norm": 1.173325538635254,
      "learning_rate": 7.690761053490734e-05,
      "loss": 0.0537,
      "step": 12100
    },
    {
      "epoch": 0.2404746417519169,
      "grad_norm": 1.455336093902588,
      "learning_rate": 7.67085382119324e-05,
      "loss": 0.0555,
      "step": 12200
    },
    {
      "epoch": 0.24244574537283425,
      "grad_norm": 1.290397047996521,
      "learning_rate": 7.650946588895747e-05,
      "loss": 0.0544,
      "step": 12300
    },
    {
      "epoch": 0.2444168489937516,
      "grad_norm": 1.3613044023513794,
      "learning_rate": 7.631039356598253e-05,
      "loss": 0.0555,
      "step": 12400
    },
    {
      "epoch": 0.24638795261466895,
      "grad_norm": 1.0895086526870728,
      "learning_rate": 7.611132124300758e-05,
      "loss": 0.0522,
      "step": 12500
    },
    {
      "epoch": 0.2483590562355863,
      "grad_norm": 1.266160249710083,
      "learning_rate": 7.591224892003264e-05,
      "loss": 0.0514,
      "step": 12600
    },
    {
      "epoch": 0.25033015985650364,
      "grad_norm": 1.2879647016525269,
      "learning_rate": 7.571317659705771e-05,
      "loss": 0.049,
      "step": 12700
    },
    {
      "epoch": 0.252301263477421,
      "grad_norm": 0.8839618563652039,
      "learning_rate": 7.551410427408277e-05,
      "loss": 0.051,
      "step": 12800
    },
    {
      "epoch": 0.25427236709833834,
      "grad_norm": 1.2790398597717285,
      "learning_rate": 7.531503195110784e-05,
      "loss": 0.0496,
      "step": 12900
    },
    {
      "epoch": 0.2562434707192557,
      "grad_norm": 0.952808141708374,
      "learning_rate": 7.51159596281329e-05,
      "loss": 0.0495,
      "step": 13000
    },
    {
      "epoch": 0.2582145743401731,
      "grad_norm": 1.293785810470581,
      "learning_rate": 7.491688730515796e-05,
      "loss": 0.0499,
      "step": 13100
    },
    {
      "epoch": 0.26018567796109043,
      "grad_norm": 0.926716685295105,
      "learning_rate": 7.471781498218303e-05,
      "loss": 0.047,
      "step": 13200
    },
    {
      "epoch": 0.2621567815820078,
      "grad_norm": 1.0579372644424438,
      "learning_rate": 7.451874265920809e-05,
      "loss": 0.0482,
      "step": 13300
    },
    {
      "epoch": 0.26412788520292513,
      "grad_norm": 1.348909854888916,
      "learning_rate": 7.431967033623315e-05,
      "loss": 0.0487,
      "step": 13400
    },
    {
      "epoch": 0.2660989888238425,
      "grad_norm": 1.2676920890808105,
      "learning_rate": 7.412059801325822e-05,
      "loss": 0.0477,
      "step": 13500
    },
    {
      "epoch": 0.2680700924447598,
      "grad_norm": 1.1364375352859497,
      "learning_rate": 7.39215256902833e-05,
      "loss": 0.0477,
      "step": 13600
    },
    {
      "epoch": 0.27004119606567717,
      "grad_norm": 1.0278290510177612,
      "learning_rate": 7.372245336730835e-05,
      "loss": 0.0471,
      "step": 13700
    },
    {
      "epoch": 0.2720122996865945,
      "grad_norm": 0.951106071472168,
      "learning_rate": 7.352338104433341e-05,
      "loss": 0.0441,
      "step": 13800
    },
    {
      "epoch": 0.27398340330751186,
      "grad_norm": 1.0428637266159058,
      "learning_rate": 7.332430872135847e-05,
      "loss": 0.0445,
      "step": 13900
    },
    {
      "epoch": 0.2759545069284292,
      "grad_norm": 1.3788909912109375,
      "learning_rate": 7.312523639838354e-05,
      "loss": 0.0454,
      "step": 14000
    },
    {
      "epoch": 0.27792561054934656,
      "grad_norm": 1.284971833229065,
      "learning_rate": 7.29261640754086e-05,
      "loss": 0.0446,
      "step": 14100
    },
    {
      "epoch": 0.2798967141702639,
      "grad_norm": 1.2992064952850342,
      "learning_rate": 7.272709175243366e-05,
      "loss": 0.0435,
      "step": 14200
    },
    {
      "epoch": 0.2818678177911813,
      "grad_norm": 1.0974807739257812,
      "learning_rate": 7.252801942945873e-05,
      "loss": 0.0422,
      "step": 14300
    },
    {
      "epoch": 0.28383892141209865,
      "grad_norm": 1.1246651411056519,
      "learning_rate": 7.232894710648379e-05,
      "loss": 0.0439,
      "step": 14400
    },
    {
      "epoch": 0.285810025033016,
      "grad_norm": 0.934268057346344,
      "learning_rate": 7.212987478350886e-05,
      "loss": 0.0424,
      "step": 14500
    },
    {
      "epoch": 0.28778112865393335,
      "grad_norm": 1.060715913772583,
      "learning_rate": 7.193080246053392e-05,
      "loss": 0.0423,
      "step": 14600
    },
    {
      "epoch": 0.2897522322748507,
      "grad_norm": 1.0625298023223877,
      "learning_rate": 7.173173013755898e-05,
      "loss": 0.0411,
      "step": 14700
    },
    {
      "epoch": 0.29172333589576804,
      "grad_norm": 1.4230554103851318,
      "learning_rate": 7.153265781458403e-05,
      "loss": 0.0396,
      "step": 14800
    },
    {
      "epoch": 0.2936944395166854,
      "grad_norm": 0.9540519714355469,
      "learning_rate": 7.13335854916091e-05,
      "loss": 0.0412,
      "step": 14900
    },
    {
      "epoch": 0.29566554313760274,
      "grad_norm": 0.8940808176994324,
      "learning_rate": 7.113451316863416e-05,
      "loss": 0.0399,
      "step": 15000
    },
    {
      "epoch": 0.2976366467585201,
      "grad_norm": 1.3822450637817383,
      "learning_rate": 7.093544084565922e-05,
      "loss": 0.0426,
      "step": 15100
    },
    {
      "epoch": 0.29960775037943743,
      "grad_norm": 1.0703463554382324,
      "learning_rate": 7.073636852268429e-05,
      "loss": 0.0387,
      "step": 15200
    },
    {
      "epoch": 0.3015788540003548,
      "grad_norm": 1.043709397315979,
      "learning_rate": 7.053729619970935e-05,
      "loss": 0.0392,
      "step": 15300
    },
    {
      "epoch": 0.3035499576212721,
      "grad_norm": 1.1158232688903809,
      "learning_rate": 7.033822387673441e-05,
      "loss": 0.0397,
      "step": 15400
    },
    {
      "epoch": 0.30552106124218953,
      "grad_norm": 1.3405815362930298,
      "learning_rate": 7.013915155375949e-05,
      "loss": 0.0392,
      "step": 15500
    },
    {
      "epoch": 0.3074921648631069,
      "grad_norm": 1.058658480644226,
      "learning_rate": 6.994007923078456e-05,
      "loss": 0.0378,
      "step": 15600
    },
    {
      "epoch": 0.3094632684840242,
      "grad_norm": 0.898497462272644,
      "learning_rate": 6.974100690780962e-05,
      "loss": 0.037,
      "step": 15700
    },
    {
      "epoch": 0.31143437210494157,
      "grad_norm": 0.730040967464447,
      "learning_rate": 6.954193458483468e-05,
      "loss": 0.038,
      "step": 15800
    },
    {
      "epoch": 0.3134054757258589,
      "grad_norm": 1.1508358716964722,
      "learning_rate": 6.934286226185975e-05,
      "loss": 0.0366,
      "step": 15900
    },
    {
      "epoch": 0.31537657934677626,
      "grad_norm": 1.1629613637924194,
      "learning_rate": 6.91437899388848e-05,
      "loss": 0.0371,
      "step": 16000
    },
    {
      "epoch": 0.3173476829676936,
      "grad_norm": 0.9851394295692444,
      "learning_rate": 6.894471761590986e-05,
      "loss": 0.0364,
      "step": 16100
    },
    {
      "epoch": 0.31931878658861096,
      "grad_norm": 1.0155011415481567,
      "learning_rate": 6.874564529293492e-05,
      "loss": 0.0371,
      "step": 16200
    },
    {
      "epoch": 0.3212898902095283,
      "grad_norm": 0.8269227743148804,
      "learning_rate": 6.854657296995999e-05,
      "loss": 0.0371,
      "step": 16300
    },
    {
      "epoch": 0.32326099383044565,
      "grad_norm": 1.259576678276062,
      "learning_rate": 6.834750064698505e-05,
      "loss": 0.0372,
      "step": 16400
    },
    {
      "epoch": 0.325232097451363,
      "grad_norm": 1.1311674118041992,
      "learning_rate": 6.814842832401012e-05,
      "loss": 0.0354,
      "step": 16500
    },
    {
      "epoch": 0.32720320107228035,
      "grad_norm": 1.2145426273345947,
      "learning_rate": 6.794935600103518e-05,
      "loss": 0.0355,
      "step": 16600
    },
    {
      "epoch": 0.3291743046931977,
      "grad_norm": 0.7615876793861389,
      "learning_rate": 6.775028367806024e-05,
      "loss": 0.0339,
      "step": 16700
    },
    {
      "epoch": 0.3311454083141151,
      "grad_norm": 0.8438616991043091,
      "learning_rate": 6.75512113550853e-05,
      "loss": 0.0355,
      "step": 16800
    },
    {
      "epoch": 0.33311651193503244,
      "grad_norm": 0.8058490753173828,
      "learning_rate": 6.735213903211037e-05,
      "loss": 0.0341,
      "step": 16900
    },
    {
      "epoch": 0.3350876155559498,
      "grad_norm": 0.9082444310188293,
      "learning_rate": 6.715306670913543e-05,
      "loss": 0.0335,
      "step": 17000
    },
    {
      "epoch": 0.33705871917686714,
      "grad_norm": 1.2233200073242188,
      "learning_rate": 6.695399438616048e-05,
      "loss": 0.033,
      "step": 17100
    },
    {
      "epoch": 0.3390298227977845,
      "grad_norm": 0.8431209325790405,
      "learning_rate": 6.675492206318555e-05,
      "loss": 0.034,
      "step": 17200
    },
    {
      "epoch": 0.34100092641870183,
      "grad_norm": 1.0800058841705322,
      "learning_rate": 6.655584974021063e-05,
      "loss": 0.0321,
      "step": 17300
    },
    {
      "epoch": 0.3429720300396192,
      "grad_norm": 1.0353339910507202,
      "learning_rate": 6.635677741723569e-05,
      "loss": 0.0329,
      "step": 17400
    },
    {
      "epoch": 0.3449431336605365,
      "grad_norm": 1.0130140781402588,
      "learning_rate": 6.615770509426075e-05,
      "loss": 0.033,
      "step": 17500
    },
    {
      "epoch": 0.3469142372814539,
      "grad_norm": 1.0624053478240967,
      "learning_rate": 6.595863277128582e-05,
      "loss": 0.0322,
      "step": 17600
    },
    {
      "epoch": 0.3488853409023712,
      "grad_norm": 0.9140854477882385,
      "learning_rate": 6.575956044831088e-05,
      "loss": 0.0323,
      "step": 17700
    },
    {
      "epoch": 0.35085644452328857,
      "grad_norm": 1.0891906023025513,
      "learning_rate": 6.556048812533594e-05,
      "loss": 0.0311,
      "step": 17800
    },
    {
      "epoch": 0.3528275481442059,
      "grad_norm": 1.192800760269165,
      "learning_rate": 6.536141580236101e-05,
      "loss": 0.0311,
      "step": 17900
    },
    {
      "epoch": 0.3547986517651233,
      "grad_norm": 1.1047089099884033,
      "learning_rate": 6.516234347938607e-05,
      "loss": 0.0307,
      "step": 18000
    },
    {
      "epoch": 0.35676975538604067,
      "grad_norm": 0.926033616065979,
      "learning_rate": 6.496327115641113e-05,
      "loss": 0.0313,
      "step": 18100
    },
    {
      "epoch": 0.358740859006958,
      "grad_norm": 1.0758742094039917,
      "learning_rate": 6.47641988334362e-05,
      "loss": 0.0314,
      "step": 18200
    },
    {
      "epoch": 0.36071196262787536,
      "grad_norm": 0.9968209862709045,
      "learning_rate": 6.456512651046125e-05,
      "loss": 0.0311,
      "step": 18300
    },
    {
      "epoch": 0.3626830662487927,
      "grad_norm": 0.7428715229034424,
      "learning_rate": 6.436605418748631e-05,
      "loss": 0.0296,
      "step": 18400
    },
    {
      "epoch": 0.36465416986971005,
      "grad_norm": 0.8981406092643738,
      "learning_rate": 6.416698186451138e-05,
      "loss": 0.0292,
      "step": 18500
    },
    {
      "epoch": 0.3666252734906274,
      "grad_norm": 0.8331553936004639,
      "learning_rate": 6.396790954153644e-05,
      "loss": 0.0293,
      "step": 18600
    },
    {
      "epoch": 0.36859637711154475,
      "grad_norm": 1.062840223312378,
      "learning_rate": 6.37688372185615e-05,
      "loss": 0.0286,
      "step": 18700
    },
    {
      "epoch": 0.3705674807324621,
      "grad_norm": 0.819762647151947,
      "learning_rate": 6.356976489558657e-05,
      "loss": 0.0269,
      "step": 18800
    },
    {
      "epoch": 0.37253858435337944,
      "grad_norm": 0.8472849726676941,
      "learning_rate": 6.337069257261163e-05,
      "loss": 0.0298,
      "step": 18900
    },
    {
      "epoch": 0.3745096879742968,
      "grad_norm": 1.2753115892410278,
      "learning_rate": 6.31716202496367e-05,
      "loss": 0.0287,
      "step": 19000
    },
    {
      "epoch": 0.37648079159521414,
      "grad_norm": 0.9526528716087341,
      "learning_rate": 6.297254792666176e-05,
      "loss": 0.0265,
      "step": 19100
    },
    {
      "epoch": 0.37845189521613154,
      "grad_norm": 0.9197461009025574,
      "learning_rate": 6.277347560368682e-05,
      "loss": 0.0274,
      "step": 19200
    },
    {
      "epoch": 0.3804229988370489,
      "grad_norm": 0.709815502166748,
      "learning_rate": 6.257440328071189e-05,
      "loss": 0.0285,
      "step": 19300
    },
    {
      "epoch": 0.38239410245796623,
      "grad_norm": 1.420017123222351,
      "learning_rate": 6.237533095773695e-05,
      "loss": 0.0279,
      "step": 19400
    },
    {
      "epoch": 0.3843652060788836,
      "grad_norm": 0.8194944858551025,
      "learning_rate": 6.217625863476201e-05,
      "loss": 0.0287,
      "step": 19500
    },
    {
      "epoch": 0.38633630969980093,
      "grad_norm": 1.0046391487121582,
      "learning_rate": 6.197718631178708e-05,
      "loss": 0.0275,
      "step": 19600
    },
    {
      "epoch": 0.3883074133207183,
      "grad_norm": 0.7633756995201111,
      "learning_rate": 6.177811398881214e-05,
      "loss": 0.0258,
      "step": 19700
    },
    {
      "epoch": 0.3902785169416356,
      "grad_norm": 0.6234754323959351,
      "learning_rate": 6.15790416658372e-05,
      "loss": 0.0266,
      "step": 19800
    },
    {
      "epoch": 0.39224962056255297,
      "grad_norm": 0.7981220483779907,
      "learning_rate": 6.137996934286227e-05,
      "loss": 0.0263,
      "step": 19900
    },
    {
      "epoch": 0.3942207241834703,
      "grad_norm": 0.8390591144561768,
      "learning_rate": 6.118089701988733e-05,
      "loss": 0.0265,
      "step": 20000
    },
    {
      "epoch": 0.39619182780438766,
      "grad_norm": 0.6919937133789062,
      "learning_rate": 6.0981824696912395e-05,
      "loss": 0.0264,
      "step": 20100
    },
    {
      "epoch": 0.398162931425305,
      "grad_norm": 0.8419435024261475,
      "learning_rate": 6.078275237393746e-05,
      "loss": 0.0243,
      "step": 20200
    },
    {
      "epoch": 0.40013403504622236,
      "grad_norm": 0.8222573399543762,
      "learning_rate": 6.058368005096252e-05,
      "loss": 0.0259,
      "step": 20300
    },
    {
      "epoch": 0.4021051386671397,
      "grad_norm": 0.776374340057373,
      "learning_rate": 6.0384607727987586e-05,
      "loss": 0.0265,
      "step": 20400
    },
    {
      "epoch": 0.4040762422880571,
      "grad_norm": 0.8050774335861206,
      "learning_rate": 6.0185535405012636e-05,
      "loss": 0.0246,
      "step": 20500
    },
    {
      "epoch": 0.40604734590897446,
      "grad_norm": 0.8897095918655396,
      "learning_rate": 5.99864630820377e-05,
      "loss": 0.0258,
      "step": 20600
    },
    {
      "epoch": 0.4080184495298918,
      "grad_norm": 0.9533419609069824,
      "learning_rate": 5.9787390759062764e-05,
      "loss": 0.0256,
      "step": 20700
    },
    {
      "epoch": 0.40998955315080915,
      "grad_norm": 0.5673797130584717,
      "learning_rate": 5.9588318436087834e-05,
      "loss": 0.0254,
      "step": 20800
    },
    {
      "epoch": 0.4119606567717265,
      "grad_norm": 0.6422973275184631,
      "learning_rate": 5.93892461131129e-05,
      "loss": 0.0248,
      "step": 20900
    },
    {
      "epoch": 0.41393176039264384,
      "grad_norm": 0.9412580728530884,
      "learning_rate": 5.919017379013796e-05,
      "loss": 0.0242,
      "step": 21000
    },
    {
      "epoch": 0.4159028640135612,
      "grad_norm": 0.8809589743614197,
      "learning_rate": 5.8991101467163025e-05,
      "loss": 0.0242,
      "step": 21100
    },
    {
      "epoch": 0.41787396763447854,
      "grad_norm": 0.7707716226577759,
      "learning_rate": 5.879202914418809e-05,
      "loss": 0.0238,
      "step": 21200
    },
    {
      "epoch": 0.4198450712553959,
      "grad_norm": 0.8034794926643372,
      "learning_rate": 5.859295682121315e-05,
      "loss": 0.0262,
      "step": 21300
    },
    {
      "epoch": 0.42181617487631323,
      "grad_norm": 0.7609057426452637,
      "learning_rate": 5.8393884498238217e-05,
      "loss": 0.0241,
      "step": 21400
    },
    {
      "epoch": 0.4237872784972306,
      "grad_norm": 0.8613146543502808,
      "learning_rate": 5.819481217526328e-05,
      "loss": 0.023,
      "step": 21500
    },
    {
      "epoch": 0.4257583821181479,
      "grad_norm": 0.8379291296005249,
      "learning_rate": 5.7995739852288344e-05,
      "loss": 0.0236,
      "step": 21600
    },
    {
      "epoch": 0.42772948573906533,
      "grad_norm": 1.0074833631515503,
      "learning_rate": 5.7796667529313394e-05,
      "loss": 0.0241,
      "step": 21700
    },
    {
      "epoch": 0.4297005893599827,
      "grad_norm": 0.9039194583892822,
      "learning_rate": 5.7597595206338465e-05,
      "loss": 0.0242,
      "step": 21800
    },
    {
      "epoch": 0.4316716929809,
      "grad_norm": 0.9433488845825195,
      "learning_rate": 5.739852288336353e-05,
      "loss": 0.0233,
      "step": 21900
    },
    {
      "epoch": 0.43364279660181737,
      "grad_norm": 1.238135576248169,
      "learning_rate": 5.719945056038859e-05,
      "loss": 0.0239,
      "step": 22000
    },
    {
      "epoch": 0.4356139002227347,
      "grad_norm": 1.2230416536331177,
      "learning_rate": 5.7000378237413656e-05,
      "loss": 0.0228,
      "step": 22100
    },
    {
      "epoch": 0.43758500384365207,
      "grad_norm": 0.7781995534896851,
      "learning_rate": 5.680130591443872e-05,
      "loss": 0.024,
      "step": 22200
    },
    {
      "epoch": 0.4395561074645694,
      "grad_norm": 1.1151231527328491,
      "learning_rate": 5.660223359146378e-05,
      "loss": 0.0225,
      "step": 22300
    },
    {
      "epoch": 0.44152721108548676,
      "grad_norm": 0.7896223664283752,
      "learning_rate": 5.640316126848885e-05,
      "loss": 0.0231,
      "step": 22400
    },
    {
      "epoch": 0.4434983147064041,
      "grad_norm": 0.6530675888061523,
      "learning_rate": 5.620408894551391e-05,
      "loss": 0.0224,
      "step": 22500
    },
    {
      "epoch": 0.44546941832732145,
      "grad_norm": 0.9742702841758728,
      "learning_rate": 5.6005016622538974e-05,
      "loss": 0.0227,
      "step": 22600
    },
    {
      "epoch": 0.4474405219482388,
      "grad_norm": 0.8509795069694519,
      "learning_rate": 5.580594429956404e-05,
      "loss": 0.0212,
      "step": 22700
    },
    {
      "epoch": 0.44941162556915615,
      "grad_norm": 0.9100814461708069,
      "learning_rate": 5.5606871976589095e-05,
      "loss": 0.0217,
      "step": 22800
    },
    {
      "epoch": 0.4513827291900735,
      "grad_norm": 0.722958505153656,
      "learning_rate": 5.540779965361416e-05,
      "loss": 0.0193,
      "step": 22900
    },
    {
      "epoch": 0.4533538328109909,
      "grad_norm": 0.9578716158866882,
      "learning_rate": 5.520872733063922e-05,
      "loss": 0.0222,
      "step": 23000
    },
    {
      "epoch": 0.45532493643190824,
      "grad_norm": 0.6902281045913696,
      "learning_rate": 5.5009655007664286e-05,
      "loss": 0.0213,
      "step": 23100
    },
    {
      "epoch": 0.4572960400528256,
      "grad_norm": 0.7917824983596802,
      "learning_rate": 5.481058268468935e-05,
      "loss": 0.021,
      "step": 23200
    },
    {
      "epoch": 0.45926714367374294,
      "grad_norm": 0.6653760075569153,
      "learning_rate": 5.461151036171441e-05,
      "loss": 0.0199,
      "step": 23300
    },
    {
      "epoch": 0.4612382472946603,
      "grad_norm": 0.9174280166625977,
      "learning_rate": 5.441243803873948e-05,
      "loss": 0.0219,
      "step": 23400
    },
    {
      "epoch": 0.46320935091557763,
      "grad_norm": 0.6958463191986084,
      "learning_rate": 5.421336571576454e-05,
      "loss": 0.0209,
      "step": 23500
    },
    {
      "epoch": 0.465180454536495,
      "grad_norm": 0.8302499651908875,
      "learning_rate": 5.4014293392789604e-05,
      "loss": 0.021,
      "step": 23600
    },
    {
      "epoch": 0.4671515581574123,
      "grad_norm": 0.968914270401001,
      "learning_rate": 5.381522106981467e-05,
      "loss": 0.0211,
      "step": 23700
    },
    {
      "epoch": 0.4691226617783297,
      "grad_norm": 0.6491387486457825,
      "learning_rate": 5.361614874683973e-05,
      "loss": 0.0195,
      "step": 23800
    },
    {
      "epoch": 0.471093765399247,
      "grad_norm": 1.0714352130889893,
      "learning_rate": 5.3417076423864795e-05,
      "loss": 0.0199,
      "step": 23900
    },
    {
      "epoch": 0.47306486902016437,
      "grad_norm": 0.5300260782241821,
      "learning_rate": 5.321800410088985e-05,
      "loss": 0.0209,
      "step": 24000
    },
    {
      "epoch": 0.4750359726410817,
      "grad_norm": 0.6413021087646484,
      "learning_rate": 5.3018931777914916e-05,
      "loss": 0.0193,
      "step": 24100
    },
    {
      "epoch": 0.4770070762619991,
      "grad_norm": 0.5903540253639221,
      "learning_rate": 5.281985945493998e-05,
      "loss": 0.0201,
      "step": 24200
    },
    {
      "epoch": 0.47897817988291647,
      "grad_norm": 0.8939948678016663,
      "learning_rate": 5.2620787131965044e-05,
      "loss": 0.0188,
      "step": 24300
    },
    {
      "epoch": 0.4809492835038338,
      "grad_norm": 0.6393290162086487,
      "learning_rate": 5.242171480899011e-05,
      "loss": 0.0189,
      "step": 24400
    },
    {
      "epoch": 0.48292038712475116,
      "grad_norm": 0.8391173481941223,
      "learning_rate": 5.222264248601517e-05,
      "loss": 0.0194,
      "step": 24500
    },
    {
      "epoch": 0.4848914907456685,
      "grad_norm": 0.8220553994178772,
      "learning_rate": 5.2023570163040235e-05,
      "loss": 0.0211,
      "step": 24600
    },
    {
      "epoch": 0.48686259436658585,
      "grad_norm": 0.47118330001831055,
      "learning_rate": 5.18244978400653e-05,
      "loss": 0.0184,
      "step": 24700
    },
    {
      "epoch": 0.4888336979875032,
      "grad_norm": 0.6489331722259521,
      "learning_rate": 5.162542551709036e-05,
      "loss": 0.018,
      "step": 24800
    },
    {
      "epoch": 0.49080480160842055,
      "grad_norm": 0.7434731721878052,
      "learning_rate": 5.1426353194115426e-05,
      "loss": 0.018,
      "step": 24900
    },
    {
      "epoch": 0.4927759052293379,
      "grad_norm": 0.5782163143157959,
      "learning_rate": 5.122728087114049e-05,
      "loss": 0.0196,
      "step": 25000
    },
    {
      "epoch": 0.49474700885025524,
      "grad_norm": 0.42499858140945435,
      "learning_rate": 5.1028208548165546e-05,
      "loss": 0.019,
      "step": 25100
    },
    {
      "epoch": 0.4967181124711726,
      "grad_norm": 0.9503417015075684,
      "learning_rate": 5.082913622519061e-05,
      "loss": 0.019,
      "step": 25200
    },
    {
      "epoch": 0.49868921609208994,
      "grad_norm": 0.8491771221160889,
      "learning_rate": 5.0630063902215674e-05,
      "loss": 0.0189,
      "step": 25300
    },
    {
      "epoch": 0.5006603197130073,
      "grad_norm": 0.8965249061584473,
      "learning_rate": 5.043099157924074e-05,
      "loss": 0.02,
      "step": 25400
    },
    {
      "epoch": 0.5026314233339246,
      "grad_norm": 0.5539340972900391,
      "learning_rate": 5.02319192562658e-05,
      "loss": 0.0172,
      "step": 25500
    },
    {
      "epoch": 0.504602526954842,
      "grad_norm": 0.5383449196815491,
      "learning_rate": 5.0032846933290865e-05,
      "loss": 0.0187,
      "step": 25600
    },
    {
      "epoch": 0.5065736305757593,
      "grad_norm": 0.8429891467094421,
      "learning_rate": 4.983377461031593e-05,
      "loss": 0.0174,
      "step": 25700
    },
    {
      "epoch": 0.5085447341966767,
      "grad_norm": 0.939052164554596,
      "learning_rate": 4.963470228734099e-05,
      "loss": 0.0162,
      "step": 25800
    },
    {
      "epoch": 0.510515837817594,
      "grad_norm": 1.1554930210113525,
      "learning_rate": 4.9435629964366056e-05,
      "loss": 0.0168,
      "step": 25900
    },
    {
      "epoch": 0.5124869414385114,
      "grad_norm": 0.6523683071136475,
      "learning_rate": 4.923655764139112e-05,
      "loss": 0.0175,
      "step": 26000
    },
    {
      "epoch": 0.5144580450594288,
      "grad_norm": 0.7464798092842102,
      "learning_rate": 4.903748531841618e-05,
      "loss": 0.0183,
      "step": 26100
    },
    {
      "epoch": 0.5164291486803462,
      "grad_norm": 0.7373915910720825,
      "learning_rate": 4.883841299544125e-05,
      "loss": 0.017,
      "step": 26200
    },
    {
      "epoch": 0.5184002523012635,
      "grad_norm": 0.5908367037773132,
      "learning_rate": 4.863934067246631e-05,
      "loss": 0.0178,
      "step": 26300
    },
    {
      "epoch": 0.5203713559221809,
      "grad_norm": 0.7525177001953125,
      "learning_rate": 4.8440268349491374e-05,
      "loss": 0.0169,
      "step": 26400
    },
    {
      "epoch": 0.5223424595430982,
      "grad_norm": 0.6224594712257385,
      "learning_rate": 4.824119602651643e-05,
      "loss": 0.018,
      "step": 26500
    },
    {
      "epoch": 0.5243135631640156,
      "grad_norm": 0.6848386526107788,
      "learning_rate": 4.8042123703541495e-05,
      "loss": 0.0167,
      "step": 26600
    },
    {
      "epoch": 0.5262846667849329,
      "grad_norm": 0.6229647397994995,
      "learning_rate": 4.784305138056656e-05,
      "loss": 0.0173,
      "step": 26700
    },
    {
      "epoch": 0.5282557704058503,
      "grad_norm": 0.797902524471283,
      "learning_rate": 4.764397905759162e-05,
      "loss": 0.0181,
      "step": 26800
    },
    {
      "epoch": 0.5302268740267676,
      "grad_norm": 0.7178263664245605,
      "learning_rate": 4.744490673461669e-05,
      "loss": 0.0168,
      "step": 26900
    },
    {
      "epoch": 0.532197977647685,
      "grad_norm": 0.6917869448661804,
      "learning_rate": 4.724583441164176e-05,
      "loss": 0.0168,
      "step": 27000
    },
    {
      "epoch": 0.5341690812686023,
      "grad_norm": 0.8125323057174683,
      "learning_rate": 4.7046762088666814e-05,
      "loss": 0.0168,
      "step": 27100
    },
    {
      "epoch": 0.5361401848895196,
      "grad_norm": 0.5364603400230408,
      "learning_rate": 4.684768976569188e-05,
      "loss": 0.0154,
      "step": 27200
    },
    {
      "epoch": 0.538111288510437,
      "grad_norm": 0.4727591276168823,
      "learning_rate": 4.664861744271694e-05,
      "loss": 0.0148,
      "step": 27300
    },
    {
      "epoch": 0.5400823921313543,
      "grad_norm": 0.8832816481590271,
      "learning_rate": 4.6449545119742005e-05,
      "loss": 0.0165,
      "step": 27400
    },
    {
      "epoch": 0.5420534957522717,
      "grad_norm": 0.8324757218360901,
      "learning_rate": 4.625047279676707e-05,
      "loss": 0.0162,
      "step": 27500
    },
    {
      "epoch": 0.544024599373189,
      "grad_norm": 0.7845913767814636,
      "learning_rate": 4.605140047379213e-05,
      "loss": 0.0167,
      "step": 27600
    },
    {
      "epoch": 0.5459957029941064,
      "grad_norm": 0.6308680176734924,
      "learning_rate": 4.585232815081719e-05,
      "loss": 0.0153,
      "step": 27700
    },
    {
      "epoch": 0.5479668066150237,
      "grad_norm": 0.7791963815689087,
      "learning_rate": 4.565325582784226e-05,
      "loss": 0.0151,
      "step": 27800
    },
    {
      "epoch": 0.5499379102359411,
      "grad_norm": 0.8695945739746094,
      "learning_rate": 4.545418350486732e-05,
      "loss": 0.0151,
      "step": 27900
    },
    {
      "epoch": 0.5519090138568584,
      "grad_norm": 0.6503579020500183,
      "learning_rate": 4.525511118189239e-05,
      "loss": 0.0158,
      "step": 28000
    },
    {
      "epoch": 0.5538801174777758,
      "grad_norm": 0.7206874489784241,
      "learning_rate": 4.505603885891745e-05,
      "loss": 0.0154,
      "step": 28100
    },
    {
      "epoch": 0.5558512210986931,
      "grad_norm": 0.6374432444572449,
      "learning_rate": 4.485696653594251e-05,
      "loss": 0.0155,
      "step": 28200
    },
    {
      "epoch": 0.5578223247196105,
      "grad_norm": 0.5474498271942139,
      "learning_rate": 4.465789421296757e-05,
      "loss": 0.0151,
      "step": 28300
    },
    {
      "epoch": 0.5597934283405278,
      "grad_norm": 0.5709995031356812,
      "learning_rate": 4.4458821889992635e-05,
      "loss": 0.015,
      "step": 28400
    },
    {
      "epoch": 0.5617645319614453,
      "grad_norm": 0.6170607209205627,
      "learning_rate": 4.42597495670177e-05,
      "loss": 0.0154,
      "step": 28500
    },
    {
      "epoch": 0.5637356355823626,
      "grad_norm": 0.6680149435997009,
      "learning_rate": 4.406067724404276e-05,
      "loss": 0.014,
      "step": 28600
    },
    {
      "epoch": 0.56570673920328,
      "grad_norm": 0.7590358257293701,
      "learning_rate": 4.3861604921067826e-05,
      "loss": 0.0153,
      "step": 28700
    },
    {
      "epoch": 0.5676778428241973,
      "grad_norm": 0.5877653360366821,
      "learning_rate": 4.366253259809289e-05,
      "loss": 0.0145,
      "step": 28800
    },
    {
      "epoch": 0.5696489464451147,
      "grad_norm": 0.8063430190086365,
      "learning_rate": 4.3463460275117953e-05,
      "loss": 0.015,
      "step": 28900
    },
    {
      "epoch": 0.571620050066032,
      "grad_norm": 0.4075806736946106,
      "learning_rate": 4.326438795214302e-05,
      "loss": 0.0132,
      "step": 29000
    },
    {
      "epoch": 0.5735911536869494,
      "grad_norm": 0.8968912363052368,
      "learning_rate": 4.306531562916808e-05,
      "loss": 0.015,
      "step": 29100
    },
    {
      "epoch": 0.5755622573078667,
      "grad_norm": 0.6805321574211121,
      "learning_rate": 4.2866243306193145e-05,
      "loss": 0.015,
      "step": 29200
    },
    {
      "epoch": 0.577533360928784,
      "grad_norm": 0.5523994565010071,
      "learning_rate": 4.266717098321821e-05,
      "loss": 0.0136,
      "step": 29300
    },
    {
      "epoch": 0.5795044645497014,
      "grad_norm": 0.7092915177345276,
      "learning_rate": 4.2468098660243265e-05,
      "loss": 0.0144,
      "step": 29400
    },
    {
      "epoch": 0.5814755681706187,
      "grad_norm": 0.3812475800514221,
      "learning_rate": 4.226902633726833e-05,
      "loss": 0.0126,
      "step": 29500
    },
    {
      "epoch": 0.5834466717915361,
      "grad_norm": 0.6348169445991516,
      "learning_rate": 4.206995401429339e-05,
      "loss": 0.0135,
      "step": 29600
    },
    {
      "epoch": 0.5854177754124534,
      "grad_norm": 0.5976532697677612,
      "learning_rate": 4.1870881691318456e-05,
      "loss": 0.0131,
      "step": 29700
    },
    {
      "epoch": 0.5873888790333708,
      "grad_norm": 0.6064245700836182,
      "learning_rate": 4.167180936834352e-05,
      "loss": 0.0142,
      "step": 29800
    },
    {
      "epoch": 0.5893599826542881,
      "grad_norm": 0.5716219544410706,
      "learning_rate": 4.147273704536859e-05,
      "loss": 0.0138,
      "step": 29900
    },
    {
      "epoch": 0.5913310862752055,
      "grad_norm": 0.5170717835426331,
      "learning_rate": 4.127366472239365e-05,
      "loss": 0.0127,
      "step": 30000
    },
    {
      "epoch": 0.5933021898961228,
      "grad_norm": 0.7615527510643005,
      "learning_rate": 4.107459239941871e-05,
      "loss": 0.0132,
      "step": 30100
    },
    {
      "epoch": 0.5952732935170402,
      "grad_norm": 0.7307315468788147,
      "learning_rate": 4.0875520076443775e-05,
      "loss": 0.0136,
      "step": 30200
    },
    {
      "epoch": 0.5972443971379575,
      "grad_norm": 0.612136960029602,
      "learning_rate": 4.067644775346884e-05,
      "loss": 0.0136,
      "step": 30300
    },
    {
      "epoch": 0.5992155007588749,
      "grad_norm": 0.5918120741844177,
      "learning_rate": 4.04773754304939e-05,
      "loss": 0.0129,
      "step": 30400
    },
    {
      "epoch": 0.6011866043797922,
      "grad_norm": 0.5673016905784607,
      "learning_rate": 4.027830310751896e-05,
      "loss": 0.0134,
      "step": 30500
    },
    {
      "epoch": 0.6031577080007096,
      "grad_norm": 0.8426414728164673,
      "learning_rate": 4.007923078454402e-05,
      "loss": 0.0134,
      "step": 30600
    },
    {
      "epoch": 0.6051288116216269,
      "grad_norm": 0.8123584985733032,
      "learning_rate": 3.9880158461569086e-05,
      "loss": 0.0125,
      "step": 30700
    },
    {
      "epoch": 0.6070999152425443,
      "grad_norm": 0.7006092667579651,
      "learning_rate": 3.968108613859415e-05,
      "loss": 0.0112,
      "step": 30800
    },
    {
      "epoch": 0.6090710188634616,
      "grad_norm": 0.6507211923599243,
      "learning_rate": 3.948201381561922e-05,
      "loss": 0.0131,
      "step": 30900
    },
    {
      "epoch": 0.6110421224843791,
      "grad_norm": 0.6673712134361267,
      "learning_rate": 3.9282941492644284e-05,
      "loss": 0.0133,
      "step": 31000
    },
    {
      "epoch": 0.6130132261052964,
      "grad_norm": 0.5936357378959656,
      "learning_rate": 3.908386916966934e-05,
      "loss": 0.0127,
      "step": 31100
    },
    {
      "epoch": 0.6149843297262138,
      "grad_norm": 0.883648157119751,
      "learning_rate": 3.8884796846694405e-05,
      "loss": 0.012,
      "step": 31200
    },
    {
      "epoch": 0.6169554333471311,
      "grad_norm": 0.6667454242706299,
      "learning_rate": 3.868572452371947e-05,
      "loss": 0.0125,
      "step": 31300
    },
    {
      "epoch": 0.6189265369680484,
      "grad_norm": 0.8433942198753357,
      "learning_rate": 3.848665220074453e-05,
      "loss": 0.0116,
      "step": 31400
    },
    {
      "epoch": 0.6208976405889658,
      "grad_norm": 0.4958101809024811,
      "learning_rate": 3.8287579877769596e-05,
      "loss": 0.0119,
      "step": 31500
    },
    {
      "epoch": 0.6228687442098831,
      "grad_norm": 0.8058832883834839,
      "learning_rate": 3.808850755479466e-05,
      "loss": 0.012,
      "step": 31600
    },
    {
      "epoch": 0.6248398478308005,
      "grad_norm": 0.6274645328521729,
      "learning_rate": 3.788943523181972e-05,
      "loss": 0.0117,
      "step": 31700
    },
    {
      "epoch": 0.6268109514517178,
      "grad_norm": 0.49845951795578003,
      "learning_rate": 3.769036290884479e-05,
      "loss": 0.0128,
      "step": 31800
    },
    {
      "epoch": 0.6287820550726352,
      "grad_norm": 0.7345939874649048,
      "learning_rate": 3.749129058586985e-05,
      "loss": 0.0128,
      "step": 31900
    },
    {
      "epoch": 0.6307531586935525,
      "grad_norm": 0.49802929162979126,
      "learning_rate": 3.7292218262894915e-05,
      "loss": 0.0116,
      "step": 32000
    },
    {
      "epoch": 0.6327242623144699,
      "grad_norm": 0.7203750610351562,
      "learning_rate": 3.709314593991998e-05,
      "loss": 0.012,
      "step": 32100
    },
    {
      "epoch": 0.6346953659353872,
      "grad_norm": 0.5738934278488159,
      "learning_rate": 3.6894073616945035e-05,
      "loss": 0.0128,
      "step": 32200
    },
    {
      "epoch": 0.6366664695563046,
      "grad_norm": 0.474212110042572,
      "learning_rate": 3.66950012939701e-05,
      "loss": 0.0113,
      "step": 32300
    },
    {
      "epoch": 0.6386375731772219,
      "grad_norm": 0.4351188838481903,
      "learning_rate": 3.649592897099516e-05,
      "loss": 0.0121,
      "step": 32400
    },
    {
      "epoch": 0.6406086767981393,
      "grad_norm": 0.49185776710510254,
      "learning_rate": 3.6296856648020226e-05,
      "loss": 0.0125,
      "step": 32500
    },
    {
      "epoch": 0.6425797804190566,
      "grad_norm": 0.38815999031066895,
      "learning_rate": 3.609778432504529e-05,
      "loss": 0.0122,
      "step": 32600
    },
    {
      "epoch": 0.644550884039974,
      "grad_norm": 0.5527774095535278,
      "learning_rate": 3.5898712002070354e-05,
      "loss": 0.0109,
      "step": 32700
    },
    {
      "epoch": 0.6465219876608913,
      "grad_norm": 0.5728583335876465,
      "learning_rate": 3.569963967909542e-05,
      "loss": 0.0111,
      "step": 32800
    },
    {
      "epoch": 0.6484930912818087,
      "grad_norm": 0.6195473670959473,
      "learning_rate": 3.550056735612048e-05,
      "loss": 0.0117,
      "step": 32900
    },
    {
      "epoch": 0.650464194902726,
      "grad_norm": 0.541167676448822,
      "learning_rate": 3.5301495033145545e-05,
      "loss": 0.0107,
      "step": 33000
    },
    {
      "epoch": 0.6524352985236433,
      "grad_norm": 0.37631118297576904,
      "learning_rate": 3.510242271017061e-05,
      "loss": 0.0105,
      "step": 33100
    },
    {
      "epoch": 0.6544064021445607,
      "grad_norm": 0.9012170433998108,
      "learning_rate": 3.490335038719567e-05,
      "loss": 0.0107,
      "step": 33200
    },
    {
      "epoch": 0.656377505765478,
      "grad_norm": 0.5433884859085083,
      "learning_rate": 3.4704278064220736e-05,
      "loss": 0.0109,
      "step": 33300
    },
    {
      "epoch": 0.6583486093863954,
      "grad_norm": 0.42410048842430115,
      "learning_rate": 3.450520574124579e-05,
      "loss": 0.0117,
      "step": 33400
    },
    {
      "epoch": 0.6603197130073128,
      "grad_norm": 0.8742848038673401,
      "learning_rate": 3.4306133418270857e-05,
      "loss": 0.0113,
      "step": 33500
    },
    {
      "epoch": 0.6622908166282302,
      "grad_norm": 0.6087108850479126,
      "learning_rate": 3.410706109529592e-05,
      "loss": 0.0103,
      "step": 33600
    },
    {
      "epoch": 0.6642619202491475,
      "grad_norm": 0.6072679758071899,
      "learning_rate": 3.3907988772320984e-05,
      "loss": 0.0102,
      "step": 33700
    },
    {
      "epoch": 0.6662330238700649,
      "grad_norm": 0.680658757686615,
      "learning_rate": 3.370891644934605e-05,
      "loss": 0.0108,
      "step": 33800
    },
    {
      "epoch": 0.6682041274909822,
      "grad_norm": 0.6634693741798401,
      "learning_rate": 3.350984412637112e-05,
      "loss": 0.0113,
      "step": 33900
    },
    {
      "epoch": 0.6701752311118996,
      "grad_norm": 0.6821473240852356,
      "learning_rate": 3.3310771803396175e-05,
      "loss": 0.0103,
      "step": 34000
    },
    {
      "epoch": 0.6721463347328169,
      "grad_norm": 0.3796372711658478,
      "learning_rate": 3.311169948042124e-05,
      "loss": 0.0116,
      "step": 34100
    },
    {
      "epoch": 0.6741174383537343,
      "grad_norm": 0.5912339687347412,
      "learning_rate": 3.29126271574463e-05,
      "loss": 0.0111,
      "step": 34200
    },
    {
      "epoch": 0.6760885419746516,
      "grad_norm": 0.25775134563446045,
      "learning_rate": 3.2713554834471366e-05,
      "loss": 0.0102,
      "step": 34300
    },
    {
      "epoch": 0.678059645595569,
      "grad_norm": 0.5859728455543518,
      "learning_rate": 3.251448251149643e-05,
      "loss": 0.0099,
      "step": 34400
    },
    {
      "epoch": 0.6800307492164863,
      "grad_norm": 0.502044677734375,
      "learning_rate": 3.231541018852149e-05,
      "loss": 0.0095,
      "step": 34500
    },
    {
      "epoch": 0.6820018528374037,
      "grad_norm": 0.5165488719940186,
      "learning_rate": 3.211633786554655e-05,
      "loss": 0.0101,
      "step": 34600
    },
    {
      "epoch": 0.683972956458321,
      "grad_norm": 0.4650629758834839,
      "learning_rate": 3.1917265542571614e-05,
      "loss": 0.0106,
      "step": 34700
    },
    {
      "epoch": 0.6859440600792384,
      "grad_norm": 0.4736723005771637,
      "learning_rate": 3.1718193219596685e-05,
      "loss": 0.0101,
      "step": 34800
    },
    {
      "epoch": 0.6879151637001557,
      "grad_norm": 0.6102833151817322,
      "learning_rate": 3.151912089662175e-05,
      "loss": 0.0093,
      "step": 34900
    },
    {
      "epoch": 0.689886267321073,
      "grad_norm": 0.5823678970336914,
      "learning_rate": 3.132004857364681e-05,
      "loss": 0.0101,
      "step": 35000
    },
    {
      "epoch": 0.6918573709419904,
      "grad_norm": 0.7574917674064636,
      "learning_rate": 3.112097625067187e-05,
      "loss": 0.0101,
      "step": 35100
    },
    {
      "epoch": 0.6938284745629077,
      "grad_norm": 0.5115204453468323,
      "learning_rate": 3.092190392769693e-05,
      "loss": 0.0101,
      "step": 35200
    },
    {
      "epoch": 0.6957995781838251,
      "grad_norm": 0.5959200859069824,
      "learning_rate": 3.0722831604721996e-05,
      "loss": 0.0094,
      "step": 35300
    },
    {
      "epoch": 0.6977706818047424,
      "grad_norm": 0.894914984703064,
      "learning_rate": 3.052375928174706e-05,
      "loss": 0.0101,
      "step": 35400
    },
    {
      "epoch": 0.6997417854256598,
      "grad_norm": 0.40634018182754517,
      "learning_rate": 3.0324686958772124e-05,
      "loss": 0.009,
      "step": 35500
    },
    {
      "epoch": 0.7017128890465771,
      "grad_norm": 0.4499861001968384,
      "learning_rate": 3.0125614635797187e-05,
      "loss": 0.0084,
      "step": 35600
    },
    {
      "epoch": 0.7036839926674945,
      "grad_norm": 0.7128419876098633,
      "learning_rate": 2.9926542312822248e-05,
      "loss": 0.009,
      "step": 35700
    },
    {
      "epoch": 0.7056550962884118,
      "grad_norm": 0.6386848092079163,
      "learning_rate": 2.972746998984731e-05,
      "loss": 0.0095,
      "step": 35800
    },
    {
      "epoch": 0.7076261999093292,
      "grad_norm": 0.3444072902202606,
      "learning_rate": 2.9528397666872375e-05,
      "loss": 0.009,
      "step": 35900
    },
    {
      "epoch": 0.7095973035302466,
      "grad_norm": 0.7115074992179871,
      "learning_rate": 2.932932534389744e-05,
      "loss": 0.0089,
      "step": 36000
    },
    {
      "epoch": 0.711568407151164,
      "grad_norm": 0.3960016965866089,
      "learning_rate": 2.9130253020922506e-05,
      "loss": 0.0091,
      "step": 36100
    },
    {
      "epoch": 0.7135395107720813,
      "grad_norm": 0.6750929355621338,
      "learning_rate": 2.8931180697947563e-05,
      "loss": 0.0094,
      "step": 36200
    },
    {
      "epoch": 0.7155106143929987,
      "grad_norm": 0.5351586937904358,
      "learning_rate": 2.8732108374972627e-05,
      "loss": 0.0089,
      "step": 36300
    },
    {
      "epoch": 0.717481718013916,
      "grad_norm": 0.5045995712280273,
      "learning_rate": 2.853303605199769e-05,
      "loss": 0.0079,
      "step": 36400
    },
    {
      "epoch": 0.7194528216348334,
      "grad_norm": 0.5199915766716003,
      "learning_rate": 2.8333963729022754e-05,
      "loss": 0.0083,
      "step": 36500
    },
    {
      "epoch": 0.7214239252557507,
      "grad_norm": 0.4920916259288788,
      "learning_rate": 2.813489140604782e-05,
      "loss": 0.0072,
      "step": 36600
    },
    {
      "epoch": 0.7233950288766681,
      "grad_norm": 0.4936508536338806,
      "learning_rate": 2.7935819083072885e-05,
      "loss": 0.0081,
      "step": 36700
    },
    {
      "epoch": 0.7253661324975854,
      "grad_norm": 0.7199549078941345,
      "learning_rate": 2.7736746760097942e-05,
      "loss": 0.0085,
      "step": 36800
    },
    {
      "epoch": 0.7273372361185028,
      "grad_norm": 0.315877765417099,
      "learning_rate": 2.7537674437123005e-05,
      "loss": 0.0091,
      "step": 36900
    },
    {
      "epoch": 0.7293083397394201,
      "grad_norm": 0.6591871380805969,
      "learning_rate": 2.7338602114148072e-05,
      "loss": 0.008,
      "step": 37000
    },
    {
      "epoch": 0.7312794433603375,
      "grad_norm": 0.5665448307991028,
      "learning_rate": 2.7139529791173136e-05,
      "loss": 0.0086,
      "step": 37100
    },
    {
      "epoch": 0.7332505469812548,
      "grad_norm": 0.5962436199188232,
      "learning_rate": 2.69404574681982e-05,
      "loss": 0.0076,
      "step": 37200
    },
    {
      "epoch": 0.7352216506021721,
      "grad_norm": 0.32590964436531067,
      "learning_rate": 2.6741385145223264e-05,
      "loss": 0.009,
      "step": 37300
    },
    {
      "epoch": 0.7371927542230895,
      "grad_norm": 0.3879895508289337,
      "learning_rate": 2.654231282224832e-05,
      "loss": 0.0081,
      "step": 37400
    },
    {
      "epoch": 0.7391638578440068,
      "grad_norm": 0.6067126393318176,
      "learning_rate": 2.6343240499273388e-05,
      "loss": 0.0084,
      "step": 37500
    },
    {
      "epoch": 0.7411349614649242,
      "grad_norm": 0.3931233286857605,
      "learning_rate": 2.614416817629845e-05,
      "loss": 0.009,
      "step": 37600
    },
    {
      "epoch": 0.7431060650858415,
      "grad_norm": 0.5202725529670715,
      "learning_rate": 2.5945095853323515e-05,
      "loss": 0.0081,
      "step": 37700
    },
    {
      "epoch": 0.7450771687067589,
      "grad_norm": 0.6790543794631958,
      "learning_rate": 2.574602353034858e-05,
      "loss": 0.008,
      "step": 37800
    },
    {
      "epoch": 0.7470482723276762,
      "grad_norm": 0.43239626288414,
      "learning_rate": 2.5546951207373642e-05,
      "loss": 0.0088,
      "step": 37900
    },
    {
      "epoch": 0.7490193759485936,
      "grad_norm": 0.47574424743652344,
      "learning_rate": 2.5347878884398703e-05,
      "loss": 0.0084,
      "step": 38000
    },
    {
      "epoch": 0.7509904795695109,
      "grad_norm": 0.42722389101982117,
      "learning_rate": 2.5148806561423766e-05,
      "loss": 0.0087,
      "step": 38100
    },
    {
      "epoch": 0.7529615831904283,
      "grad_norm": 0.4411092698574066,
      "learning_rate": 2.494973423844883e-05,
      "loss": 0.0069,
      "step": 38200
    },
    {
      "epoch": 0.7549326868113456,
      "grad_norm": 0.4269636571407318,
      "learning_rate": 2.4750661915473894e-05,
      "loss": 0.0083,
      "step": 38300
    },
    {
      "epoch": 0.7569037904322631,
      "grad_norm": 0.44558167457580566,
      "learning_rate": 2.4551589592498954e-05,
      "loss": 0.0076,
      "step": 38400
    },
    {
      "epoch": 0.7588748940531804,
      "grad_norm": 0.6640341281890869,
      "learning_rate": 2.4352517269524018e-05,
      "loss": 0.0076,
      "step": 38500
    },
    {
      "epoch": 0.7608459976740978,
      "grad_norm": 0.5820606350898743,
      "learning_rate": 2.4153444946549085e-05,
      "loss": 0.0071,
      "step": 38600
    },
    {
      "epoch": 0.7628171012950151,
      "grad_norm": 0.41736820340156555,
      "learning_rate": 2.3954372623574145e-05,
      "loss": 0.0076,
      "step": 38700
    },
    {
      "epoch": 0.7647882049159325,
      "grad_norm": 0.7165847420692444,
      "learning_rate": 2.375530030059921e-05,
      "loss": 0.008,
      "step": 38800
    },
    {
      "epoch": 0.7667593085368498,
      "grad_norm": 0.5921211242675781,
      "learning_rate": 2.3556227977624273e-05,
      "loss": 0.007,
      "step": 38900
    },
    {
      "epoch": 0.7687304121577672,
      "grad_norm": 0.6111380457878113,
      "learning_rate": 2.3357155654649336e-05,
      "loss": 0.0073,
      "step": 39000
    },
    {
      "epoch": 0.7707015157786845,
      "grad_norm": 0.4103996157646179,
      "learning_rate": 2.31580833316744e-05,
      "loss": 0.0068,
      "step": 39100
    },
    {
      "epoch": 0.7726726193996019,
      "grad_norm": 0.2571703791618347,
      "learning_rate": 2.295901100869946e-05,
      "loss": 0.0075,
      "step": 39200
    },
    {
      "epoch": 0.7746437230205192,
      "grad_norm": 0.3697565197944641,
      "learning_rate": 2.2759938685724524e-05,
      "loss": 0.0066,
      "step": 39300
    },
    {
      "epoch": 0.7766148266414366,
      "grad_norm": 0.7974883317947388,
      "learning_rate": 2.2560866362749588e-05,
      "loss": 0.0065,
      "step": 39400
    },
    {
      "epoch": 0.7785859302623539,
      "grad_norm": 0.40093308687210083,
      "learning_rate": 2.236179403977465e-05,
      "loss": 0.0066,
      "step": 39500
    },
    {
      "epoch": 0.7805570338832712,
      "grad_norm": 0.41099897027015686,
      "learning_rate": 2.2162721716799715e-05,
      "loss": 0.0075,
      "step": 39600
    },
    {
      "epoch": 0.7825281375041886,
      "grad_norm": 0.2696854770183563,
      "learning_rate": 2.196364939382478e-05,
      "loss": 0.0075,
      "step": 39700
    },
    {
      "epoch": 0.7844992411251059,
      "grad_norm": 0.3428928852081299,
      "learning_rate": 2.176457707084984e-05,
      "loss": 0.0067,
      "step": 39800
    },
    {
      "epoch": 0.7864703447460233,
      "grad_norm": 0.6508688926696777,
      "learning_rate": 2.1565504747874903e-05,
      "loss": 0.0067,
      "step": 39900
    },
    {
      "epoch": 0.7884414483669406,
      "grad_norm": 0.5386759638786316,
      "learning_rate": 2.1366432424899967e-05,
      "loss": 0.0068,
      "step": 40000
    },
    {
      "epoch": 0.790412551987858,
      "grad_norm": 0.4808156192302704,
      "learning_rate": 2.116736010192503e-05,
      "loss": 0.0072,
      "step": 40100
    },
    {
      "epoch": 0.7923836556087753,
      "grad_norm": 0.6743514537811279,
      "learning_rate": 2.0968287778950094e-05,
      "loss": 0.0066,
      "step": 40200
    },
    {
      "epoch": 0.7943547592296927,
      "grad_norm": 0.388367623090744,
      "learning_rate": 2.0769215455975158e-05,
      "loss": 0.0067,
      "step": 40300
    },
    {
      "epoch": 0.79632586285061,
      "grad_norm": 0.4627009332180023,
      "learning_rate": 2.0570143133000218e-05,
      "loss": 0.0058,
      "step": 40400
    },
    {
      "epoch": 0.7982969664715274,
      "grad_norm": 0.4241689443588257,
      "learning_rate": 2.0371070810025285e-05,
      "loss": 0.0061,
      "step": 40500
    },
    {
      "epoch": 0.8002680700924447,
      "grad_norm": 0.39834344387054443,
      "learning_rate": 2.017199848705035e-05,
      "loss": 0.0065,
      "step": 40600
    },
    {
      "epoch": 0.8022391737133621,
      "grad_norm": 0.2719663977622986,
      "learning_rate": 1.997292616407541e-05,
      "loss": 0.0062,
      "step": 40700
    },
    {
      "epoch": 0.8042102773342794,
      "grad_norm": 0.2938866913318634,
      "learning_rate": 1.9773853841100473e-05,
      "loss": 0.0071,
      "step": 40800
    },
    {
      "epoch": 0.8061813809551969,
      "grad_norm": 0.7513675689697266,
      "learning_rate": 1.9574781518125536e-05,
      "loss": 0.0063,
      "step": 40900
    },
    {
      "epoch": 0.8081524845761142,
      "grad_norm": 0.366042822599411,
      "learning_rate": 1.93757091951506e-05,
      "loss": 0.0065,
      "step": 41000
    },
    {
      "epoch": 0.8101235881970316,
      "grad_norm": 0.2966195046901703,
      "learning_rate": 1.9176636872175664e-05,
      "loss": 0.0063,
      "step": 41100
    },
    {
      "epoch": 0.8120946918179489,
      "grad_norm": 0.32155224680900574,
      "learning_rate": 1.8977564549200724e-05,
      "loss": 0.0062,
      "step": 41200
    },
    {
      "epoch": 0.8140657954388663,
      "grad_norm": 0.6853170394897461,
      "learning_rate": 1.8778492226225788e-05,
      "loss": 0.0067,
      "step": 41300
    },
    {
      "epoch": 0.8160368990597836,
      "grad_norm": 0.24202726781368256,
      "learning_rate": 1.857941990325085e-05,
      "loss": 0.0058,
      "step": 41400
    },
    {
      "epoch": 0.818008002680701,
      "grad_norm": 0.7928986549377441,
      "learning_rate": 1.8380347580275915e-05,
      "loss": 0.0071,
      "step": 41500
    },
    {
      "epoch": 0.8199791063016183,
      "grad_norm": 0.39344075322151184,
      "learning_rate": 1.818127525730098e-05,
      "loss": 0.0057,
      "step": 41600
    },
    {
      "epoch": 0.8219502099225356,
      "grad_norm": 0.5467848777770996,
      "learning_rate": 1.7982202934326043e-05,
      "loss": 0.0061,
      "step": 41700
    },
    {
      "epoch": 0.823921313543453,
      "grad_norm": 0.4659460484981537,
      "learning_rate": 1.7783130611351103e-05,
      "loss": 0.0054,
      "step": 41800
    },
    {
      "epoch": 0.8258924171643703,
      "grad_norm": 0.326992928981781,
      "learning_rate": 1.7584058288376167e-05,
      "loss": 0.0053,
      "step": 41900
    },
    {
      "epoch": 0.8278635207852877,
      "grad_norm": 0.5731582045555115,
      "learning_rate": 1.738498596540123e-05,
      "loss": 0.0063,
      "step": 42000
    },
    {
      "epoch": 0.829834624406205,
      "grad_norm": 0.4026913642883301,
      "learning_rate": 1.7185913642426294e-05,
      "loss": 0.0057,
      "step": 42100
    },
    {
      "epoch": 0.8318057280271224,
      "grad_norm": 0.5698288083076477,
      "learning_rate": 1.6986841319451358e-05,
      "loss": 0.0054,
      "step": 42200
    },
    {
      "epoch": 0.8337768316480397,
      "grad_norm": 0.5051668286323547,
      "learning_rate": 1.678776899647642e-05,
      "loss": 0.0061,
      "step": 42300
    },
    {
      "epoch": 0.8357479352689571,
      "grad_norm": 0.4929946959018707,
      "learning_rate": 1.6588696673501482e-05,
      "loss": 0.0063,
      "step": 42400
    },
    {
      "epoch": 0.8377190388898744,
      "grad_norm": 0.5157355070114136,
      "learning_rate": 1.638962435052655e-05,
      "loss": 0.0056,
      "step": 42500
    },
    {
      "epoch": 0.8396901425107918,
      "grad_norm": 0.7517353296279907,
      "learning_rate": 1.6190552027551613e-05,
      "loss": 0.0053,
      "step": 42600
    },
    {
      "epoch": 0.8416612461317091,
      "grad_norm": 0.5532257556915283,
      "learning_rate": 1.5991479704576673e-05,
      "loss": 0.0057,
      "step": 42700
    },
    {
      "epoch": 0.8436323497526265,
      "grad_norm": 0.33406326174736023,
      "learning_rate": 1.5792407381601737e-05,
      "loss": 0.0055,
      "step": 42800
    },
    {
      "epoch": 0.8456034533735438,
      "grad_norm": 0.38053247332572937,
      "learning_rate": 1.55933350586268e-05,
      "loss": 0.0052,
      "step": 42900
    },
    {
      "epoch": 0.8475745569944612,
      "grad_norm": 0.7361717820167542,
      "learning_rate": 1.5394262735651864e-05,
      "loss": 0.0053,
      "step": 43000
    },
    {
      "epoch": 0.8495456606153785,
      "grad_norm": 0.5040593147277832,
      "learning_rate": 1.5195190412676926e-05,
      "loss": 0.0063,
      "step": 43100
    },
    {
      "epoch": 0.8515167642362959,
      "grad_norm": 0.15177416801452637,
      "learning_rate": 1.4996118089701988e-05,
      "loss": 0.0051,
      "step": 43200
    },
    {
      "epoch": 0.8534878678572132,
      "grad_norm": 0.32348737120628357,
      "learning_rate": 1.4797045766727052e-05,
      "loss": 0.0052,
      "step": 43300
    },
    {
      "epoch": 0.8554589714781307,
      "grad_norm": 0.45817041397094727,
      "learning_rate": 1.4597973443752117e-05,
      "loss": 0.0054,
      "step": 43400
    },
    {
      "epoch": 0.857430075099048,
      "grad_norm": 0.5648016929626465,
      "learning_rate": 1.4398901120777177e-05,
      "loss": 0.0052,
      "step": 43500
    },
    {
      "epoch": 0.8594011787199654,
      "grad_norm": 0.296652615070343,
      "learning_rate": 1.4199828797802243e-05,
      "loss": 0.0048,
      "step": 43600
    },
    {
      "epoch": 0.8613722823408827,
      "grad_norm": 0.35121268033981323,
      "learning_rate": 1.4000756474827307e-05,
      "loss": 0.0049,
      "step": 43700
    },
    {
      "epoch": 0.8633433859618,
      "grad_norm": 0.5297470688819885,
      "learning_rate": 1.3801684151852367e-05,
      "loss": 0.0045,
      "step": 43800
    },
    {
      "epoch": 0.8653144895827174,
      "grad_norm": 0.5150076150894165,
      "learning_rate": 1.3602611828877432e-05,
      "loss": 0.0051,
      "step": 43900
    },
    {
      "epoch": 0.8672855932036347,
      "grad_norm": 0.5267905592918396,
      "learning_rate": 1.3403539505902496e-05,
      "loss": 0.0055,
      "step": 44000
    },
    {
      "epoch": 0.8692566968245521,
      "grad_norm": 0.32508420944213867,
      "learning_rate": 1.3204467182927558e-05,
      "loss": 0.0044,
      "step": 44100
    },
    {
      "epoch": 0.8712278004454694,
      "grad_norm": 0.5896554589271545,
      "learning_rate": 1.3005394859952622e-05,
      "loss": 0.0053,
      "step": 44200
    },
    {
      "epoch": 0.8731989040663868,
      "grad_norm": 0.28655704855918884,
      "learning_rate": 1.2806322536977685e-05,
      "loss": 0.0052,
      "step": 44300
    },
    {
      "epoch": 0.8751700076873041,
      "grad_norm": 0.4240598678588867,
      "learning_rate": 1.2607250214002747e-05,
      "loss": 0.0047,
      "step": 44400
    },
    {
      "epoch": 0.8771411113082215,
      "grad_norm": 0.10956951975822449,
      "learning_rate": 1.2408177891027811e-05,
      "loss": 0.0047,
      "step": 44500
    },
    {
      "epoch": 0.8791122149291388,
      "grad_norm": 0.316509485244751,
      "learning_rate": 1.2209105568052875e-05,
      "loss": 0.0046,
      "step": 44600
    },
    {
      "epoch": 0.8810833185500562,
      "grad_norm": 0.30448997020721436,
      "learning_rate": 1.2010033245077937e-05,
      "loss": 0.0046,
      "step": 44700
    },
    {
      "epoch": 0.8830544221709735,
      "grad_norm": 0.5908995866775513,
      "learning_rate": 1.1810960922103e-05,
      "loss": 0.0046,
      "step": 44800
    },
    {
      "epoch": 0.8850255257918909,
      "grad_norm": 0.38794460892677307,
      "learning_rate": 1.1611888599128064e-05,
      "loss": 0.0042,
      "step": 44900
    },
    {
      "epoch": 0.8869966294128082,
      "grad_norm": 0.31932732462882996,
      "learning_rate": 1.1412816276153126e-05,
      "loss": 0.0044,
      "step": 45000
    },
    {
      "epoch": 0.8889677330337256,
      "grad_norm": 0.49859127402305603,
      "learning_rate": 1.121374395317819e-05,
      "loss": 0.0044,
      "step": 45100
    },
    {
      "epoch": 0.8909388366546429,
      "grad_norm": 0.18198496103286743,
      "learning_rate": 1.1014671630203254e-05,
      "loss": 0.0038,
      "step": 45200
    },
    {
      "epoch": 0.8929099402755603,
      "grad_norm": 0.22741973400115967,
      "learning_rate": 1.0815599307228316e-05,
      "loss": 0.0038,
      "step": 45300
    },
    {
      "epoch": 0.8948810438964776,
      "grad_norm": 0.31391915678977966,
      "learning_rate": 1.0616526984253381e-05,
      "loss": 0.0048,
      "step": 45400
    },
    {
      "epoch": 0.896852147517395,
      "grad_norm": 0.4570537805557251,
      "learning_rate": 1.0417454661278443e-05,
      "loss": 0.0043,
      "step": 45500
    },
    {
      "epoch": 0.8988232511383123,
      "grad_norm": 0.5881010890007019,
      "learning_rate": 1.0218382338303507e-05,
      "loss": 0.0046,
      "step": 45600
    },
    {
      "epoch": 0.9007943547592296,
      "grad_norm": 0.47382551431655884,
      "learning_rate": 1.0019310015328569e-05,
      "loss": 0.0041,
      "step": 45700
    },
    {
      "epoch": 0.902765458380147,
      "grad_norm": 0.22397193312644958,
      "learning_rate": 9.820237692353632e-06,
      "loss": 0.0042,
      "step": 45800
    },
    {
      "epoch": 0.9047365620010644,
      "grad_norm": 0.2934727966785431,
      "learning_rate": 9.621165369378696e-06,
      "loss": 0.0044,
      "step": 45900
    },
    {
      "epoch": 0.9067076656219818,
      "grad_norm": 0.4909183382987976,
      "learning_rate": 9.422093046403758e-06,
      "loss": 0.004,
      "step": 46000
    },
    {
      "epoch": 0.9086787692428991,
      "grad_norm": 0.3826213777065277,
      "learning_rate": 9.223020723428823e-06,
      "loss": 0.0042,
      "step": 46100
    },
    {
      "epoch": 0.9106498728638165,
      "grad_norm": 0.39436081051826477,
      "learning_rate": 9.023948400453885e-06,
      "loss": 0.0036,
      "step": 46200
    },
    {
      "epoch": 0.9126209764847338,
      "grad_norm": 0.4448012411594391,
      "learning_rate": 8.824876077478948e-06,
      "loss": 0.0036,
      "step": 46300
    },
    {
      "epoch": 0.9145920801056512,
      "grad_norm": 0.2605080306529999,
      "learning_rate": 8.625803754504013e-06,
      "loss": 0.0038,
      "step": 46400
    },
    {
      "epoch": 0.9165631837265685,
      "grad_norm": 0.22452382743358612,
      "learning_rate": 8.426731431529075e-06,
      "loss": 0.0035,
      "step": 46500
    },
    {
      "epoch": 0.9185342873474859,
      "grad_norm": 0.05069301277399063,
      "learning_rate": 8.227659108554139e-06,
      "loss": 0.004,
      "step": 46600
    },
    {
      "epoch": 0.9205053909684032,
      "grad_norm": 0.38170668482780457,
      "learning_rate": 8.0285867855792e-06,
      "loss": 0.0037,
      "step": 46700
    },
    {
      "epoch": 0.9224764945893206,
      "grad_norm": 0.5008975863456726,
      "learning_rate": 7.829514462604264e-06,
      "loss": 0.0038,
      "step": 46800
    },
    {
      "epoch": 0.9244475982102379,
      "grad_norm": 0.40665119886398315,
      "learning_rate": 7.630442139629328e-06,
      "loss": 0.0034,
      "step": 46900
    },
    {
      "epoch": 0.9264187018311553,
      "grad_norm": 0.742854118347168,
      "learning_rate": 7.431369816654391e-06,
      "loss": 0.0039,
      "step": 47000
    },
    {
      "epoch": 0.9283898054520726,
      "grad_norm": 0.24868720769882202,
      "learning_rate": 7.2322974936794546e-06,
      "loss": 0.0033,
      "step": 47100
    },
    {
      "epoch": 0.93036090907299,
      "grad_norm": 0.5734382271766663,
      "learning_rate": 7.033225170704517e-06,
      "loss": 0.0036,
      "step": 47200
    },
    {
      "epoch": 0.9323320126939073,
      "grad_norm": 0.3380069434642792,
      "learning_rate": 6.83415284772958e-06,
      "loss": 0.0032,
      "step": 47300
    },
    {
      "epoch": 0.9343031163148247,
      "grad_norm": 0.4780324697494507,
      "learning_rate": 6.635080524754644e-06,
      "loss": 0.003,
      "step": 47400
    },
    {
      "epoch": 0.936274219935742,
      "grad_norm": 0.0915834829211235,
      "learning_rate": 6.436008201779707e-06,
      "loss": 0.0037,
      "step": 47500
    },
    {
      "epoch": 0.9382453235566593,
      "grad_norm": 0.5912806987762451,
      "learning_rate": 6.23693587880477e-06,
      "loss": 0.0035,
      "step": 47600
    },
    {
      "epoch": 0.9402164271775767,
      "grad_norm": 0.3832128047943115,
      "learning_rate": 6.037863555829833e-06,
      "loss": 0.0032,
      "step": 47700
    },
    {
      "epoch": 0.942187530798494,
      "grad_norm": 0.21933625638484955,
      "learning_rate": 5.838791232854896e-06,
      "loss": 0.0034,
      "step": 47800
    },
    {
      "epoch": 0.9441586344194114,
      "grad_norm": 0.26422998309135437,
      "learning_rate": 5.63971890987996e-06,
      "loss": 0.0031,
      "step": 47900
    },
    {
      "epoch": 0.9461297380403287,
      "grad_norm": 0.28754308819770813,
      "learning_rate": 5.440646586905023e-06,
      "loss": 0.0036,
      "step": 48000
    },
    {
      "epoch": 0.9481008416612461,
      "grad_norm": 0.17815162241458893,
      "learning_rate": 5.241574263930086e-06,
      "loss": 0.0029,
      "step": 48100
    },
    {
      "epoch": 0.9500719452821634,
      "grad_norm": 0.3039444088935852,
      "learning_rate": 5.042501940955149e-06,
      "loss": 0.0033,
      "step": 48200
    },
    {
      "epoch": 0.9520430489030808,
      "grad_norm": 0.4407741129398346,
      "learning_rate": 4.843429617980212e-06,
      "loss": 0.0032,
      "step": 48300
    },
    {
      "epoch": 0.9540141525239982,
      "grad_norm": 0.3232762813568115,
      "learning_rate": 4.644357295005276e-06,
      "loss": 0.0031,
      "step": 48400
    },
    {
      "epoch": 0.9559852561449156,
      "grad_norm": 0.5486832857131958,
      "learning_rate": 4.445284972030339e-06,
      "loss": 0.0033,
      "step": 48500
    },
    {
      "epoch": 0.9579563597658329,
      "grad_norm": 0.2484796941280365,
      "learning_rate": 4.246212649055402e-06,
      "loss": 0.0033,
      "step": 48600
    },
    {
      "epoch": 0.9599274633867503,
      "grad_norm": 0.36408406496047974,
      "learning_rate": 4.047140326080465e-06,
      "loss": 0.0032,
      "step": 48700
    },
    {
      "epoch": 0.9618985670076676,
      "grad_norm": 0.5369302034378052,
      "learning_rate": 3.848068003105528e-06,
      "loss": 0.003,
      "step": 48800
    },
    {
      "epoch": 0.963869670628585,
      "grad_norm": 0.781169056892395,
      "learning_rate": 3.6489956801305914e-06,
      "loss": 0.0028,
      "step": 48900
    },
    {
      "epoch": 0.9658407742495023,
      "grad_norm": 0.21555550396442413,
      "learning_rate": 3.449923357155655e-06,
      "loss": 0.0028,
      "step": 49000
    },
    {
      "epoch": 0.9678118778704197,
      "grad_norm": 0.17523948848247528,
      "learning_rate": 3.250851034180718e-06,
      "loss": 0.003,
      "step": 49100
    },
    {
      "epoch": 0.969782981491337,
      "grad_norm": 0.16078056395053864,
      "learning_rate": 3.0517787112057813e-06,
      "loss": 0.0026,
      "step": 49200
    },
    {
      "epoch": 0.9717540851122544,
      "grad_norm": 0.23032155632972717,
      "learning_rate": 2.8527063882308445e-06,
      "loss": 0.0032,
      "step": 49300
    },
    {
      "epoch": 0.9737251887331717,
      "grad_norm": 0.45528700947761536,
      "learning_rate": 2.6536340652559074e-06,
      "loss": 0.0025,
      "step": 49400
    },
    {
      "epoch": 0.9756962923540891,
      "grad_norm": 0.2855084538459778,
      "learning_rate": 2.4545617422809707e-06,
      "loss": 0.003,
      "step": 49500
    },
    {
      "epoch": 0.9776673959750064,
      "grad_norm": 0.2368256002664566,
      "learning_rate": 2.255489419306034e-06,
      "loss": 0.0028,
      "step": 49600
    },
    {
      "epoch": 0.9796384995959238,
      "grad_norm": 0.09101004898548126,
      "learning_rate": 2.0564170963310972e-06,
      "loss": 0.0029,
      "step": 49700
    },
    {
      "epoch": 0.9816096032168411,
      "grad_norm": 0.19433939456939697,
      "learning_rate": 1.8573447733561605e-06,
      "loss": 0.0029,
      "step": 49800
    },
    {
      "epoch": 0.9835807068377584,
      "grad_norm": 0.08444423973560333,
      "learning_rate": 1.6582724503812236e-06,
      "loss": 0.0029,
      "step": 49900
    },
    {
      "epoch": 0.9855518104586758,
      "grad_norm": 0.26451191306114197,
      "learning_rate": 1.4592001274062866e-06,
      "loss": 0.0027,
      "step": 50000
    },
    {
      "epoch": 0.9875229140795931,
      "grad_norm": 0.2719363570213318,
      "learning_rate": 1.26012780443135e-06,
      "loss": 0.0031,
      "step": 50100
    },
    {
      "epoch": 0.9894940177005105,
      "grad_norm": 0.38830843567848206,
      "learning_rate": 1.0610554814564132e-06,
      "loss": 0.0029,
      "step": 50200
    },
    {
      "epoch": 0.9914651213214278,
      "grad_norm": 0.23197369277477264,
      "learning_rate": 8.619831584814765e-07,
      "loss": 0.0028,
      "step": 50300
    },
    {
      "epoch": 0.9934362249423452,
      "grad_norm": 0.26479074358940125,
      "learning_rate": 6.629108355065395e-07,
      "loss": 0.0024,
      "step": 50400
    },
    {
      "epoch": 0.9954073285632625,
      "grad_norm": 0.2909759283065796,
      "learning_rate": 4.638385125316028e-07,
      "loss": 0.0023,
      "step": 50500
    },
    {
      "epoch": 0.9973784321841799,
      "grad_norm": 0.3310076892375946,
      "learning_rate": 2.64766189556666e-07,
      "loss": 0.0024,
      "step": 50600
    },
    {
      "epoch": 0.9993495358050972,
      "grad_norm": 0.4683413505554199,
      "learning_rate": 6.569386658172915e-08,
      "loss": 0.0027,
      "step": 50700
    }
  ],
  "logging_steps": 100,
  "max_steps": 50733,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
