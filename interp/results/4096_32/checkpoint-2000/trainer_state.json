{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9765625,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01220703125,
      "grad_norm": 0.8053004145622253,
      "learning_rate": 0.000498779296875,
      "loss": 19.9717,
      "step": 25
    },
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.18708980083465576,
      "learning_rate": 0.0004975585937500001,
      "loss": 1.2451,
      "step": 50
    },
    {
      "epoch": 0.03662109375,
      "grad_norm": 0.20843660831451416,
      "learning_rate": 0.000496337890625,
      "loss": 1.2436,
      "step": 75
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.2793765664100647,
      "learning_rate": 0.0004951171875,
      "loss": 1.8496,
      "step": 100
    },
    {
      "epoch": 0.06103515625,
      "grad_norm": 0.32661691308021545,
      "learning_rate": 0.000493896484375,
      "loss": 2.2371,
      "step": 125
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.36603018641471863,
      "learning_rate": 0.0004926757812500001,
      "loss": 2.4764,
      "step": 150
    },
    {
      "epoch": 0.08544921875,
      "grad_norm": 0.3856395483016968,
      "learning_rate": 0.000491455078125,
      "loss": 2.6761,
      "step": 175
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.4434715807437897,
      "learning_rate": 0.000490234375,
      "loss": 2.8444,
      "step": 200
    },
    {
      "epoch": 0.10986328125,
      "grad_norm": 0.4415164887905121,
      "learning_rate": 0.000489013671875,
      "loss": 2.9677,
      "step": 225
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.47082868218421936,
      "learning_rate": 0.00048779296875,
      "loss": 3.0752,
      "step": 250
    },
    {
      "epoch": 0.13427734375,
      "grad_norm": 0.48054039478302,
      "learning_rate": 0.000486572265625,
      "loss": 3.1402,
      "step": 275
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.4934934377670288,
      "learning_rate": 0.0004853515625,
      "loss": 3.2206,
      "step": 300
    },
    {
      "epoch": 0.15869140625,
      "grad_norm": 0.49448609352111816,
      "learning_rate": 0.000484130859375,
      "loss": 3.2626,
      "step": 325
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.4775053858757019,
      "learning_rate": 0.00048291015625,
      "loss": 3.3121,
      "step": 350
    },
    {
      "epoch": 0.18310546875,
      "grad_norm": 0.47582510113716125,
      "learning_rate": 0.000481689453125,
      "loss": 3.3321,
      "step": 375
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.48351967334747314,
      "learning_rate": 0.00048046875,
      "loss": 3.341,
      "step": 400
    },
    {
      "epoch": 0.20751953125,
      "grad_norm": 0.4848178029060364,
      "learning_rate": 0.000479248046875,
      "loss": 3.3351,
      "step": 425
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.46800562739372253,
      "learning_rate": 0.00047802734375,
      "loss": 3.3333,
      "step": 450
    },
    {
      "epoch": 0.23193359375,
      "grad_norm": 0.4597272276878357,
      "learning_rate": 0.000476806640625,
      "loss": 3.3176,
      "step": 475
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.4607950448989868,
      "learning_rate": 0.0004755859375,
      "loss": 3.2863,
      "step": 500
    },
    {
      "epoch": 0.25634765625,
      "grad_norm": 0.4411247968673706,
      "learning_rate": 0.000474365234375,
      "loss": 3.2311,
      "step": 525
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 0.4403899013996124,
      "learning_rate": 0.00047314453125,
      "loss": 3.1806,
      "step": 550
    },
    {
      "epoch": 0.28076171875,
      "grad_norm": 0.43817126750946045,
      "learning_rate": 0.000471923828125,
      "loss": 3.1208,
      "step": 575
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.44025880098342896,
      "learning_rate": 0.000470703125,
      "loss": 3.0496,
      "step": 600
    },
    {
      "epoch": 0.30517578125,
      "grad_norm": 0.4301396608352661,
      "learning_rate": 0.000469482421875,
      "loss": 2.9598,
      "step": 625
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.4304027855396271,
      "learning_rate": 0.00046826171875000004,
      "loss": 2.8735,
      "step": 650
    },
    {
      "epoch": 0.32958984375,
      "grad_norm": 0.41572847962379456,
      "learning_rate": 0.000467041015625,
      "loss": 2.7737,
      "step": 675
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 0.3972421884536743,
      "learning_rate": 0.00046582031250000003,
      "loss": 2.6765,
      "step": 700
    },
    {
      "epoch": 0.35400390625,
      "grad_norm": 0.3992181122303009,
      "learning_rate": 0.000464599609375,
      "loss": 2.5663,
      "step": 725
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 0.40646591782569885,
      "learning_rate": 0.00046337890625000003,
      "loss": 2.4449,
      "step": 750
    },
    {
      "epoch": 0.37841796875,
      "grad_norm": 0.42394453287124634,
      "learning_rate": 0.000462158203125,
      "loss": 2.3399,
      "step": 775
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.38079574704170227,
      "learning_rate": 0.00046093750000000003,
      "loss": 2.2162,
      "step": 800
    },
    {
      "epoch": 0.40283203125,
      "grad_norm": 0.38148555159568787,
      "learning_rate": 0.000459716796875,
      "loss": 2.0965,
      "step": 825
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.3982091248035431,
      "learning_rate": 0.00045849609375000003,
      "loss": 1.992,
      "step": 850
    },
    {
      "epoch": 0.42724609375,
      "grad_norm": 0.3670308291912079,
      "learning_rate": 0.000457275390625,
      "loss": 1.889,
      "step": 875
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 0.36543411016464233,
      "learning_rate": 0.0004560546875,
      "loss": 1.7759,
      "step": 900
    },
    {
      "epoch": 0.45166015625,
      "grad_norm": 0.35531073808670044,
      "learning_rate": 0.000454833984375,
      "loss": 1.6833,
      "step": 925
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.3717088997364044,
      "learning_rate": 0.00045361328125,
      "loss": 1.5937,
      "step": 950
    },
    {
      "epoch": 0.47607421875,
      "grad_norm": 0.3527492582798004,
      "learning_rate": 0.000452392578125,
      "loss": 1.5216,
      "step": 975
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.35426464676856995,
      "learning_rate": 0.000451171875,
      "loss": 1.455,
      "step": 1000
    },
    {
      "epoch": 0.50048828125,
      "grad_norm": 0.3563218116760254,
      "learning_rate": 0.000449951171875,
      "loss": 1.4022,
      "step": 1025
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.3220364451408386,
      "learning_rate": 0.00044873046875,
      "loss": 1.3514,
      "step": 1050
    },
    {
      "epoch": 0.52490234375,
      "grad_norm": 0.31546729803085327,
      "learning_rate": 0.000447509765625,
      "loss": 1.2938,
      "step": 1075
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.3124413788318634,
      "learning_rate": 0.0004462890625,
      "loss": 1.2471,
      "step": 1100
    },
    {
      "epoch": 0.54931640625,
      "grad_norm": 0.3173137903213501,
      "learning_rate": 0.000445068359375,
      "loss": 1.2031,
      "step": 1125
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.30095043778419495,
      "learning_rate": 0.00044384765625,
      "loss": 1.1552,
      "step": 1150
    },
    {
      "epoch": 0.57373046875,
      "grad_norm": 0.3282438814640045,
      "learning_rate": 0.000442626953125,
      "loss": 1.1164,
      "step": 1175
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.27534639835357666,
      "learning_rate": 0.00044140625,
      "loss": 1.0697,
      "step": 1200
    },
    {
      "epoch": 0.59814453125,
      "grad_norm": 0.276793897151947,
      "learning_rate": 0.000440185546875,
      "loss": 1.0265,
      "step": 1225
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.2659008800983429,
      "learning_rate": 0.00043896484375,
      "loss": 0.9921,
      "step": 1250
    },
    {
      "epoch": 0.62255859375,
      "grad_norm": 0.283071368932724,
      "learning_rate": 0.000437744140625,
      "loss": 0.9661,
      "step": 1275
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.2663941979408264,
      "learning_rate": 0.0004365234375,
      "loss": 0.9251,
      "step": 1300
    },
    {
      "epoch": 0.64697265625,
      "grad_norm": 0.2686481177806854,
      "learning_rate": 0.00043530273437500003,
      "loss": 0.8777,
      "step": 1325
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.26028138399124146,
      "learning_rate": 0.00043408203125,
      "loss": 0.8436,
      "step": 1350
    },
    {
      "epoch": 0.67138671875,
      "grad_norm": 0.2688405513763428,
      "learning_rate": 0.00043286132812500003,
      "loss": 0.8035,
      "step": 1375
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.2572328746318817,
      "learning_rate": 0.000431640625,
      "loss": 0.7608,
      "step": 1400
    },
    {
      "epoch": 0.69580078125,
      "grad_norm": 0.254562646150589,
      "learning_rate": 0.00043041992187500003,
      "loss": 0.7224,
      "step": 1425
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.2479052096605301,
      "learning_rate": 0.00042919921875,
      "loss": 0.7024,
      "step": 1450
    },
    {
      "epoch": 0.72021484375,
      "grad_norm": 0.22872374951839447,
      "learning_rate": 0.00042797851562500003,
      "loss": 0.6762,
      "step": 1475
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.2328176647424698,
      "learning_rate": 0.0004267578125,
      "loss": 0.6543,
      "step": 1500
    },
    {
      "epoch": 0.74462890625,
      "grad_norm": 0.23238638043403625,
      "learning_rate": 0.000425537109375,
      "loss": 0.636,
      "step": 1525
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.23064301908016205,
      "learning_rate": 0.00042431640625,
      "loss": 0.6143,
      "step": 1550
    },
    {
      "epoch": 0.76904296875,
      "grad_norm": 0.22168584167957306,
      "learning_rate": 0.000423095703125,
      "loss": 0.5923,
      "step": 1575
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.20554102957248688,
      "learning_rate": 0.000421875,
      "loss": 0.5661,
      "step": 1600
    },
    {
      "epoch": 0.79345703125,
      "grad_norm": 0.2080335170030594,
      "learning_rate": 0.000420654296875,
      "loss": 0.5465,
      "step": 1625
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.20503458380699158,
      "learning_rate": 0.00041943359375,
      "loss": 0.5156,
      "step": 1650
    },
    {
      "epoch": 0.81787109375,
      "grad_norm": 0.19802738726139069,
      "learning_rate": 0.000418212890625,
      "loss": 0.5011,
      "step": 1675
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.19089707732200623,
      "learning_rate": 0.0004169921875,
      "loss": 0.4862,
      "step": 1700
    },
    {
      "epoch": 0.84228515625,
      "grad_norm": 0.1863044798374176,
      "learning_rate": 0.000415771484375,
      "loss": 0.4671,
      "step": 1725
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.19633081555366516,
      "learning_rate": 0.00041455078125,
      "loss": 0.4534,
      "step": 1750
    },
    {
      "epoch": 0.86669921875,
      "grad_norm": 0.18672513961791992,
      "learning_rate": 0.000413330078125,
      "loss": 0.4458,
      "step": 1775
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.19954454898834229,
      "learning_rate": 0.000412109375,
      "loss": 0.4362,
      "step": 1800
    },
    {
      "epoch": 0.89111328125,
      "grad_norm": 0.19899068772792816,
      "learning_rate": 0.000410888671875,
      "loss": 0.4275,
      "step": 1825
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.19502831995487213,
      "learning_rate": 0.00040966796875,
      "loss": 0.4066,
      "step": 1850
    },
    {
      "epoch": 0.91552734375,
      "grad_norm": 0.16616009175777435,
      "learning_rate": 0.000408447265625,
      "loss": 0.3894,
      "step": 1875
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.18487051129341125,
      "learning_rate": 0.0004072265625,
      "loss": 0.3707,
      "step": 1900
    },
    {
      "epoch": 0.93994140625,
      "grad_norm": 0.17860840260982513,
      "learning_rate": 0.000406005859375,
      "loss": 0.3552,
      "step": 1925
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.15326550602912903,
      "learning_rate": 0.00040478515625000003,
      "loss": 0.3413,
      "step": 1950
    },
    {
      "epoch": 0.96435546875,
      "grad_norm": 0.15343590080738068,
      "learning_rate": 0.000403564453125,
      "loss": 0.3305,
      "step": 1975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.14061835408210754,
      "learning_rate": 0.00040234375000000003,
      "loss": 0.3108,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
