{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.953125,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.7256909608840942,
      "learning_rate": 0.0004975585937500001,
      "loss": 24.2015,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.2556456923484802,
      "learning_rate": 0.0004951171875,
      "loss": 1.9554,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.405994176864624,
      "learning_rate": 0.0004926757812500001,
      "loss": 2.3918,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.5792684555053711,
      "learning_rate": 0.000490234375,
      "loss": 3.9136,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.6812976598739624,
      "learning_rate": 0.00048779296875,
      "loss": 4.6996,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.7829159498214722,
      "learning_rate": 0.0004853515625,
      "loss": 5.2384,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.8468828201293945,
      "learning_rate": 0.00048291015625,
      "loss": 5.6644,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.8815123438835144,
      "learning_rate": 0.00048046875,
      "loss": 5.9972,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.9419077634811401,
      "learning_rate": 0.00047802734375,
      "loss": 6.233,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.9916335344314575,
      "learning_rate": 0.0004755859375,
      "loss": 6.4349,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 1.014488697052002,
      "learning_rate": 0.00047314453125,
      "loss": 6.5925,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 1.0778436660766602,
      "learning_rate": 0.000470703125,
      "loss": 6.7202,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.9889407753944397,
      "learning_rate": 0.00046826171875000004,
      "loss": 6.816,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 1.0611822605133057,
      "learning_rate": 0.00046582031250000003,
      "loss": 6.8687,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 1.0562382936477661,
      "learning_rate": 0.00046337890625000003,
      "loss": 6.9047,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.9849733114242554,
      "learning_rate": 0.00046093750000000003,
      "loss": 6.9159,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.9547848701477051,
      "learning_rate": 0.00045849609375000003,
      "loss": 6.8857,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 1.0055646896362305,
      "learning_rate": 0.0004560546875,
      "loss": 6.8381,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.9489848613739014,
      "learning_rate": 0.00045361328125,
      "loss": 6.7961,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.9024492502212524,
      "learning_rate": 0.000451171875,
      "loss": 6.7022,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.9383626580238342,
      "learning_rate": 0.00044873046875,
      "loss": 6.6144,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.8972709774971008,
      "learning_rate": 0.0004462890625,
      "loss": 6.5136,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.8806187510490417,
      "learning_rate": 0.00044384765625,
      "loss": 6.3846,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.8691141605377197,
      "learning_rate": 0.00044140625,
      "loss": 6.2673,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.8984339237213135,
      "learning_rate": 0.00043896484375,
      "loss": 6.1359,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.8873488903045654,
      "learning_rate": 0.0004365234375,
      "loss": 5.9894,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.8537425994873047,
      "learning_rate": 0.00043408203125,
      "loss": 5.8383,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.8232187032699585,
      "learning_rate": 0.000431640625,
      "loss": 5.6798,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.814903974533081,
      "learning_rate": 0.00042919921875,
      "loss": 5.5336,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.7902757525444031,
      "learning_rate": 0.0004267578125,
      "loss": 5.3695,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.7253377437591553,
      "learning_rate": 0.00042431640625,
      "loss": 5.2008,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.7983341217041016,
      "learning_rate": 0.000421875,
      "loss": 5.0096,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.7481955289840698,
      "learning_rate": 0.00041943359375,
      "loss": 4.8451,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.6762096881866455,
      "learning_rate": 0.0004169921875,
      "loss": 4.6777,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.8071371912956238,
      "learning_rate": 0.00041455078125,
      "loss": 4.4822,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.7484933733940125,
      "learning_rate": 0.000412109375,
      "loss": 4.3055,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.6850308179855347,
      "learning_rate": 0.00040966796875,
      "loss": 4.1573,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.7092894911766052,
      "learning_rate": 0.0004072265625,
      "loss": 3.996,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.7293285727500916,
      "learning_rate": 0.00040478515625000003,
      "loss": 3.841,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.6968901753425598,
      "learning_rate": 0.00040234375000000003,
      "loss": 3.7061,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.6615803837776184,
      "learning_rate": 0.00039990234375000003,
      "loss": 3.5836,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.6644913554191589,
      "learning_rate": 0.00039746093750000003,
      "loss": 3.4353,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.6946684122085571,
      "learning_rate": 0.00039501953125,
      "loss": 3.2716,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.628665030002594,
      "learning_rate": 0.000392578125,
      "loss": 3.1007,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.6084377765655518,
      "learning_rate": 0.00039013671875,
      "loss": 2.9769,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.6405307650566101,
      "learning_rate": 0.0003876953125,
      "loss": 2.826,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.5981870293617249,
      "learning_rate": 0.00038525390625,
      "loss": 2.6906,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.5996806621551514,
      "learning_rate": 0.0003828125,
      "loss": 2.5736,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.5812567472457886,
      "learning_rate": 0.00038037109375,
      "loss": 2.4675,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.5854231119155884,
      "learning_rate": 0.0003779296875,
      "loss": 2.3698,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.5400378704071045,
      "learning_rate": 0.00037548828125,
      "loss": 2.2786,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.5506613850593567,
      "learning_rate": 0.000373046875,
      "loss": 2.2054,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.5778705477714539,
      "learning_rate": 0.00037060546875,
      "loss": 2.1301,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.5556075572967529,
      "learning_rate": 0.0003681640625,
      "loss": 2.0575,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.5418931245803833,
      "learning_rate": 0.00036572265625,
      "loss": 1.9713,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.48190125823020935,
      "learning_rate": 0.00036328125,
      "loss": 1.8958,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.4737488925457001,
      "learning_rate": 0.00036083984375,
      "loss": 1.8378,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.43221911787986755,
      "learning_rate": 0.0003583984375,
      "loss": 1.7729,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.4509839713573456,
      "learning_rate": 0.00035595703125,
      "loss": 1.7102,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.4290684163570404,
      "learning_rate": 0.000353515625,
      "loss": 1.6602,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.4091695547103882,
      "learning_rate": 0.00035107421875,
      "loss": 1.5951,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.3797532021999359,
      "learning_rate": 0.0003486328125,
      "loss": 1.5334,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.39035576581954956,
      "learning_rate": 0.00034619140625,
      "loss": 1.4703,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.39700666069984436,
      "learning_rate": 0.00034375,
      "loss": 1.4212,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.38028237223625183,
      "learning_rate": 0.00034130859375000003,
      "loss": 1.362,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.36359140276908875,
      "learning_rate": 0.00033886718750000003,
      "loss": 1.3132,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.3566758334636688,
      "learning_rate": 0.00033642578125000003,
      "loss": 1.2632,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.37032350897789,
      "learning_rate": 0.000333984375,
      "loss": 1.218,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.31227993965148926,
      "learning_rate": 0.00033154296875,
      "loss": 1.1689,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.3604387640953064,
      "learning_rate": 0.0003291015625,
      "loss": 1.1443,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.3380556106567383,
      "learning_rate": 0.00032666015625,
      "loss": 1.0971,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.3458901047706604,
      "learning_rate": 0.00032421875,
      "loss": 1.0549,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.31901562213897705,
      "learning_rate": 0.00032177734375,
      "loss": 1.0172,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.33709076046943665,
      "learning_rate": 0.0003193359375,
      "loss": 0.9895,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.2979929447174072,
      "learning_rate": 0.00031689453125,
      "loss": 0.9672,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.3024151623249054,
      "learning_rate": 0.000314453125,
      "loss": 0.9425,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.3122934401035309,
      "learning_rate": 0.00031201171875,
      "loss": 0.9215,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.2662174701690674,
      "learning_rate": 0.0003095703125,
      "loss": 0.8946,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.27740389108657837,
      "learning_rate": 0.00030712890625,
      "loss": 0.8689,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.2852889895439148,
      "learning_rate": 0.0003046875,
      "loss": 0.8476,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
