{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.90625,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.7256909608840942,
      "learning_rate": 0.0004975585937500001,
      "loss": 24.2015,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.2556456923484802,
      "learning_rate": 0.0004951171875,
      "loss": 1.9554,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.405994176864624,
      "learning_rate": 0.0004926757812500001,
      "loss": 2.3918,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.5792684555053711,
      "learning_rate": 0.000490234375,
      "loss": 3.9136,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.6812976598739624,
      "learning_rate": 0.00048779296875,
      "loss": 4.6996,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.7829159498214722,
      "learning_rate": 0.0004853515625,
      "loss": 5.2384,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.8468828201293945,
      "learning_rate": 0.00048291015625,
      "loss": 5.6644,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.8815123438835144,
      "learning_rate": 0.00048046875,
      "loss": 5.9972,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.9419077634811401,
      "learning_rate": 0.00047802734375,
      "loss": 6.233,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.9916335344314575,
      "learning_rate": 0.0004755859375,
      "loss": 6.4349,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 1.014488697052002,
      "learning_rate": 0.00047314453125,
      "loss": 6.5925,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 1.0778436660766602,
      "learning_rate": 0.000470703125,
      "loss": 6.7202,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.9889407753944397,
      "learning_rate": 0.00046826171875000004,
      "loss": 6.816,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 1.0611822605133057,
      "learning_rate": 0.00046582031250000003,
      "loss": 6.8687,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 1.0562382936477661,
      "learning_rate": 0.00046337890625000003,
      "loss": 6.9047,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.9849733114242554,
      "learning_rate": 0.00046093750000000003,
      "loss": 6.9159,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.9547848701477051,
      "learning_rate": 0.00045849609375000003,
      "loss": 6.8857,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 1.0055646896362305,
      "learning_rate": 0.0004560546875,
      "loss": 6.8381,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.9489848613739014,
      "learning_rate": 0.00045361328125,
      "loss": 6.7961,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.9024492502212524,
      "learning_rate": 0.000451171875,
      "loss": 6.7022,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.9383626580238342,
      "learning_rate": 0.00044873046875,
      "loss": 6.6144,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.8972709774971008,
      "learning_rate": 0.0004462890625,
      "loss": 6.5136,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.8806187510490417,
      "learning_rate": 0.00044384765625,
      "loss": 6.3846,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.8691141605377197,
      "learning_rate": 0.00044140625,
      "loss": 6.2673,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.8984339237213135,
      "learning_rate": 0.00043896484375,
      "loss": 6.1359,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.8873488903045654,
      "learning_rate": 0.0004365234375,
      "loss": 5.9894,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.8537425994873047,
      "learning_rate": 0.00043408203125,
      "loss": 5.8383,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.8232187032699585,
      "learning_rate": 0.000431640625,
      "loss": 5.6798,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.814903974533081,
      "learning_rate": 0.00042919921875,
      "loss": 5.5336,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.7902757525444031,
      "learning_rate": 0.0004267578125,
      "loss": 5.3695,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.7253377437591553,
      "learning_rate": 0.00042431640625,
      "loss": 5.2008,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.7983341217041016,
      "learning_rate": 0.000421875,
      "loss": 5.0096,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.7481955289840698,
      "learning_rate": 0.00041943359375,
      "loss": 4.8451,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.6762096881866455,
      "learning_rate": 0.0004169921875,
      "loss": 4.6777,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.8071371912956238,
      "learning_rate": 0.00041455078125,
      "loss": 4.4822,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.7484933733940125,
      "learning_rate": 0.000412109375,
      "loss": 4.3055,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.6850308179855347,
      "learning_rate": 0.00040966796875,
      "loss": 4.1573,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.7092894911766052,
      "learning_rate": 0.0004072265625,
      "loss": 3.996,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.7293285727500916,
      "learning_rate": 0.00040478515625000003,
      "loss": 3.841,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.6968901753425598,
      "learning_rate": 0.00040234375000000003,
      "loss": 3.7061,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.6615803837776184,
      "learning_rate": 0.00039990234375000003,
      "loss": 3.5836,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.6644913554191589,
      "learning_rate": 0.00039746093750000003,
      "loss": 3.4353,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.6946684122085571,
      "learning_rate": 0.00039501953125,
      "loss": 3.2716,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.628665030002594,
      "learning_rate": 0.000392578125,
      "loss": 3.1007,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.6084377765655518,
      "learning_rate": 0.00039013671875,
      "loss": 2.9769,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.6405307650566101,
      "learning_rate": 0.0003876953125,
      "loss": 2.826,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.5981870293617249,
      "learning_rate": 0.00038525390625,
      "loss": 2.6906,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.5996806621551514,
      "learning_rate": 0.0003828125,
      "loss": 2.5736,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.5812567472457886,
      "learning_rate": 0.00038037109375,
      "loss": 2.4675,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.5854231119155884,
      "learning_rate": 0.0003779296875,
      "loss": 2.3698,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.5400378704071045,
      "learning_rate": 0.00037548828125,
      "loss": 2.2786,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.5506613850593567,
      "learning_rate": 0.000373046875,
      "loss": 2.2054,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.5778705477714539,
      "learning_rate": 0.00037060546875,
      "loss": 2.1301,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.5556075572967529,
      "learning_rate": 0.0003681640625,
      "loss": 2.0575,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.5418931245803833,
      "learning_rate": 0.00036572265625,
      "loss": 1.9713,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.48190125823020935,
      "learning_rate": 0.00036328125,
      "loss": 1.8958,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.4737488925457001,
      "learning_rate": 0.00036083984375,
      "loss": 1.8378,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.43221911787986755,
      "learning_rate": 0.0003583984375,
      "loss": 1.7729,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.4509839713573456,
      "learning_rate": 0.00035595703125,
      "loss": 1.7102,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.4290684163570404,
      "learning_rate": 0.000353515625,
      "loss": 1.6602,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.4091695547103882,
      "learning_rate": 0.00035107421875,
      "loss": 1.5951,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.3797532021999359,
      "learning_rate": 0.0003486328125,
      "loss": 1.5334,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.39035576581954956,
      "learning_rate": 0.00034619140625,
      "loss": 1.4703,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.39700666069984436,
      "learning_rate": 0.00034375,
      "loss": 1.4212,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.38028237223625183,
      "learning_rate": 0.00034130859375000003,
      "loss": 1.362,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.36359140276908875,
      "learning_rate": 0.00033886718750000003,
      "loss": 1.3132,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.3566758334636688,
      "learning_rate": 0.00033642578125000003,
      "loss": 1.2632,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.37032350897789,
      "learning_rate": 0.000333984375,
      "loss": 1.218,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.31227993965148926,
      "learning_rate": 0.00033154296875,
      "loss": 1.1689,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.3604387640953064,
      "learning_rate": 0.0003291015625,
      "loss": 1.1443,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.3380556106567383,
      "learning_rate": 0.00032666015625,
      "loss": 1.0971,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.3458901047706604,
      "learning_rate": 0.00032421875,
      "loss": 1.0549,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.31901562213897705,
      "learning_rate": 0.00032177734375,
      "loss": 1.0172,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.33709076046943665,
      "learning_rate": 0.0003193359375,
      "loss": 0.9895,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.2979929447174072,
      "learning_rate": 0.00031689453125,
      "loss": 0.9672,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.3024151623249054,
      "learning_rate": 0.000314453125,
      "loss": 0.9425,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.3122934401035309,
      "learning_rate": 0.00031201171875,
      "loss": 0.9215,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.2662174701690674,
      "learning_rate": 0.0003095703125,
      "loss": 0.8946,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.27740389108657837,
      "learning_rate": 0.00030712890625,
      "loss": 0.8689,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.2852889895439148,
      "learning_rate": 0.0003046875,
      "loss": 0.8476,
      "step": 2000
    },
    {
      "epoch": 1.9775390625,
      "grad_norm": 0.28264686465263367,
      "learning_rate": 0.00030224609375,
      "loss": 0.8266,
      "step": 2025
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 0.28349387645721436,
      "learning_rate": 0.0002998046875,
      "loss": 0.805,
      "step": 2050
    },
    {
      "epoch": 2.0263671875,
      "grad_norm": 0.2547950744628906,
      "learning_rate": 0.00029736328125,
      "loss": 0.7865,
      "step": 2075
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.2716766893863678,
      "learning_rate": 0.000294921875,
      "loss": 0.7739,
      "step": 2100
    },
    {
      "epoch": 2.0751953125,
      "grad_norm": 0.2629452645778656,
      "learning_rate": 0.00029248046875,
      "loss": 0.7517,
      "step": 2125
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 0.2597090005874634,
      "learning_rate": 0.0002900390625,
      "loss": 0.7492,
      "step": 2150
    },
    {
      "epoch": 2.1240234375,
      "grad_norm": 0.27202048897743225,
      "learning_rate": 0.00028759765625,
      "loss": 0.729,
      "step": 2175
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.27198976278305054,
      "learning_rate": 0.00028515625,
      "loss": 0.7195,
      "step": 2200
    },
    {
      "epoch": 2.1728515625,
      "grad_norm": 0.24202431738376617,
      "learning_rate": 0.00028271484375,
      "loss": 0.7038,
      "step": 2225
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 0.2637559473514557,
      "learning_rate": 0.00028027343750000003,
      "loss": 0.6897,
      "step": 2250
    },
    {
      "epoch": 2.2216796875,
      "grad_norm": 0.22790463268756866,
      "learning_rate": 0.00027783203125000003,
      "loss": 0.68,
      "step": 2275
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 0.2522693872451782,
      "learning_rate": 0.00027539062500000003,
      "loss": 0.6644,
      "step": 2300
    },
    {
      "epoch": 2.2705078125,
      "grad_norm": 0.2481788545846939,
      "learning_rate": 0.00027294921875,
      "loss": 0.6522,
      "step": 2325
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 0.22123834490776062,
      "learning_rate": 0.0002705078125,
      "loss": 0.6413,
      "step": 2350
    },
    {
      "epoch": 2.3193359375,
      "grad_norm": 0.23792359232902527,
      "learning_rate": 0.00026806640625,
      "loss": 0.6343,
      "step": 2375
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.2130517065525055,
      "learning_rate": 0.000265625,
      "loss": 0.6105,
      "step": 2400
    },
    {
      "epoch": 2.3681640625,
      "grad_norm": 0.21316026151180267,
      "learning_rate": 0.00026318359375,
      "loss": 0.5997,
      "step": 2425
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 0.23745352029800415,
      "learning_rate": 0.0002607421875,
      "loss": 0.5774,
      "step": 2450
    },
    {
      "epoch": 2.4169921875,
      "grad_norm": 0.2090710550546646,
      "learning_rate": 0.00025830078125,
      "loss": 0.5623,
      "step": 2475
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.19075456261634827,
      "learning_rate": 0.000255859375,
      "loss": 0.5457,
      "step": 2500
    },
    {
      "epoch": 2.4658203125,
      "grad_norm": 0.20005828142166138,
      "learning_rate": 0.00025341796875,
      "loss": 0.5277,
      "step": 2525
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 0.18882639706134796,
      "learning_rate": 0.0002509765625,
      "loss": 0.5099,
      "step": 2550
    },
    {
      "epoch": 2.5146484375,
      "grad_norm": 0.19297119975090027,
      "learning_rate": 0.00024853515625,
      "loss": 0.5028,
      "step": 2575
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.1986578106880188,
      "learning_rate": 0.00024609375,
      "loss": 0.4923,
      "step": 2600
    },
    {
      "epoch": 2.5634765625,
      "grad_norm": 0.19930753111839294,
      "learning_rate": 0.00024365234375,
      "loss": 0.482,
      "step": 2625
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 0.1868080496788025,
      "learning_rate": 0.0002412109375,
      "loss": 0.475,
      "step": 2650
    },
    {
      "epoch": 2.6123046875,
      "grad_norm": 0.19340714812278748,
      "learning_rate": 0.00023876953125,
      "loss": 0.47,
      "step": 2675
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 0.1858721524477005,
      "learning_rate": 0.000236328125,
      "loss": 0.4594,
      "step": 2700
    },
    {
      "epoch": 2.6611328125,
      "grad_norm": 0.16936902701854706,
      "learning_rate": 0.00023388671875000002,
      "loss": 0.4518,
      "step": 2725
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 0.1800665557384491,
      "learning_rate": 0.00023144531250000002,
      "loss": 0.4394,
      "step": 2750
    },
    {
      "epoch": 2.7099609375,
      "grad_norm": 0.17358389496803284,
      "learning_rate": 0.00022900390625000001,
      "loss": 0.4323,
      "step": 2775
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.17062288522720337,
      "learning_rate": 0.0002265625,
      "loss": 0.4234,
      "step": 2800
    },
    {
      "epoch": 2.7587890625,
      "grad_norm": 0.16735617816448212,
      "learning_rate": 0.00022412109375,
      "loss": 0.4145,
      "step": 2825
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 0.1670956164598465,
      "learning_rate": 0.0002216796875,
      "loss": 0.4037,
      "step": 2850
    },
    {
      "epoch": 2.8076171875,
      "grad_norm": 0.17447374761104584,
      "learning_rate": 0.00021923828125,
      "loss": 0.3967,
      "step": 2875
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 0.16652701795101166,
      "learning_rate": 0.000216796875,
      "loss": 0.3891,
      "step": 2900
    },
    {
      "epoch": 2.8564453125,
      "grad_norm": 0.15279215574264526,
      "learning_rate": 0.00021435546875,
      "loss": 0.3835,
      "step": 2925
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 0.1599160134792328,
      "learning_rate": 0.0002119140625,
      "loss": 0.3699,
      "step": 2950
    },
    {
      "epoch": 2.9052734375,
      "grad_norm": 0.15314584970474243,
      "learning_rate": 0.00020947265625,
      "loss": 0.3622,
      "step": 2975
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.15568754076957703,
      "learning_rate": 0.00020703125,
      "loss": 0.3524,
      "step": 3000
    },
    {
      "epoch": 2.9541015625,
      "grad_norm": 0.15067827701568604,
      "learning_rate": 0.00020458984375,
      "loss": 0.344,
      "step": 3025
    },
    {
      "epoch": 2.978515625,
      "grad_norm": 0.16119374334812164,
      "learning_rate": 0.00020214843750000002,
      "loss": 0.3383,
      "step": 3050
    },
    {
      "epoch": 3.0029296875,
      "grad_norm": 0.14269839227199554,
      "learning_rate": 0.00019970703125000001,
      "loss": 0.33,
      "step": 3075
    },
    {
      "epoch": 3.02734375,
      "grad_norm": 0.14656060934066772,
      "learning_rate": 0.000197265625,
      "loss": 0.3278,
      "step": 3100
    },
    {
      "epoch": 3.0517578125,
      "grad_norm": 0.1483462005853653,
      "learning_rate": 0.00019482421875,
      "loss": 0.3198,
      "step": 3125
    },
    {
      "epoch": 3.076171875,
      "grad_norm": 0.14351806044578552,
      "learning_rate": 0.0001923828125,
      "loss": 0.3156,
      "step": 3150
    },
    {
      "epoch": 3.1005859375,
      "grad_norm": 0.13536685705184937,
      "learning_rate": 0.00018994140625,
      "loss": 0.3105,
      "step": 3175
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.1417982280254364,
      "learning_rate": 0.0001875,
      "loss": 0.3065,
      "step": 3200
    },
    {
      "epoch": 3.1494140625,
      "grad_norm": 0.13708455860614777,
      "learning_rate": 0.00018505859375,
      "loss": 0.3027,
      "step": 3225
    },
    {
      "epoch": 3.173828125,
      "grad_norm": 0.14156320691108704,
      "learning_rate": 0.0001826171875,
      "loss": 0.2984,
      "step": 3250
    },
    {
      "epoch": 3.1982421875,
      "grad_norm": 0.1228814497590065,
      "learning_rate": 0.00018017578125,
      "loss": 0.2914,
      "step": 3275
    },
    {
      "epoch": 3.22265625,
      "grad_norm": 0.12761345505714417,
      "learning_rate": 0.000177734375,
      "loss": 0.2914,
      "step": 3300
    },
    {
      "epoch": 3.2470703125,
      "grad_norm": 0.13557590544223785,
      "learning_rate": 0.00017529296875,
      "loss": 0.2862,
      "step": 3325
    },
    {
      "epoch": 3.271484375,
      "grad_norm": 0.13086187839508057,
      "learning_rate": 0.0001728515625,
      "loss": 0.286,
      "step": 3350
    },
    {
      "epoch": 3.2958984375,
      "grad_norm": 0.12967488169670105,
      "learning_rate": 0.00017041015625000002,
      "loss": 0.2821,
      "step": 3375
    },
    {
      "epoch": 3.3203125,
      "grad_norm": 0.1314850151538849,
      "learning_rate": 0.00016796875000000001,
      "loss": 0.2806,
      "step": 3400
    },
    {
      "epoch": 3.3447265625,
      "grad_norm": 0.13381196558475494,
      "learning_rate": 0.00016552734375,
      "loss": 0.2791,
      "step": 3425
    },
    {
      "epoch": 3.369140625,
      "grad_norm": 0.13788928091526031,
      "learning_rate": 0.0001630859375,
      "loss": 0.2712,
      "step": 3450
    },
    {
      "epoch": 3.3935546875,
      "grad_norm": 0.13010554015636444,
      "learning_rate": 0.00016064453125,
      "loss": 0.2701,
      "step": 3475
    },
    {
      "epoch": 3.41796875,
      "grad_norm": 0.12806206941604614,
      "learning_rate": 0.000158203125,
      "loss": 0.2652,
      "step": 3500
    },
    {
      "epoch": 3.4423828125,
      "grad_norm": 0.11830981075763702,
      "learning_rate": 0.00015576171875,
      "loss": 0.2603,
      "step": 3525
    },
    {
      "epoch": 3.466796875,
      "grad_norm": 0.13082927465438843,
      "learning_rate": 0.0001533203125,
      "loss": 0.2588,
      "step": 3550
    },
    {
      "epoch": 3.4912109375,
      "grad_norm": 0.12669359147548676,
      "learning_rate": 0.00015087890625,
      "loss": 0.2566,
      "step": 3575
    },
    {
      "epoch": 3.515625,
      "grad_norm": 0.1252741813659668,
      "learning_rate": 0.0001484375,
      "loss": 0.2506,
      "step": 3600
    },
    {
      "epoch": 3.5400390625,
      "grad_norm": 0.1251491755247116,
      "learning_rate": 0.00014599609375,
      "loss": 0.2504,
      "step": 3625
    },
    {
      "epoch": 3.564453125,
      "grad_norm": 0.12100344896316528,
      "learning_rate": 0.0001435546875,
      "loss": 0.2485,
      "step": 3650
    },
    {
      "epoch": 3.5888671875,
      "grad_norm": 0.1259370595216751,
      "learning_rate": 0.00014111328125,
      "loss": 0.2448,
      "step": 3675
    },
    {
      "epoch": 3.61328125,
      "grad_norm": 0.11982510983943939,
      "learning_rate": 0.00013867187500000001,
      "loss": 0.2445,
      "step": 3700
    },
    {
      "epoch": 3.6376953125,
      "grad_norm": 0.13191546499729156,
      "learning_rate": 0.00013623046875,
      "loss": 0.2454,
      "step": 3725
    },
    {
      "epoch": 3.662109375,
      "grad_norm": 0.1390274614095688,
      "learning_rate": 0.0001337890625,
      "loss": 0.2452,
      "step": 3750
    },
    {
      "epoch": 3.6865234375,
      "grad_norm": 0.12443815916776657,
      "learning_rate": 0.00013134765625,
      "loss": 0.2422,
      "step": 3775
    },
    {
      "epoch": 3.7109375,
      "grad_norm": 0.12014325708150864,
      "learning_rate": 0.00012890625,
      "loss": 0.2427,
      "step": 3800
    },
    {
      "epoch": 3.7353515625,
      "grad_norm": 0.12305958569049835,
      "learning_rate": 0.00012646484375,
      "loss": 0.2457,
      "step": 3825
    },
    {
      "epoch": 3.759765625,
      "grad_norm": 0.13147278130054474,
      "learning_rate": 0.0001240234375,
      "loss": 0.245,
      "step": 3850
    },
    {
      "epoch": 3.7841796875,
      "grad_norm": 0.13251687586307526,
      "learning_rate": 0.00012158203125,
      "loss": 0.2472,
      "step": 3875
    },
    {
      "epoch": 3.80859375,
      "grad_norm": 0.12296488136053085,
      "learning_rate": 0.000119140625,
      "loss": 0.2496,
      "step": 3900
    },
    {
      "epoch": 3.8330078125,
      "grad_norm": 0.14155320823192596,
      "learning_rate": 0.00011669921875000001,
      "loss": 0.2492,
      "step": 3925
    },
    {
      "epoch": 3.857421875,
      "grad_norm": 0.13345827162265778,
      "learning_rate": 0.0001142578125,
      "loss": 0.2526,
      "step": 3950
    },
    {
      "epoch": 3.8818359375,
      "grad_norm": 0.14287693798542023,
      "learning_rate": 0.00011181640625,
      "loss": 0.2527,
      "step": 3975
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.14074468612670898,
      "learning_rate": 0.000109375,
      "loss": 0.2562,
      "step": 4000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
