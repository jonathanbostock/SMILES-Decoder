{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.859375,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.048828125,
      "grad_norm": 23.9404354095459,
      "learning_rate": 1.9902343750000002e-05,
      "loss": 90.8783,
      "step": 50
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 17.42243003845215,
      "learning_rate": 1.9804687500000003e-05,
      "loss": 146.0439,
      "step": 100
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 12.863730430603027,
      "learning_rate": 1.970703125e-05,
      "loss": 180.6598,
      "step": 150
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 9.513699531555176,
      "learning_rate": 1.9609375e-05,
      "loss": 196.6178,
      "step": 200
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 7.017597198486328,
      "learning_rate": 1.951171875e-05,
      "loss": 197.3808,
      "step": 250
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 5.161116600036621,
      "learning_rate": 1.9414062500000002e-05,
      "loss": 186.8364,
      "step": 300
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 3.7133285999298096,
      "learning_rate": 1.9316406250000002e-05,
      "loss": 169.0487,
      "step": 350
    },
    {
      "epoch": 0.390625,
      "grad_norm": 2.5334599018096924,
      "learning_rate": 1.9218750000000003e-05,
      "loss": 146.7145,
      "step": 400
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 1.651615023612976,
      "learning_rate": 1.912109375e-05,
      "loss": 122.81,
      "step": 450
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 1.0441550016403198,
      "learning_rate": 1.90234375e-05,
      "loss": 99.227,
      "step": 500
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.6318907737731934,
      "learning_rate": 1.892578125e-05,
      "loss": 78.7815,
      "step": 550
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.44630441069602966,
      "learning_rate": 1.8828125000000002e-05,
      "loss": 65.9259,
      "step": 600
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.34302961826324463,
      "learning_rate": 1.8730468750000003e-05,
      "loss": 59.6378,
      "step": 650
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.27531516551971436,
      "learning_rate": 1.8632812500000003e-05,
      "loss": 55.3945,
      "step": 700
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.2144961804151535,
      "learning_rate": 1.853515625e-05,
      "loss": 53.0966,
      "step": 750
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.17156414687633514,
      "learning_rate": 1.84375e-05,
      "loss": 51.5468,
      "step": 800
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.1485338658094406,
      "learning_rate": 1.833984375e-05,
      "loss": 50.8261,
      "step": 850
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.1321549266576767,
      "learning_rate": 1.8242187500000002e-05,
      "loss": 50.7436,
      "step": 900
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.11656296253204346,
      "learning_rate": 1.8144531250000003e-05,
      "loss": 50.55,
      "step": 950
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.11101242899894714,
      "learning_rate": 1.8046875e-05,
      "loss": 51.1262,
      "step": 1000
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.09416352212429047,
      "learning_rate": 1.794921875e-05,
      "loss": 51.4885,
      "step": 1050
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.09063208103179932,
      "learning_rate": 1.78515625e-05,
      "loss": 52.3396,
      "step": 1100
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.08873464167118073,
      "learning_rate": 1.775390625e-05,
      "loss": 53.3861,
      "step": 1150
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.07775665074586868,
      "learning_rate": 1.7656250000000002e-05,
      "loss": 54.4705,
      "step": 1200
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.0705363005399704,
      "learning_rate": 1.7558593750000003e-05,
      "loss": 55.4318,
      "step": 1250
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.06823254376649857,
      "learning_rate": 1.74609375e-05,
      "loss": 56.544,
      "step": 1300
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.06704414635896683,
      "learning_rate": 1.736328125e-05,
      "loss": 57.7187,
      "step": 1350
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.06129976361989975,
      "learning_rate": 1.7265625e-05,
      "loss": 59.1745,
      "step": 1400
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.05978723615407944,
      "learning_rate": 1.7167968750000002e-05,
      "loss": 60.7716,
      "step": 1450
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.05642513930797577,
      "learning_rate": 1.7070312500000002e-05,
      "loss": 62.2514,
      "step": 1500
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.057458557188510895,
      "learning_rate": 1.6972656250000003e-05,
      "loss": 63.5916,
      "step": 1550
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.05924244225025177,
      "learning_rate": 1.6875e-05,
      "loss": 65.4608,
      "step": 1600
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.05869285762310028,
      "learning_rate": 1.677734375e-05,
      "loss": 66.7084,
      "step": 1650
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.05827796831727028,
      "learning_rate": 1.66796875e-05,
      "loss": 68.3567,
      "step": 1700
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.05463333800435066,
      "learning_rate": 1.6582031250000002e-05,
      "loss": 70.0038,
      "step": 1750
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.057853832840919495,
      "learning_rate": 1.6484375000000003e-05,
      "loss": 71.5033,
      "step": 1800
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.05490129068493843,
      "learning_rate": 1.638671875e-05,
      "loss": 73.1439,
      "step": 1850
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.0508166179060936,
      "learning_rate": 1.62890625e-05,
      "loss": 74.9465,
      "step": 1900
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.051604319363832474,
      "learning_rate": 1.619140625e-05,
      "loss": 76.7517,
      "step": 1950
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.04752565547823906,
      "learning_rate": 1.609375e-05,
      "loss": 77.916,
      "step": 2000
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 0.05082530155777931,
      "learning_rate": 1.5996093750000002e-05,
      "loss": 79.9264,
      "step": 2050
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.04871072247624397,
      "learning_rate": 1.5898437500000003e-05,
      "loss": 80.8158,
      "step": 2100
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 0.04605643078684807,
      "learning_rate": 1.580078125e-05,
      "loss": 80.7276,
      "step": 2150
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.046258486807346344,
      "learning_rate": 1.5703125e-05,
      "loss": 80.2896,
      "step": 2200
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 0.04795742779970169,
      "learning_rate": 1.560546875e-05,
      "loss": 79.8747,
      "step": 2250
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 0.045850738883018494,
      "learning_rate": 1.5507812500000002e-05,
      "loss": 80.0992,
      "step": 2300
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 0.044515520334243774,
      "learning_rate": 1.5410156250000002e-05,
      "loss": 79.6324,
      "step": 2350
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.04549117758870125,
      "learning_rate": 1.5312500000000003e-05,
      "loss": 79.5176,
      "step": 2400
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 0.04314717277884483,
      "learning_rate": 1.5214843750000002e-05,
      "loss": 79.237,
      "step": 2450
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.043296292424201965,
      "learning_rate": 1.51171875e-05,
      "loss": 79.3997,
      "step": 2500
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 0.04231366887688637,
      "learning_rate": 1.5019531250000001e-05,
      "loss": 79.1208,
      "step": 2550
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.0425402857363224,
      "learning_rate": 1.4921875000000002e-05,
      "loss": 78.9719,
      "step": 2600
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 0.042851485311985016,
      "learning_rate": 1.482421875e-05,
      "loss": 78.9245,
      "step": 2650
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 0.042038965970277786,
      "learning_rate": 1.4726562500000001e-05,
      "loss": 78.7532,
      "step": 2700
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 0.0422406904399395,
      "learning_rate": 1.4628906250000002e-05,
      "loss": 78.8212,
      "step": 2750
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.0403117798268795,
      "learning_rate": 1.453125e-05,
      "loss": 78.5122,
      "step": 2800
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 0.042160119861364365,
      "learning_rate": 1.4433593750000001e-05,
      "loss": 78.377,
      "step": 2850
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 0.03988831117749214,
      "learning_rate": 1.43359375e-05,
      "loss": 78.5285,
      "step": 2900
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 0.039084915071725845,
      "learning_rate": 1.4238281250000001e-05,
      "loss": 78.48,
      "step": 2950
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.04167331010103226,
      "learning_rate": 1.4140625000000002e-05,
      "loss": 78.4825,
      "step": 3000
    },
    {
      "epoch": 2.978515625,
      "grad_norm": 0.0405011810362339,
      "learning_rate": 1.404296875e-05,
      "loss": 78.4008,
      "step": 3050
    },
    {
      "epoch": 3.02734375,
      "grad_norm": 0.038743846118450165,
      "learning_rate": 1.3945312500000001e-05,
      "loss": 78.2597,
      "step": 3100
    },
    {
      "epoch": 3.076171875,
      "grad_norm": 0.03985349088907242,
      "learning_rate": 1.3847656250000002e-05,
      "loss": 78.3694,
      "step": 3150
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.03712794557213783,
      "learning_rate": 1.375e-05,
      "loss": 78.236,
      "step": 3200
    },
    {
      "epoch": 3.173828125,
      "grad_norm": 0.03802729770541191,
      "learning_rate": 1.3652343750000001e-05,
      "loss": 78.4595,
      "step": 3250
    },
    {
      "epoch": 3.22265625,
      "grad_norm": 0.037377048283815384,
      "learning_rate": 1.3554687500000002e-05,
      "loss": 78.2291,
      "step": 3300
    },
    {
      "epoch": 3.271484375,
      "grad_norm": 0.03683096170425415,
      "learning_rate": 1.345703125e-05,
      "loss": 78.4225,
      "step": 3350
    },
    {
      "epoch": 3.3203125,
      "grad_norm": 0.03801031410694122,
      "learning_rate": 1.3359375000000001e-05,
      "loss": 78.2028,
      "step": 3400
    },
    {
      "epoch": 3.369140625,
      "grad_norm": 0.03763490170240402,
      "learning_rate": 1.3261718750000002e-05,
      "loss": 78.204,
      "step": 3450
    },
    {
      "epoch": 3.41796875,
      "grad_norm": 0.03808153048157692,
      "learning_rate": 1.31640625e-05,
      "loss": 78.3857,
      "step": 3500
    },
    {
      "epoch": 3.466796875,
      "grad_norm": 0.0370182991027832,
      "learning_rate": 1.3066406250000001e-05,
      "loss": 78.4088,
      "step": 3550
    },
    {
      "epoch": 3.515625,
      "grad_norm": 0.0372033528983593,
      "learning_rate": 1.2968750000000002e-05,
      "loss": 78.2866,
      "step": 3600
    },
    {
      "epoch": 3.564453125,
      "grad_norm": 0.03648574650287628,
      "learning_rate": 1.287109375e-05,
      "loss": 78.4814,
      "step": 3650
    },
    {
      "epoch": 3.61328125,
      "grad_norm": 0.03591421991586685,
      "learning_rate": 1.2773437500000001e-05,
      "loss": 78.3272,
      "step": 3700
    },
    {
      "epoch": 3.662109375,
      "grad_norm": 0.037494949996471405,
      "learning_rate": 1.267578125e-05,
      "loss": 78.541,
      "step": 3750
    },
    {
      "epoch": 3.7109375,
      "grad_norm": 0.036957621574401855,
      "learning_rate": 1.2578125e-05,
      "loss": 78.6359,
      "step": 3800
    },
    {
      "epoch": 3.759765625,
      "grad_norm": 0.03617069497704506,
      "learning_rate": 1.2480468750000001e-05,
      "loss": 78.4901,
      "step": 3850
    },
    {
      "epoch": 3.80859375,
      "grad_norm": 0.034058794379234314,
      "learning_rate": 1.23828125e-05,
      "loss": 78.7665,
      "step": 3900
    },
    {
      "epoch": 3.857421875,
      "grad_norm": 0.03567058593034744,
      "learning_rate": 1.2285156250000001e-05,
      "loss": 78.7969,
      "step": 3950
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.03396739065647125,
      "learning_rate": 1.2187500000000001e-05,
      "loss": 78.8531,
      "step": 4000
    },
    {
      "epoch": 3.955078125,
      "grad_norm": 0.035048868507146835,
      "learning_rate": 1.208984375e-05,
      "loss": 78.9207,
      "step": 4050
    },
    {
      "epoch": 4.00390625,
      "grad_norm": 0.033977482467889786,
      "learning_rate": 1.1992187500000001e-05,
      "loss": 79.0166,
      "step": 4100
    },
    {
      "epoch": 4.052734375,
      "grad_norm": 0.03823063522577286,
      "learning_rate": 1.1894531250000002e-05,
      "loss": 79.0632,
      "step": 4150
    },
    {
      "epoch": 4.1015625,
      "grad_norm": 0.03451039269566536,
      "learning_rate": 1.1796875e-05,
      "loss": 79.2595,
      "step": 4200
    },
    {
      "epoch": 4.150390625,
      "grad_norm": 0.03415432199835777,
      "learning_rate": 1.1699218750000001e-05,
      "loss": 79.5066,
      "step": 4250
    },
    {
      "epoch": 4.19921875,
      "grad_norm": 0.03231247514486313,
      "learning_rate": 1.1601562500000002e-05,
      "loss": 79.243,
      "step": 4300
    },
    {
      "epoch": 4.248046875,
      "grad_norm": 0.035479094833135605,
      "learning_rate": 1.150390625e-05,
      "loss": 79.6618,
      "step": 4350
    },
    {
      "epoch": 4.296875,
      "grad_norm": 0.03249198943376541,
      "learning_rate": 1.1406250000000001e-05,
      "loss": 79.7749,
      "step": 4400
    },
    {
      "epoch": 4.345703125,
      "grad_norm": 0.03905460610985756,
      "learning_rate": 1.1308593750000002e-05,
      "loss": 80.0498,
      "step": 4450
    },
    {
      "epoch": 4.39453125,
      "grad_norm": 0.032083090394735336,
      "learning_rate": 1.12109375e-05,
      "loss": 79.9606,
      "step": 4500
    },
    {
      "epoch": 4.443359375,
      "grad_norm": 0.03259943425655365,
      "learning_rate": 1.1113281250000001e-05,
      "loss": 80.1941,
      "step": 4550
    },
    {
      "epoch": 4.4921875,
      "grad_norm": 0.032248131930828094,
      "learning_rate": 1.1015625e-05,
      "loss": 80.1793,
      "step": 4600
    },
    {
      "epoch": 4.541015625,
      "grad_norm": 0.031987253576517105,
      "learning_rate": 1.091796875e-05,
      "loss": 80.2943,
      "step": 4650
    },
    {
      "epoch": 4.58984375,
      "grad_norm": 0.031462788581848145,
      "learning_rate": 1.0820312500000001e-05,
      "loss": 80.6526,
      "step": 4700
    },
    {
      "epoch": 4.638671875,
      "grad_norm": 0.03196270391345024,
      "learning_rate": 1.072265625e-05,
      "loss": 80.6582,
      "step": 4750
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.03303221985697746,
      "learning_rate": 1.0625e-05,
      "loss": 80.8909,
      "step": 4800
    },
    {
      "epoch": 4.736328125,
      "grad_norm": 0.03111075982451439,
      "learning_rate": 1.0527343750000001e-05,
      "loss": 81.0182,
      "step": 4850
    },
    {
      "epoch": 4.78515625,
      "grad_norm": 0.030331667512655258,
      "learning_rate": 1.04296875e-05,
      "loss": 81.1361,
      "step": 4900
    },
    {
      "epoch": 4.833984375,
      "grad_norm": 0.03532685339450836,
      "learning_rate": 1.033203125e-05,
      "loss": 81.2161,
      "step": 4950
    },
    {
      "epoch": 4.8828125,
      "grad_norm": 0.03126009553670883,
      "learning_rate": 1.0234375000000001e-05,
      "loss": 81.4444,
      "step": 5000
    },
    {
      "epoch": 4.931640625,
      "grad_norm": 0.03734666854143143,
      "learning_rate": 1.013671875e-05,
      "loss": 81.6336,
      "step": 5050
    },
    {
      "epoch": 4.98046875,
      "grad_norm": 0.030602524057030678,
      "learning_rate": 1.0039062500000001e-05,
      "loss": 81.8028,
      "step": 5100
    },
    {
      "epoch": 5.029296875,
      "grad_norm": 0.03758997470140457,
      "learning_rate": 9.941406250000002e-06,
      "loss": 81.9428,
      "step": 5150
    },
    {
      "epoch": 5.078125,
      "grad_norm": 0.03251773491501808,
      "learning_rate": 9.84375e-06,
      "loss": 82.3546,
      "step": 5200
    },
    {
      "epoch": 5.126953125,
      "grad_norm": 0.03180624172091484,
      "learning_rate": 9.746093750000001e-06,
      "loss": 82.4508,
      "step": 5250
    },
    {
      "epoch": 5.17578125,
      "grad_norm": 0.030776215717196465,
      "learning_rate": 9.648437500000002e-06,
      "loss": 82.5441,
      "step": 5300
    },
    {
      "epoch": 5.224609375,
      "grad_norm": 0.030079254880547523,
      "learning_rate": 9.55078125e-06,
      "loss": 82.7134,
      "step": 5350
    },
    {
      "epoch": 5.2734375,
      "grad_norm": 0.02955499477684498,
      "learning_rate": 9.453125000000001e-06,
      "loss": 82.8746,
      "step": 5400
    },
    {
      "epoch": 5.322265625,
      "grad_norm": 0.030718348920345306,
      "learning_rate": 9.35546875e-06,
      "loss": 83.1345,
      "step": 5450
    },
    {
      "epoch": 5.37109375,
      "grad_norm": 0.029198428615927696,
      "learning_rate": 9.2578125e-06,
      "loss": 83.3495,
      "step": 5500
    },
    {
      "epoch": 5.419921875,
      "grad_norm": 0.03332030773162842,
      "learning_rate": 9.160156250000001e-06,
      "loss": 83.6895,
      "step": 5550
    },
    {
      "epoch": 5.46875,
      "grad_norm": 0.02928282879292965,
      "learning_rate": 9.0625e-06,
      "loss": 83.6143,
      "step": 5600
    },
    {
      "epoch": 5.517578125,
      "grad_norm": 0.02856721170246601,
      "learning_rate": 8.96484375e-06,
      "loss": 83.8379,
      "step": 5650
    },
    {
      "epoch": 5.56640625,
      "grad_norm": 0.03340966999530792,
      "learning_rate": 8.867187500000001e-06,
      "loss": 84.1481,
      "step": 5700
    },
    {
      "epoch": 5.615234375,
      "grad_norm": 0.028106221929192543,
      "learning_rate": 8.76953125e-06,
      "loss": 84.3462,
      "step": 5750
    },
    {
      "epoch": 5.6640625,
      "grad_norm": 0.029557032510638237,
      "learning_rate": 8.671875e-06,
      "loss": 84.5868,
      "step": 5800
    },
    {
      "epoch": 5.712890625,
      "grad_norm": 0.028322391211986542,
      "learning_rate": 8.574218750000001e-06,
      "loss": 84.8261,
      "step": 5850
    },
    {
      "epoch": 5.76171875,
      "grad_norm": 0.029737159609794617,
      "learning_rate": 8.4765625e-06,
      "loss": 84.9584,
      "step": 5900
    },
    {
      "epoch": 5.810546875,
      "grad_norm": 0.028045447543263435,
      "learning_rate": 8.37890625e-06,
      "loss": 85.1999,
      "step": 5950
    },
    {
      "epoch": 5.859375,
      "grad_norm": 0.028595127165317535,
      "learning_rate": 8.281250000000001e-06,
      "loss": 85.3377,
      "step": 6000
    }
  ],
  "logging_steps": 50,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
