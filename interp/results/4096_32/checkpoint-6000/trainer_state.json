{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9296875,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01220703125,
      "grad_norm": 0.8053004145622253,
      "learning_rate": 0.000498779296875,
      "loss": 19.9717,
      "step": 25
    },
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.18708980083465576,
      "learning_rate": 0.0004975585937500001,
      "loss": 1.2451,
      "step": 50
    },
    {
      "epoch": 0.03662109375,
      "grad_norm": 0.20843660831451416,
      "learning_rate": 0.000496337890625,
      "loss": 1.2436,
      "step": 75
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.2793765664100647,
      "learning_rate": 0.0004951171875,
      "loss": 1.8496,
      "step": 100
    },
    {
      "epoch": 0.06103515625,
      "grad_norm": 0.32661691308021545,
      "learning_rate": 0.000493896484375,
      "loss": 2.2371,
      "step": 125
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.36603018641471863,
      "learning_rate": 0.0004926757812500001,
      "loss": 2.4764,
      "step": 150
    },
    {
      "epoch": 0.08544921875,
      "grad_norm": 0.3856395483016968,
      "learning_rate": 0.000491455078125,
      "loss": 2.6761,
      "step": 175
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.4434715807437897,
      "learning_rate": 0.000490234375,
      "loss": 2.8444,
      "step": 200
    },
    {
      "epoch": 0.10986328125,
      "grad_norm": 0.4415164887905121,
      "learning_rate": 0.000489013671875,
      "loss": 2.9677,
      "step": 225
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.47082868218421936,
      "learning_rate": 0.00048779296875,
      "loss": 3.0752,
      "step": 250
    },
    {
      "epoch": 0.13427734375,
      "grad_norm": 0.48054039478302,
      "learning_rate": 0.000486572265625,
      "loss": 3.1402,
      "step": 275
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.4934934377670288,
      "learning_rate": 0.0004853515625,
      "loss": 3.2206,
      "step": 300
    },
    {
      "epoch": 0.15869140625,
      "grad_norm": 0.49448609352111816,
      "learning_rate": 0.000484130859375,
      "loss": 3.2626,
      "step": 325
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.4775053858757019,
      "learning_rate": 0.00048291015625,
      "loss": 3.3121,
      "step": 350
    },
    {
      "epoch": 0.18310546875,
      "grad_norm": 0.47582510113716125,
      "learning_rate": 0.000481689453125,
      "loss": 3.3321,
      "step": 375
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.48351967334747314,
      "learning_rate": 0.00048046875,
      "loss": 3.341,
      "step": 400
    },
    {
      "epoch": 0.20751953125,
      "grad_norm": 0.4848178029060364,
      "learning_rate": 0.000479248046875,
      "loss": 3.3351,
      "step": 425
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.46800562739372253,
      "learning_rate": 0.00047802734375,
      "loss": 3.3333,
      "step": 450
    },
    {
      "epoch": 0.23193359375,
      "grad_norm": 0.4597272276878357,
      "learning_rate": 0.000476806640625,
      "loss": 3.3176,
      "step": 475
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.4607950448989868,
      "learning_rate": 0.0004755859375,
      "loss": 3.2863,
      "step": 500
    },
    {
      "epoch": 0.25634765625,
      "grad_norm": 0.4411247968673706,
      "learning_rate": 0.000474365234375,
      "loss": 3.2311,
      "step": 525
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 0.4403899013996124,
      "learning_rate": 0.00047314453125,
      "loss": 3.1806,
      "step": 550
    },
    {
      "epoch": 0.28076171875,
      "grad_norm": 0.43817126750946045,
      "learning_rate": 0.000471923828125,
      "loss": 3.1208,
      "step": 575
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.44025880098342896,
      "learning_rate": 0.000470703125,
      "loss": 3.0496,
      "step": 600
    },
    {
      "epoch": 0.30517578125,
      "grad_norm": 0.4301396608352661,
      "learning_rate": 0.000469482421875,
      "loss": 2.9598,
      "step": 625
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.4304027855396271,
      "learning_rate": 0.00046826171875000004,
      "loss": 2.8735,
      "step": 650
    },
    {
      "epoch": 0.32958984375,
      "grad_norm": 0.41572847962379456,
      "learning_rate": 0.000467041015625,
      "loss": 2.7737,
      "step": 675
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 0.3972421884536743,
      "learning_rate": 0.00046582031250000003,
      "loss": 2.6765,
      "step": 700
    },
    {
      "epoch": 0.35400390625,
      "grad_norm": 0.3992181122303009,
      "learning_rate": 0.000464599609375,
      "loss": 2.5663,
      "step": 725
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 0.40646591782569885,
      "learning_rate": 0.00046337890625000003,
      "loss": 2.4449,
      "step": 750
    },
    {
      "epoch": 0.37841796875,
      "grad_norm": 0.42394453287124634,
      "learning_rate": 0.000462158203125,
      "loss": 2.3399,
      "step": 775
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.38079574704170227,
      "learning_rate": 0.00046093750000000003,
      "loss": 2.2162,
      "step": 800
    },
    {
      "epoch": 0.40283203125,
      "grad_norm": 0.38148555159568787,
      "learning_rate": 0.000459716796875,
      "loss": 2.0965,
      "step": 825
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.3982091248035431,
      "learning_rate": 0.00045849609375000003,
      "loss": 1.992,
      "step": 850
    },
    {
      "epoch": 0.42724609375,
      "grad_norm": 0.3670308291912079,
      "learning_rate": 0.000457275390625,
      "loss": 1.889,
      "step": 875
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 0.36543411016464233,
      "learning_rate": 0.0004560546875,
      "loss": 1.7759,
      "step": 900
    },
    {
      "epoch": 0.45166015625,
      "grad_norm": 0.35531073808670044,
      "learning_rate": 0.000454833984375,
      "loss": 1.6833,
      "step": 925
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.3717088997364044,
      "learning_rate": 0.00045361328125,
      "loss": 1.5937,
      "step": 950
    },
    {
      "epoch": 0.47607421875,
      "grad_norm": 0.3527492582798004,
      "learning_rate": 0.000452392578125,
      "loss": 1.5216,
      "step": 975
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.35426464676856995,
      "learning_rate": 0.000451171875,
      "loss": 1.455,
      "step": 1000
    },
    {
      "epoch": 0.50048828125,
      "grad_norm": 0.3563218116760254,
      "learning_rate": 0.000449951171875,
      "loss": 1.4022,
      "step": 1025
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.3220364451408386,
      "learning_rate": 0.00044873046875,
      "loss": 1.3514,
      "step": 1050
    },
    {
      "epoch": 0.52490234375,
      "grad_norm": 0.31546729803085327,
      "learning_rate": 0.000447509765625,
      "loss": 1.2938,
      "step": 1075
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.3124413788318634,
      "learning_rate": 0.0004462890625,
      "loss": 1.2471,
      "step": 1100
    },
    {
      "epoch": 0.54931640625,
      "grad_norm": 0.3173137903213501,
      "learning_rate": 0.000445068359375,
      "loss": 1.2031,
      "step": 1125
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.30095043778419495,
      "learning_rate": 0.00044384765625,
      "loss": 1.1552,
      "step": 1150
    },
    {
      "epoch": 0.57373046875,
      "grad_norm": 0.3282438814640045,
      "learning_rate": 0.000442626953125,
      "loss": 1.1164,
      "step": 1175
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.27534639835357666,
      "learning_rate": 0.00044140625,
      "loss": 1.0697,
      "step": 1200
    },
    {
      "epoch": 0.59814453125,
      "grad_norm": 0.276793897151947,
      "learning_rate": 0.000440185546875,
      "loss": 1.0265,
      "step": 1225
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.2659008800983429,
      "learning_rate": 0.00043896484375,
      "loss": 0.9921,
      "step": 1250
    },
    {
      "epoch": 0.62255859375,
      "grad_norm": 0.283071368932724,
      "learning_rate": 0.000437744140625,
      "loss": 0.9661,
      "step": 1275
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.2663941979408264,
      "learning_rate": 0.0004365234375,
      "loss": 0.9251,
      "step": 1300
    },
    {
      "epoch": 0.64697265625,
      "grad_norm": 0.2686481177806854,
      "learning_rate": 0.00043530273437500003,
      "loss": 0.8777,
      "step": 1325
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.26028138399124146,
      "learning_rate": 0.00043408203125,
      "loss": 0.8436,
      "step": 1350
    },
    {
      "epoch": 0.67138671875,
      "grad_norm": 0.2688405513763428,
      "learning_rate": 0.00043286132812500003,
      "loss": 0.8035,
      "step": 1375
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.2572328746318817,
      "learning_rate": 0.000431640625,
      "loss": 0.7608,
      "step": 1400
    },
    {
      "epoch": 0.69580078125,
      "grad_norm": 0.254562646150589,
      "learning_rate": 0.00043041992187500003,
      "loss": 0.7224,
      "step": 1425
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.2479052096605301,
      "learning_rate": 0.00042919921875,
      "loss": 0.7024,
      "step": 1450
    },
    {
      "epoch": 0.72021484375,
      "grad_norm": 0.22872374951839447,
      "learning_rate": 0.00042797851562500003,
      "loss": 0.6762,
      "step": 1475
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.2328176647424698,
      "learning_rate": 0.0004267578125,
      "loss": 0.6543,
      "step": 1500
    },
    {
      "epoch": 0.74462890625,
      "grad_norm": 0.23238638043403625,
      "learning_rate": 0.000425537109375,
      "loss": 0.636,
      "step": 1525
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.23064301908016205,
      "learning_rate": 0.00042431640625,
      "loss": 0.6143,
      "step": 1550
    },
    {
      "epoch": 0.76904296875,
      "grad_norm": 0.22168584167957306,
      "learning_rate": 0.000423095703125,
      "loss": 0.5923,
      "step": 1575
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.20554102957248688,
      "learning_rate": 0.000421875,
      "loss": 0.5661,
      "step": 1600
    },
    {
      "epoch": 0.79345703125,
      "grad_norm": 0.2080335170030594,
      "learning_rate": 0.000420654296875,
      "loss": 0.5465,
      "step": 1625
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.20503458380699158,
      "learning_rate": 0.00041943359375,
      "loss": 0.5156,
      "step": 1650
    },
    {
      "epoch": 0.81787109375,
      "grad_norm": 0.19802738726139069,
      "learning_rate": 0.000418212890625,
      "loss": 0.5011,
      "step": 1675
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.19089707732200623,
      "learning_rate": 0.0004169921875,
      "loss": 0.4862,
      "step": 1700
    },
    {
      "epoch": 0.84228515625,
      "grad_norm": 0.1863044798374176,
      "learning_rate": 0.000415771484375,
      "loss": 0.4671,
      "step": 1725
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.19633081555366516,
      "learning_rate": 0.00041455078125,
      "loss": 0.4534,
      "step": 1750
    },
    {
      "epoch": 0.86669921875,
      "grad_norm": 0.18672513961791992,
      "learning_rate": 0.000413330078125,
      "loss": 0.4458,
      "step": 1775
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.19954454898834229,
      "learning_rate": 0.000412109375,
      "loss": 0.4362,
      "step": 1800
    },
    {
      "epoch": 0.89111328125,
      "grad_norm": 0.19899068772792816,
      "learning_rate": 0.000410888671875,
      "loss": 0.4275,
      "step": 1825
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.19502831995487213,
      "learning_rate": 0.00040966796875,
      "loss": 0.4066,
      "step": 1850
    },
    {
      "epoch": 0.91552734375,
      "grad_norm": 0.16616009175777435,
      "learning_rate": 0.000408447265625,
      "loss": 0.3894,
      "step": 1875
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.18487051129341125,
      "learning_rate": 0.0004072265625,
      "loss": 0.3707,
      "step": 1900
    },
    {
      "epoch": 0.93994140625,
      "grad_norm": 0.17860840260982513,
      "learning_rate": 0.000406005859375,
      "loss": 0.3552,
      "step": 1925
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.15326550602912903,
      "learning_rate": 0.00040478515625000003,
      "loss": 0.3413,
      "step": 1950
    },
    {
      "epoch": 0.96435546875,
      "grad_norm": 0.15343590080738068,
      "learning_rate": 0.000403564453125,
      "loss": 0.3305,
      "step": 1975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.14061835408210754,
      "learning_rate": 0.00040234375000000003,
      "loss": 0.3108,
      "step": 2000
    },
    {
      "epoch": 0.98876953125,
      "grad_norm": 0.15068304538726807,
      "learning_rate": 0.000401123046875,
      "loss": 0.301,
      "step": 2025
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.1407787799835205,
      "learning_rate": 0.00039990234375000003,
      "loss": 0.2938,
      "step": 2050
    },
    {
      "epoch": 1.01318359375,
      "grad_norm": 0.14533323049545288,
      "learning_rate": 0.000398681640625,
      "loss": 0.281,
      "step": 2075
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.1502067744731903,
      "learning_rate": 0.00039746093750000003,
      "loss": 0.2717,
      "step": 2100
    },
    {
      "epoch": 1.03759765625,
      "grad_norm": 0.13692258298397064,
      "learning_rate": 0.000396240234375,
      "loss": 0.2685,
      "step": 2125
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.1383141577243805,
      "learning_rate": 0.00039501953125,
      "loss": 0.2655,
      "step": 2150
    },
    {
      "epoch": 1.06201171875,
      "grad_norm": 0.14107199013233185,
      "learning_rate": 0.000393798828125,
      "loss": 0.2551,
      "step": 2175
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.14415916800498962,
      "learning_rate": 0.000392578125,
      "loss": 0.2492,
      "step": 2200
    },
    {
      "epoch": 1.08642578125,
      "grad_norm": 0.1327083855867386,
      "learning_rate": 0.000391357421875,
      "loss": 0.2422,
      "step": 2225
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.13717208802700043,
      "learning_rate": 0.00039013671875,
      "loss": 0.2361,
      "step": 2250
    },
    {
      "epoch": 1.11083984375,
      "grad_norm": 0.12566278874874115,
      "learning_rate": 0.000388916015625,
      "loss": 0.2326,
      "step": 2275
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.1280563324689865,
      "learning_rate": 0.0003876953125,
      "loss": 0.2312,
      "step": 2300
    },
    {
      "epoch": 1.13525390625,
      "grad_norm": 0.13207033276557922,
      "learning_rate": 0.000386474609375,
      "loss": 0.2227,
      "step": 2325
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.11327952891588211,
      "learning_rate": 0.00038525390625,
      "loss": 0.2138,
      "step": 2350
    },
    {
      "epoch": 1.15966796875,
      "grad_norm": 0.12906979024410248,
      "learning_rate": 0.000384033203125,
      "loss": 0.2135,
      "step": 2375
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.11453904211521149,
      "learning_rate": 0.0003828125,
      "loss": 0.2107,
      "step": 2400
    },
    {
      "epoch": 1.18408203125,
      "grad_norm": 0.12213249504566193,
      "learning_rate": 0.000381591796875,
      "loss": 0.2072,
      "step": 2425
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.11522644013166428,
      "learning_rate": 0.00038037109375,
      "loss": 0.2031,
      "step": 2450
    },
    {
      "epoch": 1.20849609375,
      "grad_norm": 0.10610130429267883,
      "learning_rate": 0.000379150390625,
      "loss": 0.1987,
      "step": 2475
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.11074187606573105,
      "learning_rate": 0.0003779296875,
      "loss": 0.1926,
      "step": 2500
    },
    {
      "epoch": 1.23291015625,
      "grad_norm": 0.10902141034603119,
      "learning_rate": 0.000376708984375,
      "loss": 0.1891,
      "step": 2525
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.10599008202552795,
      "learning_rate": 0.00037548828125,
      "loss": 0.1859,
      "step": 2550
    },
    {
      "epoch": 1.25732421875,
      "grad_norm": 0.10308635234832764,
      "learning_rate": 0.00037426757812500003,
      "loss": 0.1817,
      "step": 2575
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.09872802346944809,
      "learning_rate": 0.000373046875,
      "loss": 0.1787,
      "step": 2600
    },
    {
      "epoch": 1.28173828125,
      "grad_norm": 0.0959843099117279,
      "learning_rate": 0.00037182617187500003,
      "loss": 0.1749,
      "step": 2625
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.10018742084503174,
      "learning_rate": 0.00037060546875,
      "loss": 0.1708,
      "step": 2650
    },
    {
      "epoch": 1.30615234375,
      "grad_norm": 0.09397029131650925,
      "learning_rate": 0.00036938476562500003,
      "loss": 0.1658,
      "step": 2675
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.09040192514657974,
      "learning_rate": 0.0003681640625,
      "loss": 0.1636,
      "step": 2700
    },
    {
      "epoch": 1.33056640625,
      "grad_norm": 0.08900581300258636,
      "learning_rate": 0.00036694335937500003,
      "loss": 0.1603,
      "step": 2725
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.08271434158086777,
      "learning_rate": 0.00036572265625,
      "loss": 0.156,
      "step": 2750
    },
    {
      "epoch": 1.35498046875,
      "grad_norm": 0.08405007421970367,
      "learning_rate": 0.000364501953125,
      "loss": 0.1504,
      "step": 2775
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.07286962121725082,
      "learning_rate": 0.00036328125,
      "loss": 0.1467,
      "step": 2800
    },
    {
      "epoch": 1.37939453125,
      "grad_norm": 0.07830283790826797,
      "learning_rate": 0.000362060546875,
      "loss": 0.14,
      "step": 2825
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.07696489989757538,
      "learning_rate": 0.00036083984375,
      "loss": 0.1362,
      "step": 2850
    },
    {
      "epoch": 1.40380859375,
      "grad_norm": 0.07415279746055603,
      "learning_rate": 0.000359619140625,
      "loss": 0.1342,
      "step": 2875
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.07001757621765137,
      "learning_rate": 0.0003583984375,
      "loss": 0.1312,
      "step": 2900
    },
    {
      "epoch": 1.42822265625,
      "grad_norm": 0.07203922420740128,
      "learning_rate": 0.000357177734375,
      "loss": 0.1304,
      "step": 2925
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.06954029947519302,
      "learning_rate": 0.00035595703125,
      "loss": 0.128,
      "step": 2950
    },
    {
      "epoch": 1.45263671875,
      "grad_norm": 0.07059136033058167,
      "learning_rate": 0.000354736328125,
      "loss": 0.1252,
      "step": 2975
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.06899701803922653,
      "learning_rate": 0.000353515625,
      "loss": 0.1251,
      "step": 3000
    },
    {
      "epoch": 1.47705078125,
      "grad_norm": 0.0666346475481987,
      "learning_rate": 0.000352294921875,
      "loss": 0.1253,
      "step": 3025
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.06732606142759323,
      "learning_rate": 0.00035107421875,
      "loss": 0.1259,
      "step": 3050
    },
    {
      "epoch": 1.50146484375,
      "grad_norm": 0.06740029156208038,
      "learning_rate": 0.000349853515625,
      "loss": 0.1276,
      "step": 3075
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.07671967148780823,
      "learning_rate": 0.0003486328125,
      "loss": 0.1305,
      "step": 3100
    },
    {
      "epoch": 1.52587890625,
      "grad_norm": 0.07633882015943527,
      "learning_rate": 0.000347412109375,
      "loss": 0.1308,
      "step": 3125
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.07554536312818527,
      "learning_rate": 0.00034619140625,
      "loss": 0.1323,
      "step": 3150
    },
    {
      "epoch": 1.55029296875,
      "grad_norm": 0.07312365621328354,
      "learning_rate": 0.000344970703125,
      "loss": 0.1316,
      "step": 3175
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.07617147266864777,
      "learning_rate": 0.00034375,
      "loss": 0.1332,
      "step": 3200
    },
    {
      "epoch": 1.57470703125,
      "grad_norm": 0.08129062503576279,
      "learning_rate": 0.000342529296875,
      "loss": 0.1332,
      "step": 3225
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.0748438760638237,
      "learning_rate": 0.00034130859375000003,
      "loss": 0.1339,
      "step": 3250
    },
    {
      "epoch": 1.59912109375,
      "grad_norm": 0.07429654896259308,
      "learning_rate": 0.000340087890625,
      "loss": 0.1341,
      "step": 3275
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.07731883227825165,
      "learning_rate": 0.00033886718750000003,
      "loss": 0.1349,
      "step": 3300
    },
    {
      "epoch": 1.62353515625,
      "grad_norm": 0.07363834232091904,
      "learning_rate": 0.000337646484375,
      "loss": 0.133,
      "step": 3325
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.07007826864719391,
      "learning_rate": 0.00033642578125000003,
      "loss": 0.1333,
      "step": 3350
    },
    {
      "epoch": 1.64794921875,
      "grad_norm": 0.07555453479290009,
      "learning_rate": 0.000335205078125,
      "loss": 0.1285,
      "step": 3375
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.07585756480693817,
      "learning_rate": 0.000333984375,
      "loss": 0.1241,
      "step": 3400
    },
    {
      "epoch": 1.67236328125,
      "grad_norm": 0.059130601584911346,
      "learning_rate": 0.000332763671875,
      "loss": 0.119,
      "step": 3425
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.061377134174108505,
      "learning_rate": 0.00033154296875,
      "loss": 0.1145,
      "step": 3450
    },
    {
      "epoch": 1.69677734375,
      "grad_norm": 0.05925699695944786,
      "learning_rate": 0.000330322265625,
      "loss": 0.1103,
      "step": 3475
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.05236286297440529,
      "learning_rate": 0.0003291015625,
      "loss": 0.109,
      "step": 3500
    },
    {
      "epoch": 1.72119140625,
      "grad_norm": 0.05815034732222557,
      "learning_rate": 0.000327880859375,
      "loss": 0.1049,
      "step": 3525
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.049529314041137695,
      "learning_rate": 0.00032666015625,
      "loss": 0.1027,
      "step": 3550
    },
    {
      "epoch": 1.74560546875,
      "grad_norm": 0.04997085779905319,
      "learning_rate": 0.000325439453125,
      "loss": 0.103,
      "step": 3575
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.043860722333192825,
      "learning_rate": 0.00032421875,
      "loss": 0.1006,
      "step": 3600
    },
    {
      "epoch": 1.77001953125,
      "grad_norm": 0.048153407871723175,
      "learning_rate": 0.000322998046875,
      "loss": 0.099,
      "step": 3625
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.046833351254463196,
      "learning_rate": 0.00032177734375,
      "loss": 0.0986,
      "step": 3650
    },
    {
      "epoch": 1.79443359375,
      "grad_norm": 0.04663754627108574,
      "learning_rate": 0.000320556640625,
      "loss": 0.099,
      "step": 3675
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.05393289402127266,
      "learning_rate": 0.0003193359375,
      "loss": 0.0982,
      "step": 3700
    },
    {
      "epoch": 1.81884765625,
      "grad_norm": 0.04680147022008896,
      "learning_rate": 0.000318115234375,
      "loss": 0.0969,
      "step": 3725
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.044904548674821854,
      "learning_rate": 0.00031689453125,
      "loss": 0.0961,
      "step": 3750
    },
    {
      "epoch": 1.84326171875,
      "grad_norm": 0.08653516322374344,
      "learning_rate": 0.000315673828125,
      "loss": 0.0941,
      "step": 3775
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.04249005764722824,
      "learning_rate": 0.000314453125,
      "loss": 0.0949,
      "step": 3800
    },
    {
      "epoch": 1.86767578125,
      "grad_norm": 0.05456399917602539,
      "learning_rate": 0.000313232421875,
      "loss": 0.0931,
      "step": 3825
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.04358552768826485,
      "learning_rate": 0.00031201171875,
      "loss": 0.0911,
      "step": 3850
    },
    {
      "epoch": 1.89208984375,
      "grad_norm": 0.04575251042842865,
      "learning_rate": 0.00031079101562500003,
      "loss": 0.0912,
      "step": 3875
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.04384196177124977,
      "learning_rate": 0.0003095703125,
      "loss": 0.091,
      "step": 3900
    },
    {
      "epoch": 1.91650390625,
      "grad_norm": 0.04102759808301926,
      "learning_rate": 0.00030834960937500003,
      "loss": 0.0902,
      "step": 3925
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.046337664127349854,
      "learning_rate": 0.00030712890625,
      "loss": 0.0902,
      "step": 3950
    },
    {
      "epoch": 1.94091796875,
      "grad_norm": 0.04058988019824028,
      "learning_rate": 0.00030590820312500003,
      "loss": 0.0906,
      "step": 3975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.04701392725110054,
      "learning_rate": 0.0003046875,
      "loss": 0.0908,
      "step": 4000
    },
    {
      "epoch": 1.96533203125,
      "grad_norm": 0.04557555541396141,
      "learning_rate": 0.000303466796875,
      "loss": 0.0902,
      "step": 4025
    },
    {
      "epoch": 1.9775390625,
      "grad_norm": 0.0414847731590271,
      "learning_rate": 0.00030224609375,
      "loss": 0.089,
      "step": 4050
    },
    {
      "epoch": 1.98974609375,
      "grad_norm": 0.037424955517053604,
      "learning_rate": 0.000301025390625,
      "loss": 0.0884,
      "step": 4075
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 0.04086415469646454,
      "learning_rate": 0.0002998046875,
      "loss": 0.0869,
      "step": 4100
    },
    {
      "epoch": 2.01416015625,
      "grad_norm": 0.04009965807199478,
      "learning_rate": 0.000298583984375,
      "loss": 0.0877,
      "step": 4125
    },
    {
      "epoch": 2.0263671875,
      "grad_norm": 0.03569091856479645,
      "learning_rate": 0.00029736328125,
      "loss": 0.0861,
      "step": 4150
    },
    {
      "epoch": 2.03857421875,
      "grad_norm": 0.039494551718235016,
      "learning_rate": 0.000296142578125,
      "loss": 0.0855,
      "step": 4175
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.03999131917953491,
      "learning_rate": 0.000294921875,
      "loss": 0.0851,
      "step": 4200
    },
    {
      "epoch": 2.06298828125,
      "grad_norm": 0.03611314296722412,
      "learning_rate": 0.000293701171875,
      "loss": 0.0858,
      "step": 4225
    },
    {
      "epoch": 2.0751953125,
      "grad_norm": 0.05321892350912094,
      "learning_rate": 0.00029248046875,
      "loss": 0.0853,
      "step": 4250
    },
    {
      "epoch": 2.08740234375,
      "grad_norm": 0.042140744626522064,
      "learning_rate": 0.000291259765625,
      "loss": 0.0839,
      "step": 4275
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 0.03954990953207016,
      "learning_rate": 0.0002900390625,
      "loss": 0.0832,
      "step": 4300
    },
    {
      "epoch": 2.11181640625,
      "grad_norm": 0.03531181439757347,
      "learning_rate": 0.000288818359375,
      "loss": 0.0823,
      "step": 4325
    },
    {
      "epoch": 2.1240234375,
      "grad_norm": 0.0491049699485302,
      "learning_rate": 0.00028759765625,
      "loss": 0.0823,
      "step": 4350
    },
    {
      "epoch": 2.13623046875,
      "grad_norm": 0.03957589343190193,
      "learning_rate": 0.000286376953125,
      "loss": 0.0819,
      "step": 4375
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.03945082053542137,
      "learning_rate": 0.00028515625,
      "loss": 0.0817,
      "step": 4400
    },
    {
      "epoch": 2.16064453125,
      "grad_norm": 0.03650183603167534,
      "learning_rate": 0.000283935546875,
      "loss": 0.0814,
      "step": 4425
    },
    {
      "epoch": 2.1728515625,
      "grad_norm": 0.03605959191918373,
      "learning_rate": 0.00028271484375,
      "loss": 0.0817,
      "step": 4450
    },
    {
      "epoch": 2.18505859375,
      "grad_norm": 0.0345168262720108,
      "learning_rate": 0.000281494140625,
      "loss": 0.0811,
      "step": 4475
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 0.03614337742328644,
      "learning_rate": 0.00028027343750000003,
      "loss": 0.0798,
      "step": 4500
    },
    {
      "epoch": 2.20947265625,
      "grad_norm": 0.035642143338918686,
      "learning_rate": 0.000279052734375,
      "loss": 0.0805,
      "step": 4525
    },
    {
      "epoch": 2.2216796875,
      "grad_norm": 0.03364923223853111,
      "learning_rate": 0.00027783203125000003,
      "loss": 0.0809,
      "step": 4550
    },
    {
      "epoch": 2.23388671875,
      "grad_norm": 0.036224886775016785,
      "learning_rate": 0.000276611328125,
      "loss": 0.08,
      "step": 4575
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 0.03420208767056465,
      "learning_rate": 0.00027539062500000003,
      "loss": 0.0795,
      "step": 4600
    },
    {
      "epoch": 2.25830078125,
      "grad_norm": 0.04244865104556084,
      "learning_rate": 0.000274169921875,
      "loss": 0.0793,
      "step": 4625
    },
    {
      "epoch": 2.2705078125,
      "grad_norm": 0.038579411804676056,
      "learning_rate": 0.00027294921875,
      "loss": 0.079,
      "step": 4650
    },
    {
      "epoch": 2.28271484375,
      "grad_norm": 0.03358455002307892,
      "learning_rate": 0.000271728515625,
      "loss": 0.0791,
      "step": 4675
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 0.034806132316589355,
      "learning_rate": 0.0002705078125,
      "loss": 0.0794,
      "step": 4700
    },
    {
      "epoch": 2.30712890625,
      "grad_norm": 0.037629351019859314,
      "learning_rate": 0.000269287109375,
      "loss": 0.0792,
      "step": 4725
    },
    {
      "epoch": 2.3193359375,
      "grad_norm": 0.038300324231386185,
      "learning_rate": 0.00026806640625,
      "loss": 0.0784,
      "step": 4750
    },
    {
      "epoch": 2.33154296875,
      "grad_norm": 0.03291190788149834,
      "learning_rate": 0.000266845703125,
      "loss": 0.0792,
      "step": 4775
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.03392736241221428,
      "learning_rate": 0.000265625,
      "loss": 0.0795,
      "step": 4800
    },
    {
      "epoch": 2.35595703125,
      "grad_norm": 0.03584694862365723,
      "learning_rate": 0.000264404296875,
      "loss": 0.0795,
      "step": 4825
    },
    {
      "epoch": 2.3681640625,
      "grad_norm": 0.04132615029811859,
      "learning_rate": 0.00026318359375,
      "loss": 0.0793,
      "step": 4850
    },
    {
      "epoch": 2.38037109375,
      "grad_norm": 0.03437857702374458,
      "learning_rate": 0.000261962890625,
      "loss": 0.079,
      "step": 4875
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 0.03957613930106163,
      "learning_rate": 0.0002607421875,
      "loss": 0.0794,
      "step": 4900
    },
    {
      "epoch": 2.40478515625,
      "grad_norm": 0.04672690108418465,
      "learning_rate": 0.000259521484375,
      "loss": 0.0792,
      "step": 4925
    },
    {
      "epoch": 2.4169921875,
      "grad_norm": 0.0359778068959713,
      "learning_rate": 0.00025830078125,
      "loss": 0.0789,
      "step": 4950
    },
    {
      "epoch": 2.42919921875,
      "grad_norm": 0.029396722093224525,
      "learning_rate": 0.000257080078125,
      "loss": 0.0777,
      "step": 4975
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.03279935196042061,
      "learning_rate": 0.000255859375,
      "loss": 0.0774,
      "step": 5000
    },
    {
      "epoch": 2.45361328125,
      "grad_norm": 0.031090885400772095,
      "learning_rate": 0.000254638671875,
      "loss": 0.0774,
      "step": 5025
    },
    {
      "epoch": 2.4658203125,
      "grad_norm": 0.04075797647237778,
      "learning_rate": 0.00025341796875,
      "loss": 0.0767,
      "step": 5050
    },
    {
      "epoch": 2.47802734375,
      "grad_norm": 0.03411693498492241,
      "learning_rate": 0.000252197265625,
      "loss": 0.0763,
      "step": 5075
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 0.03860051557421684,
      "learning_rate": 0.0002509765625,
      "loss": 0.0764,
      "step": 5100
    },
    {
      "epoch": 2.50244140625,
      "grad_norm": 0.03218981251120567,
      "learning_rate": 0.00024975585937500003,
      "loss": 0.0762,
      "step": 5125
    },
    {
      "epoch": 2.5146484375,
      "grad_norm": 0.03441958129405975,
      "learning_rate": 0.00024853515625,
      "loss": 0.0758,
      "step": 5150
    },
    {
      "epoch": 2.52685546875,
      "grad_norm": 0.028691697865724564,
      "learning_rate": 0.00024731445312500003,
      "loss": 0.0759,
      "step": 5175
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.03284120187163353,
      "learning_rate": 0.00024609375,
      "loss": 0.0754,
      "step": 5200
    },
    {
      "epoch": 2.55126953125,
      "grad_norm": 0.038508716970682144,
      "learning_rate": 0.00024487304687500003,
      "loss": 0.0756,
      "step": 5225
    },
    {
      "epoch": 2.5634765625,
      "grad_norm": 0.03168872743844986,
      "learning_rate": 0.00024365234375,
      "loss": 0.0755,
      "step": 5250
    },
    {
      "epoch": 2.57568359375,
      "grad_norm": 0.03417612984776497,
      "learning_rate": 0.000242431640625,
      "loss": 0.0753,
      "step": 5275
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 0.03106442466378212,
      "learning_rate": 0.0002412109375,
      "loss": 0.0756,
      "step": 5300
    },
    {
      "epoch": 2.60009765625,
      "grad_norm": 0.03361950442194939,
      "learning_rate": 0.000239990234375,
      "loss": 0.0759,
      "step": 5325
    },
    {
      "epoch": 2.6123046875,
      "grad_norm": 0.035629261285066605,
      "learning_rate": 0.00023876953125,
      "loss": 0.0757,
      "step": 5350
    },
    {
      "epoch": 2.62451171875,
      "grad_norm": 0.03342992067337036,
      "learning_rate": 0.000237548828125,
      "loss": 0.0752,
      "step": 5375
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 0.04789174348115921,
      "learning_rate": 0.000236328125,
      "loss": 0.0752,
      "step": 5400
    },
    {
      "epoch": 2.64892578125,
      "grad_norm": 0.03359038010239601,
      "learning_rate": 0.000235107421875,
      "loss": 0.0749,
      "step": 5425
    },
    {
      "epoch": 2.6611328125,
      "grad_norm": 0.03057328425347805,
      "learning_rate": 0.00023388671875000002,
      "loss": 0.0745,
      "step": 5450
    },
    {
      "epoch": 2.67333984375,
      "grad_norm": 0.027987802401185036,
      "learning_rate": 0.00023266601562500002,
      "loss": 0.0746,
      "step": 5475
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 0.03000960871577263,
      "learning_rate": 0.00023144531250000002,
      "loss": 0.0744,
      "step": 5500
    },
    {
      "epoch": 2.69775390625,
      "grad_norm": 0.03208865225315094,
      "learning_rate": 0.00023022460937500001,
      "loss": 0.0741,
      "step": 5525
    },
    {
      "epoch": 2.7099609375,
      "grad_norm": 0.03171757236123085,
      "learning_rate": 0.00022900390625000001,
      "loss": 0.0738,
      "step": 5550
    },
    {
      "epoch": 2.72216796875,
      "grad_norm": 0.033815812319517136,
      "learning_rate": 0.000227783203125,
      "loss": 0.0739,
      "step": 5575
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.029134128242731094,
      "learning_rate": 0.0002265625,
      "loss": 0.0739,
      "step": 5600
    },
    {
      "epoch": 2.74658203125,
      "grad_norm": 0.034498199820518494,
      "learning_rate": 0.000225341796875,
      "loss": 0.0737,
      "step": 5625
    },
    {
      "epoch": 2.7587890625,
      "grad_norm": 0.02987746149301529,
      "learning_rate": 0.00022412109375,
      "loss": 0.0736,
      "step": 5650
    },
    {
      "epoch": 2.77099609375,
      "grad_norm": 0.030668392777442932,
      "learning_rate": 0.000222900390625,
      "loss": 0.0734,
      "step": 5675
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 0.03708433732390404,
      "learning_rate": 0.0002216796875,
      "loss": 0.0734,
      "step": 5700
    },
    {
      "epoch": 2.79541015625,
      "grad_norm": 0.02960829809308052,
      "learning_rate": 0.000220458984375,
      "loss": 0.0733,
      "step": 5725
    },
    {
      "epoch": 2.8076171875,
      "grad_norm": 0.03151148557662964,
      "learning_rate": 0.00021923828125,
      "loss": 0.0733,
      "step": 5750
    },
    {
      "epoch": 2.81982421875,
      "grad_norm": 0.030901741236448288,
      "learning_rate": 0.000218017578125,
      "loss": 0.0729,
      "step": 5775
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 0.029605546966195107,
      "learning_rate": 0.000216796875,
      "loss": 0.0731,
      "step": 5800
    },
    {
      "epoch": 2.84423828125,
      "grad_norm": 0.030682142823934555,
      "learning_rate": 0.000215576171875,
      "loss": 0.073,
      "step": 5825
    },
    {
      "epoch": 2.8564453125,
      "grad_norm": 0.04256663843989372,
      "learning_rate": 0.00021435546875,
      "loss": 0.0729,
      "step": 5850
    },
    {
      "epoch": 2.86865234375,
      "grad_norm": 0.034853119403123856,
      "learning_rate": 0.000213134765625,
      "loss": 0.0726,
      "step": 5875
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 0.0364716611802578,
      "learning_rate": 0.0002119140625,
      "loss": 0.0729,
      "step": 5900
    },
    {
      "epoch": 2.89306640625,
      "grad_norm": 0.029121186584234238,
      "learning_rate": 0.000210693359375,
      "loss": 0.0727,
      "step": 5925
    },
    {
      "epoch": 2.9052734375,
      "grad_norm": 0.029108121991157532,
      "learning_rate": 0.00020947265625,
      "loss": 0.0726,
      "step": 5950
    },
    {
      "epoch": 2.91748046875,
      "grad_norm": 0.030597634613513947,
      "learning_rate": 0.000208251953125,
      "loss": 0.0725,
      "step": 5975
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.029279261827468872,
      "learning_rate": 0.00020703125,
      "loss": 0.0727,
      "step": 6000
    }
  ],
  "logging_steps": 25,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
