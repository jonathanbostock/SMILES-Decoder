{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.8828125,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.5854522585868835,
      "learning_rate": 0.0004975585937500001,
      "loss": 16.358,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.15268820524215698,
      "learning_rate": 0.0004951171875,
      "loss": 0.5966,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.10899701714515686,
      "learning_rate": 0.0004926757812500001,
      "loss": 0.5669,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.13303729891777039,
      "learning_rate": 0.000490234375,
      "loss": 0.8183,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.1512087732553482,
      "learning_rate": 0.00048779296875,
      "loss": 0.9393,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.16966082155704498,
      "learning_rate": 0.0004853515625,
      "loss": 1.0115,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.17988243699073792,
      "learning_rate": 0.00048291015625,
      "loss": 1.0641,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.18388530611991882,
      "learning_rate": 0.00048046875,
      "loss": 1.0994,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.19158156216144562,
      "learning_rate": 0.00047802734375,
      "loss": 1.116,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.20136067271232605,
      "learning_rate": 0.0004755859375,
      "loss": 1.1277,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 0.20528624951839447,
      "learning_rate": 0.00047314453125,
      "loss": 1.1326,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.21226602792739868,
      "learning_rate": 0.000470703125,
      "loss": 1.1312,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.20222653448581696,
      "learning_rate": 0.00046826171875000004,
      "loss": 1.1244,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 0.2131710797548294,
      "learning_rate": 0.00046582031250000003,
      "loss": 1.1107,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 0.20610317587852478,
      "learning_rate": 0.00046337890625000003,
      "loss": 1.0942,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.20073433220386505,
      "learning_rate": 0.00046093750000000003,
      "loss": 1.074,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.18935878574848175,
      "learning_rate": 0.00045849609375000003,
      "loss": 1.0487,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 0.19012120366096497,
      "learning_rate": 0.0004560546875,
      "loss": 1.0231,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.19095395505428314,
      "learning_rate": 0.00045361328125,
      "loss": 0.9981,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.1745787411928177,
      "learning_rate": 0.000451171875,
      "loss": 0.9664,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.1791153997182846,
      "learning_rate": 0.00044873046875,
      "loss": 0.9358,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.17577365040779114,
      "learning_rate": 0.0004462890625,
      "loss": 0.9049,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.167428120970726,
      "learning_rate": 0.00044384765625,
      "loss": 0.8687,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.16418854892253876,
      "learning_rate": 0.00044140625,
      "loss": 0.8386,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.16467314958572388,
      "learning_rate": 0.00043896484375,
      "loss": 0.8067,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.15295477211475372,
      "learning_rate": 0.0004365234375,
      "loss": 0.7714,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.14986325800418854,
      "learning_rate": 0.00043408203125,
      "loss": 0.7355,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.14420175552368164,
      "learning_rate": 0.000431640625,
      "loss": 0.7011,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.13566073775291443,
      "learning_rate": 0.00042919921875,
      "loss": 0.6719,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.1329873502254486,
      "learning_rate": 0.0004267578125,
      "loss": 0.6382,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.1334587186574936,
      "learning_rate": 0.00042431640625,
      "loss": 0.6065,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.1253957450389862,
      "learning_rate": 0.000421875,
      "loss": 0.5712,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.13090498745441437,
      "learning_rate": 0.00041943359375,
      "loss": 0.5396,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.1243271678686142,
      "learning_rate": 0.0004169921875,
      "loss": 0.511,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.12392134219408035,
      "learning_rate": 0.00041455078125,
      "loss": 0.4787,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.11718609184026718,
      "learning_rate": 0.000412109375,
      "loss": 0.4481,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.11065927147865295,
      "learning_rate": 0.00040966796875,
      "loss": 0.4208,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.11016631871461868,
      "learning_rate": 0.0004072265625,
      "loss": 0.3918,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.10946615785360336,
      "learning_rate": 0.00040478515625000003,
      "loss": 0.3643,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.09850984811782837,
      "learning_rate": 0.00040234375000000003,
      "loss": 0.343,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.10084358602762222,
      "learning_rate": 0.00039990234375000003,
      "loss": 0.3214,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.09600520879030228,
      "learning_rate": 0.00039746093750000003,
      "loss": 0.2983,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.0968308299779892,
      "learning_rate": 0.00039501953125,
      "loss": 0.2754,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.0941547304391861,
      "learning_rate": 0.000392578125,
      "loss": 0.2546,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.09136081486940384,
      "learning_rate": 0.00039013671875,
      "loss": 0.239,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.09124442934989929,
      "learning_rate": 0.0003876953125,
      "loss": 0.2222,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.07929614931344986,
      "learning_rate": 0.00038525390625,
      "loss": 0.2106,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.08242657035589218,
      "learning_rate": 0.0003828125,
      "loss": 0.1963,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.07406534254550934,
      "learning_rate": 0.00038037109375,
      "loss": 0.1847,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.07868527621030807,
      "learning_rate": 0.0003779296875,
      "loss": 0.1728,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.06912849098443985,
      "learning_rate": 0.00037548828125,
      "loss": 0.1631,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.06977448612451553,
      "learning_rate": 0.000373046875,
      "loss": 0.1537,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.06778544932603836,
      "learning_rate": 0.00037060546875,
      "loss": 0.1465,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.06610343605279922,
      "learning_rate": 0.0003681640625,
      "loss": 0.1394,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.06736165285110474,
      "learning_rate": 0.00036572265625,
      "loss": 0.1329,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.06374763697385788,
      "learning_rate": 0.00036328125,
      "loss": 0.1252,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.06135062128305435,
      "learning_rate": 0.00036083984375,
      "loss": 0.1193,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.06181982159614563,
      "learning_rate": 0.0003583984375,
      "loss": 0.111,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.062070172280073166,
      "learning_rate": 0.00035595703125,
      "loss": 0.1063,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.0581425316631794,
      "learning_rate": 0.000353515625,
      "loss": 0.0997,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.05454927682876587,
      "learning_rate": 0.00035107421875,
      "loss": 0.0939,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.05440986901521683,
      "learning_rate": 0.0003486328125,
      "loss": 0.0889,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.047830261290073395,
      "learning_rate": 0.00034619140625,
      "loss": 0.0842,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.04787995666265488,
      "learning_rate": 0.00034375,
      "loss": 0.0807,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.05224420875310898,
      "learning_rate": 0.00034130859375000003,
      "loss": 0.0776,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.05496683344244957,
      "learning_rate": 0.00033886718750000003,
      "loss": 0.075,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.052069272845983505,
      "learning_rate": 0.00033642578125000003,
      "loss": 0.0722,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.04861455038189888,
      "learning_rate": 0.000333984375,
      "loss": 0.0697,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.04029540345072746,
      "learning_rate": 0.00033154296875,
      "loss": 0.0672,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.04173929989337921,
      "learning_rate": 0.0003291015625,
      "loss": 0.0656,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.05799512565135956,
      "learning_rate": 0.00032666015625,
      "loss": 0.0629,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.050124842673540115,
      "learning_rate": 0.00032421875,
      "loss": 0.061,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.03845048323273659,
      "learning_rate": 0.00032177734375,
      "loss": 0.0598,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.05147148668766022,
      "learning_rate": 0.0003193359375,
      "loss": 0.0588,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.03850817307829857,
      "learning_rate": 0.00031689453125,
      "loss": 0.0577,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.04902185872197151,
      "learning_rate": 0.000314453125,
      "loss": 0.057,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.03623533248901367,
      "learning_rate": 0.00031201171875,
      "loss": 0.0561,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.039054177701473236,
      "learning_rate": 0.0003095703125,
      "loss": 0.0552,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.03862152248620987,
      "learning_rate": 0.00030712890625,
      "loss": 0.0541,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.03915011137723923,
      "learning_rate": 0.0003046875,
      "loss": 0.0534,
      "step": 2000
    },
    {
      "epoch": 1.9775390625,
      "grad_norm": 0.037797361612319946,
      "learning_rate": 0.00030224609375,
      "loss": 0.0525,
      "step": 2025
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 0.04616841673851013,
      "learning_rate": 0.0002998046875,
      "loss": 0.0518,
      "step": 2050
    },
    {
      "epoch": 2.0263671875,
      "grad_norm": 0.03516468033194542,
      "learning_rate": 0.00029736328125,
      "loss": 0.051,
      "step": 2075
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.038275666534900665,
      "learning_rate": 0.000294921875,
      "loss": 0.0502,
      "step": 2100
    },
    {
      "epoch": 2.0751953125,
      "grad_norm": 0.03964139521121979,
      "learning_rate": 0.00029248046875,
      "loss": 0.0498,
      "step": 2125
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 0.03376977890729904,
      "learning_rate": 0.0002900390625,
      "loss": 0.049,
      "step": 2150
    },
    {
      "epoch": 2.1240234375,
      "grad_norm": 0.031627681106328964,
      "learning_rate": 0.00028759765625,
      "loss": 0.0483,
      "step": 2175
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.03401333466172218,
      "learning_rate": 0.00028515625,
      "loss": 0.048,
      "step": 2200
    },
    {
      "epoch": 2.1728515625,
      "grad_norm": 0.042032986879348755,
      "learning_rate": 0.00028271484375,
      "loss": 0.0474,
      "step": 2225
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 0.03765462338924408,
      "learning_rate": 0.00028027343750000003,
      "loss": 0.047,
      "step": 2250
    },
    {
      "epoch": 2.2216796875,
      "grad_norm": 0.03462832793593407,
      "learning_rate": 0.00027783203125000003,
      "loss": 0.047,
      "step": 2275
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 0.031352948397397995,
      "learning_rate": 0.00027539062500000003,
      "loss": 0.0462,
      "step": 2300
    },
    {
      "epoch": 2.2705078125,
      "grad_norm": 0.03289768844842911,
      "learning_rate": 0.00027294921875,
      "loss": 0.0457,
      "step": 2325
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 0.028450028970837593,
      "learning_rate": 0.0002705078125,
      "loss": 0.0452,
      "step": 2350
    },
    {
      "epoch": 2.3193359375,
      "grad_norm": 0.03165653720498085,
      "learning_rate": 0.00026806640625,
      "loss": 0.0452,
      "step": 2375
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.03517341613769531,
      "learning_rate": 0.000265625,
      "loss": 0.0449,
      "step": 2400
    },
    {
      "epoch": 2.3681640625,
      "grad_norm": 0.03384038805961609,
      "learning_rate": 0.00026318359375,
      "loss": 0.0445,
      "step": 2425
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 0.03025493398308754,
      "learning_rate": 0.0002607421875,
      "loss": 0.0443,
      "step": 2450
    },
    {
      "epoch": 2.4169921875,
      "grad_norm": 0.029737718403339386,
      "learning_rate": 0.00025830078125,
      "loss": 0.044,
      "step": 2475
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.03978845104575157,
      "learning_rate": 0.000255859375,
      "loss": 0.044,
      "step": 2500
    },
    {
      "epoch": 2.4658203125,
      "grad_norm": 0.02972337417304516,
      "learning_rate": 0.00025341796875,
      "loss": 0.0437,
      "step": 2525
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 0.040176160633563995,
      "learning_rate": 0.0002509765625,
      "loss": 0.0435,
      "step": 2550
    },
    {
      "epoch": 2.5146484375,
      "grad_norm": 0.036715805530548096,
      "learning_rate": 0.00024853515625,
      "loss": 0.0434,
      "step": 2575
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.031898047775030136,
      "learning_rate": 0.00024609375,
      "loss": 0.0432,
      "step": 2600
    },
    {
      "epoch": 2.5634765625,
      "grad_norm": 0.03259057551622391,
      "learning_rate": 0.00024365234375,
      "loss": 0.0429,
      "step": 2625
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 0.050590649247169495,
      "learning_rate": 0.0002412109375,
      "loss": 0.0429,
      "step": 2650
    },
    {
      "epoch": 2.6123046875,
      "grad_norm": 0.036185864359140396,
      "learning_rate": 0.00023876953125,
      "loss": 0.0429,
      "step": 2675
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 0.030696580186486244,
      "learning_rate": 0.000236328125,
      "loss": 0.0426,
      "step": 2700
    },
    {
      "epoch": 2.6611328125,
      "grad_norm": 0.028668135404586792,
      "learning_rate": 0.00023388671875000002,
      "loss": 0.0423,
      "step": 2725
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 0.03119017742574215,
      "learning_rate": 0.00023144531250000002,
      "loss": 0.0422,
      "step": 2750
    },
    {
      "epoch": 2.7099609375,
      "grad_norm": 0.03349817171692848,
      "learning_rate": 0.00022900390625000001,
      "loss": 0.042,
      "step": 2775
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.02827714942395687,
      "learning_rate": 0.0002265625,
      "loss": 0.0419,
      "step": 2800
    },
    {
      "epoch": 2.7587890625,
      "grad_norm": 0.03742709755897522,
      "learning_rate": 0.00022412109375,
      "loss": 0.0418,
      "step": 2825
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 0.035998061299324036,
      "learning_rate": 0.0002216796875,
      "loss": 0.0418,
      "step": 2850
    },
    {
      "epoch": 2.8076171875,
      "grad_norm": 0.029097680002450943,
      "learning_rate": 0.00021923828125,
      "loss": 0.0418,
      "step": 2875
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 0.029395809397101402,
      "learning_rate": 0.000216796875,
      "loss": 0.0416,
      "step": 2900
    },
    {
      "epoch": 2.8564453125,
      "grad_norm": 0.02779688499867916,
      "learning_rate": 0.00021435546875,
      "loss": 0.0416,
      "step": 2925
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 0.030445965006947517,
      "learning_rate": 0.0002119140625,
      "loss": 0.0416,
      "step": 2950
    },
    {
      "epoch": 2.9052734375,
      "grad_norm": 0.027429405599832535,
      "learning_rate": 0.00020947265625,
      "loss": 0.0413,
      "step": 2975
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.027967842295765877,
      "learning_rate": 0.00020703125,
      "loss": 0.0415,
      "step": 3000
    },
    {
      "epoch": 2.9541015625,
      "grad_norm": 0.035614047199487686,
      "learning_rate": 0.00020458984375,
      "loss": 0.0413,
      "step": 3025
    },
    {
      "epoch": 2.978515625,
      "grad_norm": 0.02768748067319393,
      "learning_rate": 0.00020214843750000002,
      "loss": 0.0412,
      "step": 3050
    },
    {
      "epoch": 3.0029296875,
      "grad_norm": 0.030674779787659645,
      "learning_rate": 0.00019970703125000001,
      "loss": 0.0412,
      "step": 3075
    },
    {
      "epoch": 3.02734375,
      "grad_norm": 0.027625935152173042,
      "learning_rate": 0.000197265625,
      "loss": 0.0411,
      "step": 3100
    },
    {
      "epoch": 3.0517578125,
      "grad_norm": 0.03263561427593231,
      "learning_rate": 0.00019482421875,
      "loss": 0.041,
      "step": 3125
    },
    {
      "epoch": 3.076171875,
      "grad_norm": 0.030535293743014336,
      "learning_rate": 0.0001923828125,
      "loss": 0.0408,
      "step": 3150
    },
    {
      "epoch": 3.1005859375,
      "grad_norm": 0.02832183614373207,
      "learning_rate": 0.00018994140625,
      "loss": 0.0409,
      "step": 3175
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.03203945979475975,
      "learning_rate": 0.0001875,
      "loss": 0.0408,
      "step": 3200
    },
    {
      "epoch": 3.1494140625,
      "grad_norm": 0.027662336826324463,
      "learning_rate": 0.00018505859375,
      "loss": 0.0408,
      "step": 3225
    },
    {
      "epoch": 3.173828125,
      "grad_norm": 0.02704174816608429,
      "learning_rate": 0.0001826171875,
      "loss": 0.0407,
      "step": 3250
    },
    {
      "epoch": 3.1982421875,
      "grad_norm": 0.027182508260011673,
      "learning_rate": 0.00018017578125,
      "loss": 0.0406,
      "step": 3275
    },
    {
      "epoch": 3.22265625,
      "grad_norm": 0.029532916843891144,
      "learning_rate": 0.000177734375,
      "loss": 0.0407,
      "step": 3300
    },
    {
      "epoch": 3.2470703125,
      "grad_norm": 0.03145166486501694,
      "learning_rate": 0.00017529296875,
      "loss": 0.0406,
      "step": 3325
    },
    {
      "epoch": 3.271484375,
      "grad_norm": 0.026269633322954178,
      "learning_rate": 0.0001728515625,
      "loss": 0.0407,
      "step": 3350
    },
    {
      "epoch": 3.2958984375,
      "grad_norm": 0.03604942187666893,
      "learning_rate": 0.00017041015625000002,
      "loss": 0.0408,
      "step": 3375
    },
    {
      "epoch": 3.3203125,
      "grad_norm": 0.03209727630019188,
      "learning_rate": 0.00016796875000000001,
      "loss": 0.0405,
      "step": 3400
    },
    {
      "epoch": 3.3447265625,
      "grad_norm": 0.026507679373025894,
      "learning_rate": 0.00016552734375,
      "loss": 0.0406,
      "step": 3425
    },
    {
      "epoch": 3.369140625,
      "grad_norm": 0.032946787774562836,
      "learning_rate": 0.0001630859375,
      "loss": 0.0405,
      "step": 3450
    },
    {
      "epoch": 3.3935546875,
      "grad_norm": 0.027981236577033997,
      "learning_rate": 0.00016064453125,
      "loss": 0.0406,
      "step": 3475
    },
    {
      "epoch": 3.41796875,
      "grad_norm": 0.02677365578711033,
      "learning_rate": 0.000158203125,
      "loss": 0.0405,
      "step": 3500
    },
    {
      "epoch": 3.4423828125,
      "grad_norm": 0.02460654452443123,
      "learning_rate": 0.00015576171875,
      "loss": 0.0404,
      "step": 3525
    },
    {
      "epoch": 3.466796875,
      "grad_norm": 0.031148351728916168,
      "learning_rate": 0.0001533203125,
      "loss": 0.0405,
      "step": 3550
    },
    {
      "epoch": 3.4912109375,
      "grad_norm": 0.02672722563147545,
      "learning_rate": 0.00015087890625,
      "loss": 0.0404,
      "step": 3575
    },
    {
      "epoch": 3.515625,
      "grad_norm": 0.026939552277326584,
      "learning_rate": 0.0001484375,
      "loss": 0.0402,
      "step": 3600
    },
    {
      "epoch": 3.5400390625,
      "grad_norm": 0.022589223459362984,
      "learning_rate": 0.00014599609375,
      "loss": 0.0403,
      "step": 3625
    },
    {
      "epoch": 3.564453125,
      "grad_norm": 0.02579294517636299,
      "learning_rate": 0.0001435546875,
      "loss": 0.0405,
      "step": 3650
    },
    {
      "epoch": 3.5888671875,
      "grad_norm": 0.02839893288910389,
      "learning_rate": 0.00014111328125,
      "loss": 0.0404,
      "step": 3675
    },
    {
      "epoch": 3.61328125,
      "grad_norm": 0.031231500208377838,
      "learning_rate": 0.00013867187500000001,
      "loss": 0.0403,
      "step": 3700
    },
    {
      "epoch": 3.6376953125,
      "grad_norm": 0.0247338879853487,
      "learning_rate": 0.00013623046875,
      "loss": 0.0403,
      "step": 3725
    },
    {
      "epoch": 3.662109375,
      "grad_norm": 0.025845324620604515,
      "learning_rate": 0.0001337890625,
      "loss": 0.0403,
      "step": 3750
    },
    {
      "epoch": 3.6865234375,
      "grad_norm": 0.024631012231111526,
      "learning_rate": 0.00013134765625,
      "loss": 0.0404,
      "step": 3775
    },
    {
      "epoch": 3.7109375,
      "grad_norm": 0.024046916514635086,
      "learning_rate": 0.00012890625,
      "loss": 0.0403,
      "step": 3800
    },
    {
      "epoch": 3.7353515625,
      "grad_norm": 0.025872014462947845,
      "learning_rate": 0.00012646484375,
      "loss": 0.0403,
      "step": 3825
    },
    {
      "epoch": 3.759765625,
      "grad_norm": 0.04435938969254494,
      "learning_rate": 0.0001240234375,
      "loss": 0.0405,
      "step": 3850
    },
    {
      "epoch": 3.7841796875,
      "grad_norm": 0.030728189274668694,
      "learning_rate": 0.00012158203125,
      "loss": 0.0403,
      "step": 3875
    },
    {
      "epoch": 3.80859375,
      "grad_norm": 0.023911889642477036,
      "learning_rate": 0.000119140625,
      "loss": 0.0403,
      "step": 3900
    },
    {
      "epoch": 3.8330078125,
      "grad_norm": 0.028845829889178276,
      "learning_rate": 0.00011669921875000001,
      "loss": 0.0402,
      "step": 3925
    },
    {
      "epoch": 3.857421875,
      "grad_norm": 0.025533402338624,
      "learning_rate": 0.0001142578125,
      "loss": 0.0402,
      "step": 3950
    },
    {
      "epoch": 3.8818359375,
      "grad_norm": 0.03047882951796055,
      "learning_rate": 0.00011181640625,
      "loss": 0.0402,
      "step": 3975
    },
    {
      "epoch": 3.90625,
      "grad_norm": 0.025421734899282455,
      "learning_rate": 0.000109375,
      "loss": 0.0403,
      "step": 4000
    },
    {
      "epoch": 3.9306640625,
      "grad_norm": 0.03294295072555542,
      "learning_rate": 0.00010693359375,
      "loss": 0.0401,
      "step": 4025
    },
    {
      "epoch": 3.955078125,
      "grad_norm": 0.027582848444581032,
      "learning_rate": 0.0001044921875,
      "loss": 0.0402,
      "step": 4050
    },
    {
      "epoch": 3.9794921875,
      "grad_norm": 0.024285785853862762,
      "learning_rate": 0.00010205078125,
      "loss": 0.0401,
      "step": 4075
    },
    {
      "epoch": 4.00390625,
      "grad_norm": 0.03284096345305443,
      "learning_rate": 9.960937500000001e-05,
      "loss": 0.0402,
      "step": 4100
    },
    {
      "epoch": 4.0283203125,
      "grad_norm": 0.026107564568519592,
      "learning_rate": 9.716796875e-05,
      "loss": 0.04,
      "step": 4125
    },
    {
      "epoch": 4.052734375,
      "grad_norm": 0.03336120769381523,
      "learning_rate": 9.47265625e-05,
      "loss": 0.04,
      "step": 4150
    },
    {
      "epoch": 4.0771484375,
      "grad_norm": 0.030096400529146194,
      "learning_rate": 9.228515625e-05,
      "loss": 0.04,
      "step": 4175
    },
    {
      "epoch": 4.1015625,
      "grad_norm": 0.023576540872454643,
      "learning_rate": 8.984375e-05,
      "loss": 0.04,
      "step": 4200
    },
    {
      "epoch": 4.1259765625,
      "grad_norm": 0.026405341923236847,
      "learning_rate": 8.740234375e-05,
      "loss": 0.0401,
      "step": 4225
    },
    {
      "epoch": 4.150390625,
      "grad_norm": 0.024030201137065887,
      "learning_rate": 8.496093750000001e-05,
      "loss": 0.04,
      "step": 4250
    },
    {
      "epoch": 4.1748046875,
      "grad_norm": 0.026349058374762535,
      "learning_rate": 8.251953125e-05,
      "loss": 0.0401,
      "step": 4275
    },
    {
      "epoch": 4.19921875,
      "grad_norm": 0.023532060906291008,
      "learning_rate": 8.0078125e-05,
      "loss": 0.0401,
      "step": 4300
    },
    {
      "epoch": 4.2236328125,
      "grad_norm": 0.024448709562420845,
      "learning_rate": 7.763671875e-05,
      "loss": 0.04,
      "step": 4325
    },
    {
      "epoch": 4.248046875,
      "grad_norm": 0.02800106629729271,
      "learning_rate": 7.51953125e-05,
      "loss": 0.04,
      "step": 4350
    },
    {
      "epoch": 4.2724609375,
      "grad_norm": 0.03888821601867676,
      "learning_rate": 7.275390625e-05,
      "loss": 0.0401,
      "step": 4375
    },
    {
      "epoch": 4.296875,
      "grad_norm": 0.022860659286379814,
      "learning_rate": 7.031250000000001e-05,
      "loss": 0.0401,
      "step": 4400
    },
    {
      "epoch": 4.3212890625,
      "grad_norm": 0.02281850203871727,
      "learning_rate": 6.787109375e-05,
      "loss": 0.0401,
      "step": 4425
    },
    {
      "epoch": 4.345703125,
      "grad_norm": 0.0404062457382679,
      "learning_rate": 6.54296875e-05,
      "loss": 0.0401,
      "step": 4450
    },
    {
      "epoch": 4.3701171875,
      "grad_norm": 0.02325405925512314,
      "learning_rate": 6.298828125e-05,
      "loss": 0.04,
      "step": 4475
    },
    {
      "epoch": 4.39453125,
      "grad_norm": 0.024223938584327698,
      "learning_rate": 6.0546875e-05,
      "loss": 0.04,
      "step": 4500
    },
    {
      "epoch": 4.4189453125,
      "grad_norm": 0.02615336887538433,
      "learning_rate": 5.8105468750000004e-05,
      "loss": 0.0401,
      "step": 4525
    },
    {
      "epoch": 4.443359375,
      "grad_norm": 0.027786757797002792,
      "learning_rate": 5.56640625e-05,
      "loss": 0.0401,
      "step": 4550
    },
    {
      "epoch": 4.4677734375,
      "grad_norm": 0.02722497098147869,
      "learning_rate": 5.322265625e-05,
      "loss": 0.0401,
      "step": 4575
    },
    {
      "epoch": 4.4921875,
      "grad_norm": 0.022412018850445747,
      "learning_rate": 5.0781250000000004e-05,
      "loss": 0.0399,
      "step": 4600
    },
    {
      "epoch": 4.5166015625,
      "grad_norm": 0.024554869160056114,
      "learning_rate": 4.833984375e-05,
      "loss": 0.04,
      "step": 4625
    },
    {
      "epoch": 4.541015625,
      "grad_norm": 0.0232352614402771,
      "learning_rate": 4.58984375e-05,
      "loss": 0.04,
      "step": 4650
    },
    {
      "epoch": 4.5654296875,
      "grad_norm": 0.022426798939704895,
      "learning_rate": 4.345703125e-05,
      "loss": 0.04,
      "step": 4675
    },
    {
      "epoch": 4.58984375,
      "grad_norm": 0.02229292318224907,
      "learning_rate": 4.1015625e-05,
      "loss": 0.0399,
      "step": 4700
    },
    {
      "epoch": 4.6142578125,
      "grad_norm": 0.02799428254365921,
      "learning_rate": 3.857421875e-05,
      "loss": 0.04,
      "step": 4725
    },
    {
      "epoch": 4.638671875,
      "grad_norm": 0.023584747686982155,
      "learning_rate": 3.61328125e-05,
      "loss": 0.0399,
      "step": 4750
    },
    {
      "epoch": 4.6630859375,
      "grad_norm": 0.027867238968610764,
      "learning_rate": 3.369140625e-05,
      "loss": 0.0401,
      "step": 4775
    },
    {
      "epoch": 4.6875,
      "grad_norm": 0.0254130270332098,
      "learning_rate": 3.125e-05,
      "loss": 0.04,
      "step": 4800
    },
    {
      "epoch": 4.7119140625,
      "grad_norm": 0.040774088352918625,
      "learning_rate": 2.8808593750000002e-05,
      "loss": 0.0399,
      "step": 4825
    },
    {
      "epoch": 4.736328125,
      "grad_norm": 0.022673221305012703,
      "learning_rate": 2.63671875e-05,
      "loss": 0.04,
      "step": 4850
    },
    {
      "epoch": 4.7607421875,
      "grad_norm": 0.021295448765158653,
      "learning_rate": 2.392578125e-05,
      "loss": 0.0399,
      "step": 4875
    },
    {
      "epoch": 4.78515625,
      "grad_norm": 0.021876081824302673,
      "learning_rate": 2.1484375e-05,
      "loss": 0.0399,
      "step": 4900
    },
    {
      "epoch": 4.8095703125,
      "grad_norm": 0.022794419899582863,
      "learning_rate": 1.904296875e-05,
      "loss": 0.0399,
      "step": 4925
    },
    {
      "epoch": 4.833984375,
      "grad_norm": 0.03775164484977722,
      "learning_rate": 1.66015625e-05,
      "loss": 0.04,
      "step": 4950
    },
    {
      "epoch": 4.8583984375,
      "grad_norm": 0.022537022829055786,
      "learning_rate": 1.416015625e-05,
      "loss": 0.0398,
      "step": 4975
    },
    {
      "epoch": 4.8828125,
      "grad_norm": 0.024093996733427048,
      "learning_rate": 1.171875e-05,
      "loss": 0.04,
      "step": 5000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
