{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9296875,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.5854522585868835,
      "learning_rate": 0.0004975585937500001,
      "loss": 16.358,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.15268820524215698,
      "learning_rate": 0.0004951171875,
      "loss": 0.5966,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.10899701714515686,
      "learning_rate": 0.0004926757812500001,
      "loss": 0.5669,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.13303729891777039,
      "learning_rate": 0.000490234375,
      "loss": 0.8183,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.1512087732553482,
      "learning_rate": 0.00048779296875,
      "loss": 0.9393,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.16966082155704498,
      "learning_rate": 0.0004853515625,
      "loss": 1.0115,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.17988243699073792,
      "learning_rate": 0.00048291015625,
      "loss": 1.0641,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.18388530611991882,
      "learning_rate": 0.00048046875,
      "loss": 1.0994,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.19158156216144562,
      "learning_rate": 0.00047802734375,
      "loss": 1.116,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.20136067271232605,
      "learning_rate": 0.0004755859375,
      "loss": 1.1277,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 0.20528624951839447,
      "learning_rate": 0.00047314453125,
      "loss": 1.1326,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.21226602792739868,
      "learning_rate": 0.000470703125,
      "loss": 1.1312,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.20222653448581696,
      "learning_rate": 0.00046826171875000004,
      "loss": 1.1244,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 0.2131710797548294,
      "learning_rate": 0.00046582031250000003,
      "loss": 1.1107,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 0.20610317587852478,
      "learning_rate": 0.00046337890625000003,
      "loss": 1.0942,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.20073433220386505,
      "learning_rate": 0.00046093750000000003,
      "loss": 1.074,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.18935878574848175,
      "learning_rate": 0.00045849609375000003,
      "loss": 1.0487,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 0.19012120366096497,
      "learning_rate": 0.0004560546875,
      "loss": 1.0231,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.19095395505428314,
      "learning_rate": 0.00045361328125,
      "loss": 0.9981,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.1745787411928177,
      "learning_rate": 0.000451171875,
      "loss": 0.9664,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.1791153997182846,
      "learning_rate": 0.00044873046875,
      "loss": 0.9358,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.17577365040779114,
      "learning_rate": 0.0004462890625,
      "loss": 0.9049,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.167428120970726,
      "learning_rate": 0.00044384765625,
      "loss": 0.8687,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.16418854892253876,
      "learning_rate": 0.00044140625,
      "loss": 0.8386,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.16467314958572388,
      "learning_rate": 0.00043896484375,
      "loss": 0.8067,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.15295477211475372,
      "learning_rate": 0.0004365234375,
      "loss": 0.7714,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.14986325800418854,
      "learning_rate": 0.00043408203125,
      "loss": 0.7355,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.14420175552368164,
      "learning_rate": 0.000431640625,
      "loss": 0.7011,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.13566073775291443,
      "learning_rate": 0.00042919921875,
      "loss": 0.6719,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.1329873502254486,
      "learning_rate": 0.0004267578125,
      "loss": 0.6382,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.1334587186574936,
      "learning_rate": 0.00042431640625,
      "loss": 0.6065,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.1253957450389862,
      "learning_rate": 0.000421875,
      "loss": 0.5712,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.13090498745441437,
      "learning_rate": 0.00041943359375,
      "loss": 0.5396,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.1243271678686142,
      "learning_rate": 0.0004169921875,
      "loss": 0.511,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.12392134219408035,
      "learning_rate": 0.00041455078125,
      "loss": 0.4787,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.11718609184026718,
      "learning_rate": 0.000412109375,
      "loss": 0.4481,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.11065927147865295,
      "learning_rate": 0.00040966796875,
      "loss": 0.4208,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.11016631871461868,
      "learning_rate": 0.0004072265625,
      "loss": 0.3918,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.10946615785360336,
      "learning_rate": 0.00040478515625000003,
      "loss": 0.3643,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.09850984811782837,
      "learning_rate": 0.00040234375000000003,
      "loss": 0.343,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.10084358602762222,
      "learning_rate": 0.00039990234375000003,
      "loss": 0.3214,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.09600520879030228,
      "learning_rate": 0.00039746093750000003,
      "loss": 0.2983,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.0968308299779892,
      "learning_rate": 0.00039501953125,
      "loss": 0.2754,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.0941547304391861,
      "learning_rate": 0.000392578125,
      "loss": 0.2546,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.09136081486940384,
      "learning_rate": 0.00039013671875,
      "loss": 0.239,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.09124442934989929,
      "learning_rate": 0.0003876953125,
      "loss": 0.2222,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.07929614931344986,
      "learning_rate": 0.00038525390625,
      "loss": 0.2106,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.08242657035589218,
      "learning_rate": 0.0003828125,
      "loss": 0.1963,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.07406534254550934,
      "learning_rate": 0.00038037109375,
      "loss": 0.1847,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.07868527621030807,
      "learning_rate": 0.0003779296875,
      "loss": 0.1728,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.06912849098443985,
      "learning_rate": 0.00037548828125,
      "loss": 0.1631,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.06977448612451553,
      "learning_rate": 0.000373046875,
      "loss": 0.1537,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.06778544932603836,
      "learning_rate": 0.00037060546875,
      "loss": 0.1465,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.06610343605279922,
      "learning_rate": 0.0003681640625,
      "loss": 0.1394,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.06736165285110474,
      "learning_rate": 0.00036572265625,
      "loss": 0.1329,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.06374763697385788,
      "learning_rate": 0.00036328125,
      "loss": 0.1252,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.06135062128305435,
      "learning_rate": 0.00036083984375,
      "loss": 0.1193,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.06181982159614563,
      "learning_rate": 0.0003583984375,
      "loss": 0.111,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.062070172280073166,
      "learning_rate": 0.00035595703125,
      "loss": 0.1063,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.0581425316631794,
      "learning_rate": 0.000353515625,
      "loss": 0.0997,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.05454927682876587,
      "learning_rate": 0.00035107421875,
      "loss": 0.0939,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.05440986901521683,
      "learning_rate": 0.0003486328125,
      "loss": 0.0889,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.047830261290073395,
      "learning_rate": 0.00034619140625,
      "loss": 0.0842,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.04787995666265488,
      "learning_rate": 0.00034375,
      "loss": 0.0807,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.05224420875310898,
      "learning_rate": 0.00034130859375000003,
      "loss": 0.0776,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.05496683344244957,
      "learning_rate": 0.00033886718750000003,
      "loss": 0.075,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.052069272845983505,
      "learning_rate": 0.00033642578125000003,
      "loss": 0.0722,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.04861455038189888,
      "learning_rate": 0.000333984375,
      "loss": 0.0697,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.04029540345072746,
      "learning_rate": 0.00033154296875,
      "loss": 0.0672,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.04173929989337921,
      "learning_rate": 0.0003291015625,
      "loss": 0.0656,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.05799512565135956,
      "learning_rate": 0.00032666015625,
      "loss": 0.0629,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.050124842673540115,
      "learning_rate": 0.00032421875,
      "loss": 0.061,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.03845048323273659,
      "learning_rate": 0.00032177734375,
      "loss": 0.0598,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.05147148668766022,
      "learning_rate": 0.0003193359375,
      "loss": 0.0588,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.03850817307829857,
      "learning_rate": 0.00031689453125,
      "loss": 0.0577,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.04902185872197151,
      "learning_rate": 0.000314453125,
      "loss": 0.057,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.03623533248901367,
      "learning_rate": 0.00031201171875,
      "loss": 0.0561,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.039054177701473236,
      "learning_rate": 0.0003095703125,
      "loss": 0.0552,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.03862152248620987,
      "learning_rate": 0.00030712890625,
      "loss": 0.0541,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.03915011137723923,
      "learning_rate": 0.0003046875,
      "loss": 0.0534,
      "step": 2000
    },
    {
      "epoch": 1.9775390625,
      "grad_norm": 0.037797361612319946,
      "learning_rate": 0.00030224609375,
      "loss": 0.0525,
      "step": 2025
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 0.04616841673851013,
      "learning_rate": 0.0002998046875,
      "loss": 0.0518,
      "step": 2050
    },
    {
      "epoch": 2.0263671875,
      "grad_norm": 0.03516468033194542,
      "learning_rate": 0.00029736328125,
      "loss": 0.051,
      "step": 2075
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.038275666534900665,
      "learning_rate": 0.000294921875,
      "loss": 0.0502,
      "step": 2100
    },
    {
      "epoch": 2.0751953125,
      "grad_norm": 0.03964139521121979,
      "learning_rate": 0.00029248046875,
      "loss": 0.0498,
      "step": 2125
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 0.03376977890729904,
      "learning_rate": 0.0002900390625,
      "loss": 0.049,
      "step": 2150
    },
    {
      "epoch": 2.1240234375,
      "grad_norm": 0.031627681106328964,
      "learning_rate": 0.00028759765625,
      "loss": 0.0483,
      "step": 2175
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.03401333466172218,
      "learning_rate": 0.00028515625,
      "loss": 0.048,
      "step": 2200
    },
    {
      "epoch": 2.1728515625,
      "grad_norm": 0.042032986879348755,
      "learning_rate": 0.00028271484375,
      "loss": 0.0474,
      "step": 2225
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 0.03765462338924408,
      "learning_rate": 0.00028027343750000003,
      "loss": 0.047,
      "step": 2250
    },
    {
      "epoch": 2.2216796875,
      "grad_norm": 0.03462832793593407,
      "learning_rate": 0.00027783203125000003,
      "loss": 0.047,
      "step": 2275
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 0.031352948397397995,
      "learning_rate": 0.00027539062500000003,
      "loss": 0.0462,
      "step": 2300
    },
    {
      "epoch": 2.2705078125,
      "grad_norm": 0.03289768844842911,
      "learning_rate": 0.00027294921875,
      "loss": 0.0457,
      "step": 2325
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 0.028450028970837593,
      "learning_rate": 0.0002705078125,
      "loss": 0.0452,
      "step": 2350
    },
    {
      "epoch": 2.3193359375,
      "grad_norm": 0.03165653720498085,
      "learning_rate": 0.00026806640625,
      "loss": 0.0452,
      "step": 2375
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.03517341613769531,
      "learning_rate": 0.000265625,
      "loss": 0.0449,
      "step": 2400
    },
    {
      "epoch": 2.3681640625,
      "grad_norm": 0.03384038805961609,
      "learning_rate": 0.00026318359375,
      "loss": 0.0445,
      "step": 2425
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 0.03025493398308754,
      "learning_rate": 0.0002607421875,
      "loss": 0.0443,
      "step": 2450
    },
    {
      "epoch": 2.4169921875,
      "grad_norm": 0.029737718403339386,
      "learning_rate": 0.00025830078125,
      "loss": 0.044,
      "step": 2475
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.03978845104575157,
      "learning_rate": 0.000255859375,
      "loss": 0.044,
      "step": 2500
    },
    {
      "epoch": 2.4658203125,
      "grad_norm": 0.02972337417304516,
      "learning_rate": 0.00025341796875,
      "loss": 0.0437,
      "step": 2525
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 0.040176160633563995,
      "learning_rate": 0.0002509765625,
      "loss": 0.0435,
      "step": 2550
    },
    {
      "epoch": 2.5146484375,
      "grad_norm": 0.036715805530548096,
      "learning_rate": 0.00024853515625,
      "loss": 0.0434,
      "step": 2575
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.031898047775030136,
      "learning_rate": 0.00024609375,
      "loss": 0.0432,
      "step": 2600
    },
    {
      "epoch": 2.5634765625,
      "grad_norm": 0.03259057551622391,
      "learning_rate": 0.00024365234375,
      "loss": 0.0429,
      "step": 2625
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 0.050590649247169495,
      "learning_rate": 0.0002412109375,
      "loss": 0.0429,
      "step": 2650
    },
    {
      "epoch": 2.6123046875,
      "grad_norm": 0.036185864359140396,
      "learning_rate": 0.00023876953125,
      "loss": 0.0429,
      "step": 2675
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 0.030696580186486244,
      "learning_rate": 0.000236328125,
      "loss": 0.0426,
      "step": 2700
    },
    {
      "epoch": 2.6611328125,
      "grad_norm": 0.028668135404586792,
      "learning_rate": 0.00023388671875000002,
      "loss": 0.0423,
      "step": 2725
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 0.03119017742574215,
      "learning_rate": 0.00023144531250000002,
      "loss": 0.0422,
      "step": 2750
    },
    {
      "epoch": 2.7099609375,
      "grad_norm": 0.03349817171692848,
      "learning_rate": 0.00022900390625000001,
      "loss": 0.042,
      "step": 2775
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.02827714942395687,
      "learning_rate": 0.0002265625,
      "loss": 0.0419,
      "step": 2800
    },
    {
      "epoch": 2.7587890625,
      "grad_norm": 0.03742709755897522,
      "learning_rate": 0.00022412109375,
      "loss": 0.0418,
      "step": 2825
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 0.035998061299324036,
      "learning_rate": 0.0002216796875,
      "loss": 0.0418,
      "step": 2850
    },
    {
      "epoch": 2.8076171875,
      "grad_norm": 0.029097680002450943,
      "learning_rate": 0.00021923828125,
      "loss": 0.0418,
      "step": 2875
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 0.029395809397101402,
      "learning_rate": 0.000216796875,
      "loss": 0.0416,
      "step": 2900
    },
    {
      "epoch": 2.8564453125,
      "grad_norm": 0.02779688499867916,
      "learning_rate": 0.00021435546875,
      "loss": 0.0416,
      "step": 2925
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 0.030445965006947517,
      "learning_rate": 0.0002119140625,
      "loss": 0.0416,
      "step": 2950
    },
    {
      "epoch": 2.9052734375,
      "grad_norm": 0.027429405599832535,
      "learning_rate": 0.00020947265625,
      "loss": 0.0413,
      "step": 2975
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.027967842295765877,
      "learning_rate": 0.00020703125,
      "loss": 0.0415,
      "step": 3000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
