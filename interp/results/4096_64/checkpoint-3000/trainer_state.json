{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.46484375,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01220703125,
      "grad_norm": 0.768100917339325,
      "learning_rate": 0.000498779296875,
      "loss": 15.8707,
      "step": 25
    },
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.15556682646274567,
      "learning_rate": 0.0004975585937500001,
      "loss": 0.4811,
      "step": 50
    },
    {
      "epoch": 0.03662109375,
      "grad_norm": 0.08003606647253036,
      "learning_rate": 0.000496337890625,
      "loss": 0.3584,
      "step": 75
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 0.0765458270907402,
      "learning_rate": 0.0004951171875,
      "loss": 0.4326,
      "step": 100
    },
    {
      "epoch": 0.06103515625,
      "grad_norm": 0.08090454339981079,
      "learning_rate": 0.000493896484375,
      "loss": 0.483,
      "step": 125
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 0.08631101995706558,
      "learning_rate": 0.0004926757812500001,
      "loss": 0.5083,
      "step": 150
    },
    {
      "epoch": 0.08544921875,
      "grad_norm": 0.0879414901137352,
      "learning_rate": 0.000491455078125,
      "loss": 0.5283,
      "step": 175
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 0.0972672700881958,
      "learning_rate": 0.000490234375,
      "loss": 0.5438,
      "step": 200
    },
    {
      "epoch": 0.10986328125,
      "grad_norm": 0.09690986573696136,
      "learning_rate": 0.000489013671875,
      "loss": 0.5513,
      "step": 225
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 0.10111001133918762,
      "learning_rate": 0.00048779296875,
      "loss": 0.5568,
      "step": 250
    },
    {
      "epoch": 0.13427734375,
      "grad_norm": 0.10112517327070236,
      "learning_rate": 0.000486572265625,
      "loss": 0.555,
      "step": 275
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 0.10390528291463852,
      "learning_rate": 0.0004853515625,
      "loss": 0.5568,
      "step": 300
    },
    {
      "epoch": 0.15869140625,
      "grad_norm": 0.10476253181695938,
      "learning_rate": 0.000484130859375,
      "loss": 0.5521,
      "step": 325
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 0.09982336312532425,
      "learning_rate": 0.00048291015625,
      "loss": 0.5497,
      "step": 350
    },
    {
      "epoch": 0.18310546875,
      "grad_norm": 0.10151772946119308,
      "learning_rate": 0.000481689453125,
      "loss": 0.5423,
      "step": 375
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.09799964725971222,
      "learning_rate": 0.00048046875,
      "loss": 0.5335,
      "step": 400
    },
    {
      "epoch": 0.20751953125,
      "grad_norm": 0.10452569276094437,
      "learning_rate": 0.000479248046875,
      "loss": 0.5226,
      "step": 425
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 0.09275005757808685,
      "learning_rate": 0.00047802734375,
      "loss": 0.5134,
      "step": 450
    },
    {
      "epoch": 0.23193359375,
      "grad_norm": 0.09385619312524796,
      "learning_rate": 0.000476806640625,
      "loss": 0.5016,
      "step": 475
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 0.09283509105443954,
      "learning_rate": 0.0004755859375,
      "loss": 0.4889,
      "step": 500
    },
    {
      "epoch": 0.25634765625,
      "grad_norm": 0.08906935900449753,
      "learning_rate": 0.000474365234375,
      "loss": 0.4726,
      "step": 525
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 0.08339618891477585,
      "learning_rate": 0.00047314453125,
      "loss": 0.457,
      "step": 550
    },
    {
      "epoch": 0.28076171875,
      "grad_norm": 0.08314736187458038,
      "learning_rate": 0.000471923828125,
      "loss": 0.4413,
      "step": 575
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.08276554197072983,
      "learning_rate": 0.000470703125,
      "loss": 0.424,
      "step": 600
    },
    {
      "epoch": 0.30517578125,
      "grad_norm": 0.08289232850074768,
      "learning_rate": 0.000469482421875,
      "loss": 0.4031,
      "step": 625
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 0.08049936592578888,
      "learning_rate": 0.00046826171875000004,
      "loss": 0.3856,
      "step": 650
    },
    {
      "epoch": 0.32958984375,
      "grad_norm": 0.07921646535396576,
      "learning_rate": 0.000467041015625,
      "loss": 0.3648,
      "step": 675
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 0.07907144725322723,
      "learning_rate": 0.00046582031250000003,
      "loss": 0.3455,
      "step": 700
    },
    {
      "epoch": 0.35400390625,
      "grad_norm": 0.07369320094585419,
      "learning_rate": 0.000464599609375,
      "loss": 0.3247,
      "step": 725
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 0.07352422177791595,
      "learning_rate": 0.00046337890625000003,
      "loss": 0.3029,
      "step": 750
    },
    {
      "epoch": 0.37841796875,
      "grad_norm": 0.06767629086971283,
      "learning_rate": 0.000462158203125,
      "loss": 0.2857,
      "step": 775
    },
    {
      "epoch": 0.390625,
      "grad_norm": 0.06941746920347214,
      "learning_rate": 0.00046093750000000003,
      "loss": 0.2641,
      "step": 800
    },
    {
      "epoch": 0.40283203125,
      "grad_norm": 0.06857173144817352,
      "learning_rate": 0.000459716796875,
      "loss": 0.2442,
      "step": 825
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 0.06618550419807434,
      "learning_rate": 0.00045849609375000003,
      "loss": 0.226,
      "step": 850
    },
    {
      "epoch": 0.42724609375,
      "grad_norm": 0.07053276151418686,
      "learning_rate": 0.000457275390625,
      "loss": 0.2094,
      "step": 875
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 0.059461843222379684,
      "learning_rate": 0.0004560546875,
      "loss": 0.1917,
      "step": 900
    },
    {
      "epoch": 0.45166015625,
      "grad_norm": 0.057667359709739685,
      "learning_rate": 0.000454833984375,
      "loss": 0.1783,
      "step": 925
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 0.056638311594724655,
      "learning_rate": 0.00045361328125,
      "loss": 0.1647,
      "step": 950
    },
    {
      "epoch": 0.47607421875,
      "grad_norm": 0.057167600840330124,
      "learning_rate": 0.000452392578125,
      "loss": 0.1526,
      "step": 975
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.054081328213214874,
      "learning_rate": 0.000451171875,
      "loss": 0.1421,
      "step": 1000
    },
    {
      "epoch": 0.50048828125,
      "grad_norm": 0.05246705189347267,
      "learning_rate": 0.000449951171875,
      "loss": 0.1342,
      "step": 1025
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 0.05347311496734619,
      "learning_rate": 0.00044873046875,
      "loss": 0.1269,
      "step": 1050
    },
    {
      "epoch": 0.52490234375,
      "grad_norm": 0.05152884125709534,
      "learning_rate": 0.000447509765625,
      "loss": 0.1201,
      "step": 1075
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 0.050548311322927475,
      "learning_rate": 0.0004462890625,
      "loss": 0.1136,
      "step": 1100
    },
    {
      "epoch": 0.54931640625,
      "grad_norm": 0.04835197329521179,
      "learning_rate": 0.000445068359375,
      "loss": 0.1069,
      "step": 1125
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 0.048597387969493866,
      "learning_rate": 0.00044384765625,
      "loss": 0.1018,
      "step": 1150
    },
    {
      "epoch": 0.57373046875,
      "grad_norm": 0.0453181229531765,
      "learning_rate": 0.000442626953125,
      "loss": 0.0966,
      "step": 1175
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.044155001640319824,
      "learning_rate": 0.00044140625,
      "loss": 0.0914,
      "step": 1200
    },
    {
      "epoch": 0.59814453125,
      "grad_norm": 0.04453407600522041,
      "learning_rate": 0.000440185546875,
      "loss": 0.0871,
      "step": 1225
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 0.04587841033935547,
      "learning_rate": 0.00043896484375,
      "loss": 0.0835,
      "step": 1250
    },
    {
      "epoch": 0.62255859375,
      "grad_norm": 0.041833244264125824,
      "learning_rate": 0.000437744140625,
      "loss": 0.0799,
      "step": 1275
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 0.046214599162340164,
      "learning_rate": 0.0004365234375,
      "loss": 0.076,
      "step": 1300
    },
    {
      "epoch": 0.64697265625,
      "grad_norm": 0.03891298919916153,
      "learning_rate": 0.00043530273437500003,
      "loss": 0.0738,
      "step": 1325
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 0.038931477814912796,
      "learning_rate": 0.00043408203125,
      "loss": 0.0708,
      "step": 1350
    },
    {
      "epoch": 0.67138671875,
      "grad_norm": 0.045183319598436356,
      "learning_rate": 0.00043286132812500003,
      "loss": 0.0683,
      "step": 1375
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 0.037948086857795715,
      "learning_rate": 0.000431640625,
      "loss": 0.0654,
      "step": 1400
    },
    {
      "epoch": 0.69580078125,
      "grad_norm": 0.03838043287396431,
      "learning_rate": 0.00043041992187500003,
      "loss": 0.0628,
      "step": 1425
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 0.03457389771938324,
      "learning_rate": 0.00042919921875,
      "loss": 0.0608,
      "step": 1450
    },
    {
      "epoch": 0.72021484375,
      "grad_norm": 0.04078701138496399,
      "learning_rate": 0.00042797851562500003,
      "loss": 0.0587,
      "step": 1475
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 0.03289162740111351,
      "learning_rate": 0.0004267578125,
      "loss": 0.0569,
      "step": 1500
    },
    {
      "epoch": 0.74462890625,
      "grad_norm": 0.0385429747402668,
      "learning_rate": 0.000425537109375,
      "loss": 0.055,
      "step": 1525
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 0.03455742448568344,
      "learning_rate": 0.00042431640625,
      "loss": 0.0535,
      "step": 1550
    },
    {
      "epoch": 0.76904296875,
      "grad_norm": 0.032590948045253754,
      "learning_rate": 0.000423095703125,
      "loss": 0.0521,
      "step": 1575
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.03588685765862465,
      "learning_rate": 0.000421875,
      "loss": 0.051,
      "step": 1600
    },
    {
      "epoch": 0.79345703125,
      "grad_norm": 0.032848112285137177,
      "learning_rate": 0.000420654296875,
      "loss": 0.0502,
      "step": 1625
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 0.0358990915119648,
      "learning_rate": 0.00041943359375,
      "loss": 0.0493,
      "step": 1650
    },
    {
      "epoch": 0.81787109375,
      "grad_norm": 0.03399088978767395,
      "learning_rate": 0.000418212890625,
      "loss": 0.0488,
      "step": 1675
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 0.029139237478375435,
      "learning_rate": 0.0004169921875,
      "loss": 0.0482,
      "step": 1700
    },
    {
      "epoch": 0.84228515625,
      "grad_norm": 0.028679531067609787,
      "learning_rate": 0.000415771484375,
      "loss": 0.0478,
      "step": 1725
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 0.030130954459309578,
      "learning_rate": 0.00041455078125,
      "loss": 0.0474,
      "step": 1750
    },
    {
      "epoch": 0.86669921875,
      "grad_norm": 0.02945731393992901,
      "learning_rate": 0.000413330078125,
      "loss": 0.0471,
      "step": 1775
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 0.027716975659132004,
      "learning_rate": 0.000412109375,
      "loss": 0.0466,
      "step": 1800
    },
    {
      "epoch": 0.89111328125,
      "grad_norm": 0.028937099501490593,
      "learning_rate": 0.000410888671875,
      "loss": 0.0465,
      "step": 1825
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 0.03127557411789894,
      "learning_rate": 0.00040966796875,
      "loss": 0.0461,
      "step": 1850
    },
    {
      "epoch": 0.91552734375,
      "grad_norm": 0.030221104621887207,
      "learning_rate": 0.000408447265625,
      "loss": 0.0455,
      "step": 1875
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 0.02742650732398033,
      "learning_rate": 0.0004072265625,
      "loss": 0.0453,
      "step": 1900
    },
    {
      "epoch": 0.93994140625,
      "grad_norm": 0.028805872425436974,
      "learning_rate": 0.000406005859375,
      "loss": 0.045,
      "step": 1925
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 0.038779497146606445,
      "learning_rate": 0.00040478515625000003,
      "loss": 0.0448,
      "step": 1950
    },
    {
      "epoch": 0.96435546875,
      "grad_norm": 0.02555529773235321,
      "learning_rate": 0.000403564453125,
      "loss": 0.0447,
      "step": 1975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.026429008692502975,
      "learning_rate": 0.00040234375000000003,
      "loss": 0.0446,
      "step": 2000
    },
    {
      "epoch": 0.98876953125,
      "grad_norm": 0.028563736006617546,
      "learning_rate": 0.000401123046875,
      "loss": 0.0442,
      "step": 2025
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 0.03433351218700409,
      "learning_rate": 0.00039990234375000003,
      "loss": 0.0442,
      "step": 2050
    },
    {
      "epoch": 1.01318359375,
      "grad_norm": 0.0326574482023716,
      "learning_rate": 0.000398681640625,
      "loss": 0.0439,
      "step": 2075
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 0.036238349974155426,
      "learning_rate": 0.00039746093750000003,
      "loss": 0.0436,
      "step": 2100
    },
    {
      "epoch": 1.03759765625,
      "grad_norm": 0.026205627247691154,
      "learning_rate": 0.000396240234375,
      "loss": 0.0433,
      "step": 2125
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 0.026677966117858887,
      "learning_rate": 0.00039501953125,
      "loss": 0.0432,
      "step": 2150
    },
    {
      "epoch": 1.06201171875,
      "grad_norm": 0.029975375160574913,
      "learning_rate": 0.000393798828125,
      "loss": 0.043,
      "step": 2175
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 0.03102281503379345,
      "learning_rate": 0.000392578125,
      "loss": 0.0431,
      "step": 2200
    },
    {
      "epoch": 1.08642578125,
      "grad_norm": 0.02803538739681244,
      "learning_rate": 0.000391357421875,
      "loss": 0.0427,
      "step": 2225
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 0.026506388559937477,
      "learning_rate": 0.00039013671875,
      "loss": 0.0426,
      "step": 2250
    },
    {
      "epoch": 1.11083984375,
      "grad_norm": 0.028008749708533287,
      "learning_rate": 0.000388916015625,
      "loss": 0.0424,
      "step": 2275
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 0.02632603421807289,
      "learning_rate": 0.0003876953125,
      "loss": 0.0424,
      "step": 2300
    },
    {
      "epoch": 1.13525390625,
      "grad_norm": 0.03465180844068527,
      "learning_rate": 0.000386474609375,
      "loss": 0.0422,
      "step": 2325
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 0.028413638472557068,
      "learning_rate": 0.00038525390625,
      "loss": 0.0422,
      "step": 2350
    },
    {
      "epoch": 1.15966796875,
      "grad_norm": 0.028475770726799965,
      "learning_rate": 0.000384033203125,
      "loss": 0.0422,
      "step": 2375
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.03235531598329544,
      "learning_rate": 0.0003828125,
      "loss": 0.0421,
      "step": 2400
    },
    {
      "epoch": 1.18408203125,
      "grad_norm": 0.02724539302289486,
      "learning_rate": 0.000381591796875,
      "loss": 0.0422,
      "step": 2425
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.02655557543039322,
      "learning_rate": 0.00038037109375,
      "loss": 0.0418,
      "step": 2450
    },
    {
      "epoch": 1.20849609375,
      "grad_norm": 0.03319256380200386,
      "learning_rate": 0.000379150390625,
      "loss": 0.0418,
      "step": 2475
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.032252080738544464,
      "learning_rate": 0.0003779296875,
      "loss": 0.0421,
      "step": 2500
    },
    {
      "epoch": 1.23291015625,
      "grad_norm": 0.030129237100481987,
      "learning_rate": 0.000376708984375,
      "loss": 0.0417,
      "step": 2525
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 0.027797294780611992,
      "learning_rate": 0.00037548828125,
      "loss": 0.0414,
      "step": 2550
    },
    {
      "epoch": 1.25732421875,
      "grad_norm": 0.026256339624524117,
      "learning_rate": 0.00037426757812500003,
      "loss": 0.0414,
      "step": 2575
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.032692138105630875,
      "learning_rate": 0.000373046875,
      "loss": 0.0412,
      "step": 2600
    },
    {
      "epoch": 1.28173828125,
      "grad_norm": 0.03010810725390911,
      "learning_rate": 0.00037182617187500003,
      "loss": 0.0412,
      "step": 2625
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.02834588661789894,
      "learning_rate": 0.00037060546875,
      "loss": 0.0412,
      "step": 2650
    },
    {
      "epoch": 1.30615234375,
      "grad_norm": 0.027174176648259163,
      "learning_rate": 0.00036938476562500003,
      "loss": 0.0409,
      "step": 2675
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.027521580457687378,
      "learning_rate": 0.0003681640625,
      "loss": 0.0409,
      "step": 2700
    },
    {
      "epoch": 1.33056640625,
      "grad_norm": 0.027177434414625168,
      "learning_rate": 0.00036694335937500003,
      "loss": 0.0407,
      "step": 2725
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.02844941057264805,
      "learning_rate": 0.00036572265625,
      "loss": 0.0407,
      "step": 2750
    },
    {
      "epoch": 1.35498046875,
      "grad_norm": 0.028658365830779076,
      "learning_rate": 0.000364501953125,
      "loss": 0.0407,
      "step": 2775
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.027598407119512558,
      "learning_rate": 0.00036328125,
      "loss": 0.0405,
      "step": 2800
    },
    {
      "epoch": 1.37939453125,
      "grad_norm": 0.02851065620779991,
      "learning_rate": 0.000362060546875,
      "loss": 0.0405,
      "step": 2825
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.0334969162940979,
      "learning_rate": 0.00036083984375,
      "loss": 0.0403,
      "step": 2850
    },
    {
      "epoch": 1.40380859375,
      "grad_norm": 0.02675042301416397,
      "learning_rate": 0.000359619140625,
      "loss": 0.0403,
      "step": 2875
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.026020070537924767,
      "learning_rate": 0.0003583984375,
      "loss": 0.0402,
      "step": 2900
    },
    {
      "epoch": 1.42822265625,
      "grad_norm": 0.03204963728785515,
      "learning_rate": 0.000357177734375,
      "loss": 0.0401,
      "step": 2925
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.028510097414255142,
      "learning_rate": 0.00035595703125,
      "loss": 0.0399,
      "step": 2950
    },
    {
      "epoch": 1.45263671875,
      "grad_norm": 0.02790098823606968,
      "learning_rate": 0.000354736328125,
      "loss": 0.0397,
      "step": 2975
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.030102834105491638,
      "learning_rate": 0.000353515625,
      "loss": 0.0399,
      "step": 3000
    }
  ],
  "logging_steps": 25,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
