{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.953125,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 2.052504062652588,
      "learning_rate": 0.0004975585937500001,
      "loss": 56.4201,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 1.1347166299819946,
      "learning_rate": 0.0004951171875,
      "loss": 10.227,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 1.897075891494751,
      "learning_rate": 0.0004926757812500001,
      "loss": 12.3813,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 2.5938405990600586,
      "learning_rate": 0.000490234375,
      "loss": 18.3137,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 3.0749738216400146,
      "learning_rate": 0.00048779296875,
      "loss": 22.724,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 3.6397817134857178,
      "learning_rate": 0.0004853515625,
      "loss": 26.2632,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 4.081915378570557,
      "learning_rate": 0.00048291015625,
      "loss": 29.3054,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 4.435105800628662,
      "learning_rate": 0.00048046875,
      "loss": 32.0698,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 4.723056316375732,
      "learning_rate": 0.00047802734375,
      "loss": 34.1392,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 4.986416339874268,
      "learning_rate": 0.0004755859375,
      "loss": 36.092,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 5.331530570983887,
      "learning_rate": 0.00047314453125,
      "loss": 37.6054,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 5.59279727935791,
      "learning_rate": 0.000470703125,
      "loss": 39.0094,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 5.89646577835083,
      "learning_rate": 0.00046826171875000004,
      "loss": 40.0506,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 6.097855091094971,
      "learning_rate": 0.00046582031250000003,
      "loss": 40.8154,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 6.18082332611084,
      "learning_rate": 0.00046337890625000003,
      "loss": 41.4814,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 6.405974388122559,
      "learning_rate": 0.00046093750000000003,
      "loss": 41.9423,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 6.545469284057617,
      "learning_rate": 0.00045849609375000003,
      "loss": 42.1116,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 6.4817938804626465,
      "learning_rate": 0.0004560546875,
      "loss": 42.1541,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 6.7261738777160645,
      "learning_rate": 0.00045361328125,
      "loss": 42.1496,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 6.633119106292725,
      "learning_rate": 0.000451171875,
      "loss": 42.0785,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 6.835946559906006,
      "learning_rate": 0.00044873046875,
      "loss": 41.9359,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 6.936797618865967,
      "learning_rate": 0.0004462890625,
      "loss": 41.5612,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 6.835446834564209,
      "learning_rate": 0.00044384765625,
      "loss": 41.0542,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 6.715896129608154,
      "learning_rate": 0.00044140625,
      "loss": 40.3891,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 6.765377044677734,
      "learning_rate": 0.00043896484375,
      "loss": 40.1052,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 6.655229091644287,
      "learning_rate": 0.0004365234375,
      "loss": 39.0631,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 6.633371353149414,
      "learning_rate": 0.00043408203125,
      "loss": 38.5114,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 6.5968403816223145,
      "learning_rate": 0.000431640625,
      "loss": 37.605,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 6.592091083526611,
      "learning_rate": 0.00042919921875,
      "loss": 36.8111,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 6.321893692016602,
      "learning_rate": 0.0004267578125,
      "loss": 35.9338,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 6.176114082336426,
      "learning_rate": 0.00042431640625,
      "loss": 34.9643,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 6.369580268859863,
      "learning_rate": 0.000421875,
      "loss": 33.9321,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 5.906301498413086,
      "learning_rate": 0.00041943359375,
      "loss": 33.1482,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 6.084192752838135,
      "learning_rate": 0.0004169921875,
      "loss": 32.2677,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 5.805783748626709,
      "learning_rate": 0.00041455078125,
      "loss": 31.2612,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 5.723628044128418,
      "learning_rate": 0.000412109375,
      "loss": 30.2564,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 5.7403740882873535,
      "learning_rate": 0.00040966796875,
      "loss": 29.3074,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 5.679982662200928,
      "learning_rate": 0.0004072265625,
      "loss": 28.3646,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 5.597200870513916,
      "learning_rate": 0.00040478515625000003,
      "loss": 27.2315,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 5.271562099456787,
      "learning_rate": 0.00040234375000000003,
      "loss": 26.3029,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 5.044878959655762,
      "learning_rate": 0.00039990234375000003,
      "loss": 25.299,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 4.77520227432251,
      "learning_rate": 0.00039746093750000003,
      "loss": 24.0108,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 4.72211217880249,
      "learning_rate": 0.00039501953125,
      "loss": 22.5522,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 4.446959972381592,
      "learning_rate": 0.000392578125,
      "loss": 21.1541,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 4.096365451812744,
      "learning_rate": 0.00039013671875,
      "loss": 19.9845,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 4.030325412750244,
      "learning_rate": 0.0003876953125,
      "loss": 18.8592,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 3.7494165897369385,
      "learning_rate": 0.00038525390625,
      "loss": 17.9349,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 3.5364155769348145,
      "learning_rate": 0.0003828125,
      "loss": 17.1405,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 3.424826145172119,
      "learning_rate": 0.00038037109375,
      "loss": 16.4315,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 3.3157401084899902,
      "learning_rate": 0.0003779296875,
      "loss": 15.8542,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 3.1597630977630615,
      "learning_rate": 0.00037548828125,
      "loss": 15.3726,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 3.0645179748535156,
      "learning_rate": 0.000373046875,
      "loss": 15.0183,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 2.9971680641174316,
      "learning_rate": 0.00037060546875,
      "loss": 14.8071,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 2.960193157196045,
      "learning_rate": 0.0003681640625,
      "loss": 14.5499,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 3.084923028945923,
      "learning_rate": 0.00036572265625,
      "loss": 14.1961,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 2.733158588409424,
      "learning_rate": 0.00036328125,
      "loss": 13.8357,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 2.6330597400665283,
      "learning_rate": 0.00036083984375,
      "loss": 13.6129,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 2.6174097061157227,
      "learning_rate": 0.0003583984375,
      "loss": 13.2661,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 2.5560007095336914,
      "learning_rate": 0.00035595703125,
      "loss": 12.8798,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 2.54197359085083,
      "learning_rate": 0.000353515625,
      "loss": 12.6779,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 2.350174903869629,
      "learning_rate": 0.00035107421875,
      "loss": 12.4787,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 2.3258793354034424,
      "learning_rate": 0.0003486328125,
      "loss": 12.1188,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 2.183894395828247,
      "learning_rate": 0.00034619140625,
      "loss": 11.8649,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 2.3298749923706055,
      "learning_rate": 0.00034375,
      "loss": 11.5628,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 2.107189893722534,
      "learning_rate": 0.00034130859375000003,
      "loss": 11.3435,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 2.2224647998809814,
      "learning_rate": 0.00033886718750000003,
      "loss": 11.0298,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 2.1514201164245605,
      "learning_rate": 0.00033642578125000003,
      "loss": 10.6924,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 2.1623661518096924,
      "learning_rate": 0.000333984375,
      "loss": 10.488,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 2.0172548294067383,
      "learning_rate": 0.00033154296875,
      "loss": 10.2413,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 1.985045313835144,
      "learning_rate": 0.0003291015625,
      "loss": 10.0869,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 1.9932464361190796,
      "learning_rate": 0.00032666015625,
      "loss": 9.8161,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 1.9870593547821045,
      "learning_rate": 0.00032421875,
      "loss": 9.5237,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 1.8901381492614746,
      "learning_rate": 0.00032177734375,
      "loss": 9.3171,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 1.8237673044204712,
      "learning_rate": 0.0003193359375,
      "loss": 9.0971,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 1.7609201669692993,
      "learning_rate": 0.00031689453125,
      "loss": 8.9384,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 1.966776967048645,
      "learning_rate": 0.000314453125,
      "loss": 8.9199,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 1.9261269569396973,
      "learning_rate": 0.00031201171875,
      "loss": 8.8379,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 1.7655450105667114,
      "learning_rate": 0.0003095703125,
      "loss": 8.6415,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 1.7698240280151367,
      "learning_rate": 0.00030712890625,
      "loss": 8.4308,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 1.7414158582687378,
      "learning_rate": 0.0003046875,
      "loss": 8.1269,
      "step": 2000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
