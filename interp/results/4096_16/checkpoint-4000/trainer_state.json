{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.90625,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0244140625,
      "grad_norm": 2.052504062652588,
      "learning_rate": 0.0004975585937500001,
      "loss": 56.4201,
      "step": 25
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 1.1347166299819946,
      "learning_rate": 0.0004951171875,
      "loss": 10.227,
      "step": 50
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 1.897075891494751,
      "learning_rate": 0.0004926757812500001,
      "loss": 12.3813,
      "step": 75
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 2.5938405990600586,
      "learning_rate": 0.000490234375,
      "loss": 18.3137,
      "step": 100
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 3.0749738216400146,
      "learning_rate": 0.00048779296875,
      "loss": 22.724,
      "step": 125
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 3.6397817134857178,
      "learning_rate": 0.0004853515625,
      "loss": 26.2632,
      "step": 150
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 4.081915378570557,
      "learning_rate": 0.00048291015625,
      "loss": 29.3054,
      "step": 175
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 4.435105800628662,
      "learning_rate": 0.00048046875,
      "loss": 32.0698,
      "step": 200
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 4.723056316375732,
      "learning_rate": 0.00047802734375,
      "loss": 34.1392,
      "step": 225
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 4.986416339874268,
      "learning_rate": 0.0004755859375,
      "loss": 36.092,
      "step": 250
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 5.331530570983887,
      "learning_rate": 0.00047314453125,
      "loss": 37.6054,
      "step": 275
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 5.59279727935791,
      "learning_rate": 0.000470703125,
      "loss": 39.0094,
      "step": 300
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 5.89646577835083,
      "learning_rate": 0.00046826171875000004,
      "loss": 40.0506,
      "step": 325
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 6.097855091094971,
      "learning_rate": 0.00046582031250000003,
      "loss": 40.8154,
      "step": 350
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 6.18082332611084,
      "learning_rate": 0.00046337890625000003,
      "loss": 41.4814,
      "step": 375
    },
    {
      "epoch": 0.390625,
      "grad_norm": 6.405974388122559,
      "learning_rate": 0.00046093750000000003,
      "loss": 41.9423,
      "step": 400
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 6.545469284057617,
      "learning_rate": 0.00045849609375000003,
      "loss": 42.1116,
      "step": 425
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 6.4817938804626465,
      "learning_rate": 0.0004560546875,
      "loss": 42.1541,
      "step": 450
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 6.7261738777160645,
      "learning_rate": 0.00045361328125,
      "loss": 42.1496,
      "step": 475
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 6.633119106292725,
      "learning_rate": 0.000451171875,
      "loss": 42.0785,
      "step": 500
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 6.835946559906006,
      "learning_rate": 0.00044873046875,
      "loss": 41.9359,
      "step": 525
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 6.936797618865967,
      "learning_rate": 0.0004462890625,
      "loss": 41.5612,
      "step": 550
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 6.835446834564209,
      "learning_rate": 0.00044384765625,
      "loss": 41.0542,
      "step": 575
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 6.715896129608154,
      "learning_rate": 0.00044140625,
      "loss": 40.3891,
      "step": 600
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 6.765377044677734,
      "learning_rate": 0.00043896484375,
      "loss": 40.1052,
      "step": 625
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 6.655229091644287,
      "learning_rate": 0.0004365234375,
      "loss": 39.0631,
      "step": 650
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 6.633371353149414,
      "learning_rate": 0.00043408203125,
      "loss": 38.5114,
      "step": 675
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 6.5968403816223145,
      "learning_rate": 0.000431640625,
      "loss": 37.605,
      "step": 700
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 6.592091083526611,
      "learning_rate": 0.00042919921875,
      "loss": 36.8111,
      "step": 725
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 6.321893692016602,
      "learning_rate": 0.0004267578125,
      "loss": 35.9338,
      "step": 750
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 6.176114082336426,
      "learning_rate": 0.00042431640625,
      "loss": 34.9643,
      "step": 775
    },
    {
      "epoch": 0.78125,
      "grad_norm": 6.369580268859863,
      "learning_rate": 0.000421875,
      "loss": 33.9321,
      "step": 800
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 5.906301498413086,
      "learning_rate": 0.00041943359375,
      "loss": 33.1482,
      "step": 825
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 6.084192752838135,
      "learning_rate": 0.0004169921875,
      "loss": 32.2677,
      "step": 850
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 5.805783748626709,
      "learning_rate": 0.00041455078125,
      "loss": 31.2612,
      "step": 875
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 5.723628044128418,
      "learning_rate": 0.000412109375,
      "loss": 30.2564,
      "step": 900
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 5.7403740882873535,
      "learning_rate": 0.00040966796875,
      "loss": 29.3074,
      "step": 925
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 5.679982662200928,
      "learning_rate": 0.0004072265625,
      "loss": 28.3646,
      "step": 950
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 5.597200870513916,
      "learning_rate": 0.00040478515625000003,
      "loss": 27.2315,
      "step": 975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 5.271562099456787,
      "learning_rate": 0.00040234375000000003,
      "loss": 26.3029,
      "step": 1000
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 5.044878959655762,
      "learning_rate": 0.00039990234375000003,
      "loss": 25.299,
      "step": 1025
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 4.77520227432251,
      "learning_rate": 0.00039746093750000003,
      "loss": 24.0108,
      "step": 1050
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 4.72211217880249,
      "learning_rate": 0.00039501953125,
      "loss": 22.5522,
      "step": 1075
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 4.446959972381592,
      "learning_rate": 0.000392578125,
      "loss": 21.1541,
      "step": 1100
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 4.096365451812744,
      "learning_rate": 0.00039013671875,
      "loss": 19.9845,
      "step": 1125
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 4.030325412750244,
      "learning_rate": 0.0003876953125,
      "loss": 18.8592,
      "step": 1150
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 3.7494165897369385,
      "learning_rate": 0.00038525390625,
      "loss": 17.9349,
      "step": 1175
    },
    {
      "epoch": 1.171875,
      "grad_norm": 3.5364155769348145,
      "learning_rate": 0.0003828125,
      "loss": 17.1405,
      "step": 1200
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 3.424826145172119,
      "learning_rate": 0.00038037109375,
      "loss": 16.4315,
      "step": 1225
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 3.3157401084899902,
      "learning_rate": 0.0003779296875,
      "loss": 15.8542,
      "step": 1250
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 3.1597630977630615,
      "learning_rate": 0.00037548828125,
      "loss": 15.3726,
      "step": 1275
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 3.0645179748535156,
      "learning_rate": 0.000373046875,
      "loss": 15.0183,
      "step": 1300
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 2.9971680641174316,
      "learning_rate": 0.00037060546875,
      "loss": 14.8071,
      "step": 1325
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 2.960193157196045,
      "learning_rate": 0.0003681640625,
      "loss": 14.5499,
      "step": 1350
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 3.084923028945923,
      "learning_rate": 0.00036572265625,
      "loss": 14.1961,
      "step": 1375
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 2.733158588409424,
      "learning_rate": 0.00036328125,
      "loss": 13.8357,
      "step": 1400
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 2.6330597400665283,
      "learning_rate": 0.00036083984375,
      "loss": 13.6129,
      "step": 1425
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 2.6174097061157227,
      "learning_rate": 0.0003583984375,
      "loss": 13.2661,
      "step": 1450
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 2.5560007095336914,
      "learning_rate": 0.00035595703125,
      "loss": 12.8798,
      "step": 1475
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 2.54197359085083,
      "learning_rate": 0.000353515625,
      "loss": 12.6779,
      "step": 1500
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 2.350174903869629,
      "learning_rate": 0.00035107421875,
      "loss": 12.4787,
      "step": 1525
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 2.3258793354034424,
      "learning_rate": 0.0003486328125,
      "loss": 12.1188,
      "step": 1550
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 2.183894395828247,
      "learning_rate": 0.00034619140625,
      "loss": 11.8649,
      "step": 1575
    },
    {
      "epoch": 1.5625,
      "grad_norm": 2.3298749923706055,
      "learning_rate": 0.00034375,
      "loss": 11.5628,
      "step": 1600
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 2.107189893722534,
      "learning_rate": 0.00034130859375000003,
      "loss": 11.3435,
      "step": 1625
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 2.2224647998809814,
      "learning_rate": 0.00033886718750000003,
      "loss": 11.0298,
      "step": 1650
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 2.1514201164245605,
      "learning_rate": 0.00033642578125000003,
      "loss": 10.6924,
      "step": 1675
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 2.1623661518096924,
      "learning_rate": 0.000333984375,
      "loss": 10.488,
      "step": 1700
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 2.0172548294067383,
      "learning_rate": 0.00033154296875,
      "loss": 10.2413,
      "step": 1725
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 1.985045313835144,
      "learning_rate": 0.0003291015625,
      "loss": 10.0869,
      "step": 1750
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 1.9932464361190796,
      "learning_rate": 0.00032666015625,
      "loss": 9.8161,
      "step": 1775
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 1.9870593547821045,
      "learning_rate": 0.00032421875,
      "loss": 9.5237,
      "step": 1800
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 1.8901381492614746,
      "learning_rate": 0.00032177734375,
      "loss": 9.3171,
      "step": 1825
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 1.8237673044204712,
      "learning_rate": 0.0003193359375,
      "loss": 9.0971,
      "step": 1850
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 1.7609201669692993,
      "learning_rate": 0.00031689453125,
      "loss": 8.9384,
      "step": 1875
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 1.966776967048645,
      "learning_rate": 0.000314453125,
      "loss": 8.9199,
      "step": 1900
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 1.9261269569396973,
      "learning_rate": 0.00031201171875,
      "loss": 8.8379,
      "step": 1925
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 1.7655450105667114,
      "learning_rate": 0.0003095703125,
      "loss": 8.6415,
      "step": 1950
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 1.7698240280151367,
      "learning_rate": 0.00030712890625,
      "loss": 8.4308,
      "step": 1975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 1.7414158582687378,
      "learning_rate": 0.0003046875,
      "loss": 8.1269,
      "step": 2000
    },
    {
      "epoch": 1.9775390625,
      "grad_norm": 1.7487125396728516,
      "learning_rate": 0.00030224609375,
      "loss": 7.9077,
      "step": 2025
    },
    {
      "epoch": 2.001953125,
      "grad_norm": 1.747498869895935,
      "learning_rate": 0.0002998046875,
      "loss": 7.668,
      "step": 2050
    },
    {
      "epoch": 2.0263671875,
      "grad_norm": 1.612326741218567,
      "learning_rate": 0.00029736328125,
      "loss": 7.4429,
      "step": 2075
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 1.5837218761444092,
      "learning_rate": 0.000294921875,
      "loss": 7.3102,
      "step": 2100
    },
    {
      "epoch": 2.0751953125,
      "grad_norm": 1.5365400314331055,
      "learning_rate": 0.00029248046875,
      "loss": 7.2022,
      "step": 2125
    },
    {
      "epoch": 2.099609375,
      "grad_norm": 1.720461130142212,
      "learning_rate": 0.0002900390625,
      "loss": 7.1607,
      "step": 2150
    },
    {
      "epoch": 2.1240234375,
      "grad_norm": 1.6186975240707397,
      "learning_rate": 0.00028759765625,
      "loss": 7.1946,
      "step": 2175
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 1.7159444093704224,
      "learning_rate": 0.00028515625,
      "loss": 7.3145,
      "step": 2200
    },
    {
      "epoch": 2.1728515625,
      "grad_norm": 1.6742533445358276,
      "learning_rate": 0.00028271484375,
      "loss": 7.428,
      "step": 2225
    },
    {
      "epoch": 2.197265625,
      "grad_norm": 1.6259171962738037,
      "learning_rate": 0.00028027343750000003,
      "loss": 7.4866,
      "step": 2250
    },
    {
      "epoch": 2.2216796875,
      "grad_norm": 1.7720311880111694,
      "learning_rate": 0.00027783203125000003,
      "loss": 7.5108,
      "step": 2275
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 1.674267292022705,
      "learning_rate": 0.00027539062500000003,
      "loss": 7.4993,
      "step": 2300
    },
    {
      "epoch": 2.2705078125,
      "grad_norm": 1.721929669380188,
      "learning_rate": 0.00027294921875,
      "loss": 7.4035,
      "step": 2325
    },
    {
      "epoch": 2.294921875,
      "grad_norm": 1.6088604927062988,
      "learning_rate": 0.0002705078125,
      "loss": 7.2973,
      "step": 2350
    },
    {
      "epoch": 2.3193359375,
      "grad_norm": 1.5106667280197144,
      "learning_rate": 0.00026806640625,
      "loss": 7.1742,
      "step": 2375
    },
    {
      "epoch": 2.34375,
      "grad_norm": 1.5679570436477661,
      "learning_rate": 0.000265625,
      "loss": 7.0347,
      "step": 2400
    },
    {
      "epoch": 2.3681640625,
      "grad_norm": 1.5278571844100952,
      "learning_rate": 0.00026318359375,
      "loss": 6.94,
      "step": 2425
    },
    {
      "epoch": 2.392578125,
      "grad_norm": 1.3396284580230713,
      "learning_rate": 0.0002607421875,
      "loss": 6.7942,
      "step": 2450
    },
    {
      "epoch": 2.4169921875,
      "grad_norm": 1.5294636487960815,
      "learning_rate": 0.00025830078125,
      "loss": 6.6676,
      "step": 2475
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 1.4765774011611938,
      "learning_rate": 0.000255859375,
      "loss": 6.503,
      "step": 2500
    },
    {
      "epoch": 2.4658203125,
      "grad_norm": 1.506360650062561,
      "learning_rate": 0.00025341796875,
      "loss": 6.3975,
      "step": 2525
    },
    {
      "epoch": 2.490234375,
      "grad_norm": 1.4414886236190796,
      "learning_rate": 0.0002509765625,
      "loss": 6.3633,
      "step": 2550
    },
    {
      "epoch": 2.5146484375,
      "grad_norm": 1.66427743434906,
      "learning_rate": 0.00024853515625,
      "loss": 6.2981,
      "step": 2575
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 1.5051841735839844,
      "learning_rate": 0.00024609375,
      "loss": 6.2362,
      "step": 2600
    },
    {
      "epoch": 2.5634765625,
      "grad_norm": 1.4037818908691406,
      "learning_rate": 0.00024365234375,
      "loss": 6.1209,
      "step": 2625
    },
    {
      "epoch": 2.587890625,
      "grad_norm": 1.3073922395706177,
      "learning_rate": 0.0002412109375,
      "loss": 5.982,
      "step": 2650
    },
    {
      "epoch": 2.6123046875,
      "grad_norm": 1.3952288627624512,
      "learning_rate": 0.00023876953125,
      "loss": 5.8541,
      "step": 2675
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 1.3575422763824463,
      "learning_rate": 0.000236328125,
      "loss": 5.7164,
      "step": 2700
    },
    {
      "epoch": 2.6611328125,
      "grad_norm": 1.3604438304901123,
      "learning_rate": 0.00023388671875000002,
      "loss": 5.5999,
      "step": 2725
    },
    {
      "epoch": 2.685546875,
      "grad_norm": 1.3544994592666626,
      "learning_rate": 0.00023144531250000002,
      "loss": 5.4958,
      "step": 2750
    },
    {
      "epoch": 2.7099609375,
      "grad_norm": 1.3088446855545044,
      "learning_rate": 0.00022900390625000001,
      "loss": 5.4457,
      "step": 2775
    },
    {
      "epoch": 2.734375,
      "grad_norm": 1.4281615018844604,
      "learning_rate": 0.0002265625,
      "loss": 5.37,
      "step": 2800
    },
    {
      "epoch": 2.7587890625,
      "grad_norm": 1.2615424394607544,
      "learning_rate": 0.00022412109375,
      "loss": 5.303,
      "step": 2825
    },
    {
      "epoch": 2.783203125,
      "grad_norm": 1.2773237228393555,
      "learning_rate": 0.0002216796875,
      "loss": 5.1872,
      "step": 2850
    },
    {
      "epoch": 2.8076171875,
      "grad_norm": 1.181366205215454,
      "learning_rate": 0.00021923828125,
      "loss": 5.1187,
      "step": 2875
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 1.3125250339508057,
      "learning_rate": 0.000216796875,
      "loss": 5.0173,
      "step": 2900
    },
    {
      "epoch": 2.8564453125,
      "grad_norm": 1.147847294807434,
      "learning_rate": 0.00021435546875,
      "loss": 4.9696,
      "step": 2925
    },
    {
      "epoch": 2.880859375,
      "grad_norm": 1.112104058265686,
      "learning_rate": 0.0002119140625,
      "loss": 4.889,
      "step": 2950
    },
    {
      "epoch": 2.9052734375,
      "grad_norm": 1.2320441007614136,
      "learning_rate": 0.00020947265625,
      "loss": 4.8414,
      "step": 2975
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 1.116281270980835,
      "learning_rate": 0.00020703125,
      "loss": 4.7814,
      "step": 3000
    },
    {
      "epoch": 2.9541015625,
      "grad_norm": 1.1420849561691284,
      "learning_rate": 0.00020458984375,
      "loss": 4.6723,
      "step": 3025
    },
    {
      "epoch": 2.978515625,
      "grad_norm": 1.1601437330245972,
      "learning_rate": 0.00020214843750000002,
      "loss": 4.6273,
      "step": 3050
    },
    {
      "epoch": 3.0029296875,
      "grad_norm": 1.126220703125,
      "learning_rate": 0.00019970703125000001,
      "loss": 4.5601,
      "step": 3075
    },
    {
      "epoch": 3.02734375,
      "grad_norm": 1.0962380170822144,
      "learning_rate": 0.000197265625,
      "loss": 4.5089,
      "step": 3100
    },
    {
      "epoch": 3.0517578125,
      "grad_norm": 1.0885146856307983,
      "learning_rate": 0.00019482421875,
      "loss": 4.4332,
      "step": 3125
    },
    {
      "epoch": 3.076171875,
      "grad_norm": 1.0331013202667236,
      "learning_rate": 0.0001923828125,
      "loss": 4.4021,
      "step": 3150
    },
    {
      "epoch": 3.1005859375,
      "grad_norm": 1.1653155088424683,
      "learning_rate": 0.00018994140625,
      "loss": 4.3515,
      "step": 3175
    },
    {
      "epoch": 3.125,
      "grad_norm": 1.0676296949386597,
      "learning_rate": 0.0001875,
      "loss": 4.2975,
      "step": 3200
    },
    {
      "epoch": 3.1494140625,
      "grad_norm": 1.190609097480774,
      "learning_rate": 0.00018505859375,
      "loss": 4.2995,
      "step": 3225
    },
    {
      "epoch": 3.173828125,
      "grad_norm": 1.1001722812652588,
      "learning_rate": 0.0001826171875,
      "loss": 4.2609,
      "step": 3250
    },
    {
      "epoch": 3.1982421875,
      "grad_norm": 1.0977802276611328,
      "learning_rate": 0.00018017578125,
      "loss": 4.2631,
      "step": 3275
    },
    {
      "epoch": 3.22265625,
      "grad_norm": 1.1211012601852417,
      "learning_rate": 0.000177734375,
      "loss": 4.2688,
      "step": 3300
    },
    {
      "epoch": 3.2470703125,
      "grad_norm": 1.130021095275879,
      "learning_rate": 0.00017529296875,
      "loss": 4.2605,
      "step": 3325
    },
    {
      "epoch": 3.271484375,
      "grad_norm": 1.046713948249817,
      "learning_rate": 0.0001728515625,
      "loss": 4.2915,
      "step": 3350
    },
    {
      "epoch": 3.2958984375,
      "grad_norm": 1.1881442070007324,
      "learning_rate": 0.00017041015625000002,
      "loss": 4.2977,
      "step": 3375
    },
    {
      "epoch": 3.3203125,
      "grad_norm": 1.096346139907837,
      "learning_rate": 0.00016796875000000001,
      "loss": 4.2622,
      "step": 3400
    },
    {
      "epoch": 3.3447265625,
      "grad_norm": 1.141291856765747,
      "learning_rate": 0.00016552734375,
      "loss": 4.2612,
      "step": 3425
    },
    {
      "epoch": 3.369140625,
      "grad_norm": 1.0046696662902832,
      "learning_rate": 0.0001630859375,
      "loss": 4.2337,
      "step": 3450
    },
    {
      "epoch": 3.3935546875,
      "grad_norm": 1.0523370504379272,
      "learning_rate": 0.00016064453125,
      "loss": 4.2334,
      "step": 3475
    },
    {
      "epoch": 3.41796875,
      "grad_norm": 1.018011212348938,
      "learning_rate": 0.000158203125,
      "loss": 4.2327,
      "step": 3500
    },
    {
      "epoch": 3.4423828125,
      "grad_norm": 1.060004711151123,
      "learning_rate": 0.00015576171875,
      "loss": 4.2233,
      "step": 3525
    },
    {
      "epoch": 3.466796875,
      "grad_norm": 1.0619953870773315,
      "learning_rate": 0.0001533203125,
      "loss": 4.2452,
      "step": 3550
    },
    {
      "epoch": 3.4912109375,
      "grad_norm": 1.0904632806777954,
      "learning_rate": 0.00015087890625,
      "loss": 4.2581,
      "step": 3575
    },
    {
      "epoch": 3.515625,
      "grad_norm": 1.1524664163589478,
      "learning_rate": 0.0001484375,
      "loss": 4.2715,
      "step": 3600
    },
    {
      "epoch": 3.5400390625,
      "grad_norm": 1.050889253616333,
      "learning_rate": 0.00014599609375,
      "loss": 4.3196,
      "step": 3625
    },
    {
      "epoch": 3.564453125,
      "grad_norm": 1.0847545862197876,
      "learning_rate": 0.0001435546875,
      "loss": 4.3284,
      "step": 3650
    },
    {
      "epoch": 3.5888671875,
      "grad_norm": 1.065430998802185,
      "learning_rate": 0.00014111328125,
      "loss": 4.3732,
      "step": 3675
    },
    {
      "epoch": 3.61328125,
      "grad_norm": 1.0982638597488403,
      "learning_rate": 0.00013867187500000001,
      "loss": 4.373,
      "step": 3700
    },
    {
      "epoch": 3.6376953125,
      "grad_norm": 1.1314177513122559,
      "learning_rate": 0.00013623046875,
      "loss": 4.3948,
      "step": 3725
    },
    {
      "epoch": 3.662109375,
      "grad_norm": 1.2266507148742676,
      "learning_rate": 0.0001337890625,
      "loss": 4.3915,
      "step": 3750
    },
    {
      "epoch": 3.6865234375,
      "grad_norm": 1.1960389614105225,
      "learning_rate": 0.00013134765625,
      "loss": 4.4105,
      "step": 3775
    },
    {
      "epoch": 3.7109375,
      "grad_norm": 1.1429020166397095,
      "learning_rate": 0.00012890625,
      "loss": 4.4058,
      "step": 3800
    },
    {
      "epoch": 3.7353515625,
      "grad_norm": 1.1546238660812378,
      "learning_rate": 0.00012646484375,
      "loss": 4.3746,
      "step": 3825
    },
    {
      "epoch": 3.759765625,
      "grad_norm": 1.1264214515686035,
      "learning_rate": 0.0001240234375,
      "loss": 4.4023,
      "step": 3850
    },
    {
      "epoch": 3.7841796875,
      "grad_norm": 1.084043025970459,
      "learning_rate": 0.00012158203125,
      "loss": 4.392,
      "step": 3875
    },
    {
      "epoch": 3.80859375,
      "grad_norm": 1.024262547492981,
      "learning_rate": 0.000119140625,
      "loss": 4.3726,
      "step": 3900
    },
    {
      "epoch": 3.8330078125,
      "grad_norm": 1.0795013904571533,
      "learning_rate": 0.00011669921875000001,
      "loss": 4.3301,
      "step": 3925
    },
    {
      "epoch": 3.857421875,
      "grad_norm": 1.0725760459899902,
      "learning_rate": 0.0001142578125,
      "loss": 4.3391,
      "step": 3950
    },
    {
      "epoch": 3.8818359375,
      "grad_norm": 1.0686101913452148,
      "learning_rate": 0.00011181640625,
      "loss": 4.3219,
      "step": 3975
    },
    {
      "epoch": 3.90625,
      "grad_norm": 1.072229266166687,
      "learning_rate": 0.000109375,
      "loss": 4.3105,
      "step": 4000
    }
  ],
  "logging_steps": 25,
  "max_steps": 5120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
