{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.953125,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01220703125,
      "grad_norm": 1.3326678276062012,
      "learning_rate": 0.000498779296875,
      "loss": 38.361,
      "step": 25
    },
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.5136749148368835,
      "learning_rate": 0.0004975585937500001,
      "loss": 4.998,
      "step": 50
    },
    {
      "epoch": 0.03662109375,
      "grad_norm": 0.8903566002845764,
      "learning_rate": 0.000496337890625,
      "loss": 5.3903,
      "step": 75
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 1.1837118864059448,
      "learning_rate": 0.0004951171875,
      "loss": 8.5075,
      "step": 100
    },
    {
      "epoch": 0.06103515625,
      "grad_norm": 1.457871913909912,
      "learning_rate": 0.000493896484375,
      "loss": 10.4259,
      "step": 125
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 1.6656646728515625,
      "learning_rate": 0.0004926757812500001,
      "loss": 11.7846,
      "step": 150
    },
    {
      "epoch": 0.08544921875,
      "grad_norm": 1.7859668731689453,
      "learning_rate": 0.000491455078125,
      "loss": 13.1132,
      "step": 175
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 2.127591133117676,
      "learning_rate": 0.000490234375,
      "loss": 14.2343,
      "step": 200
    },
    {
      "epoch": 0.10986328125,
      "grad_norm": 2.1554505825042725,
      "learning_rate": 0.000489013671875,
      "loss": 15.1889,
      "step": 225
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 2.2897493839263916,
      "learning_rate": 0.00048779296875,
      "loss": 16.034,
      "step": 250
    },
    {
      "epoch": 0.13427734375,
      "grad_norm": 2.413649320602417,
      "learning_rate": 0.000486572265625,
      "loss": 16.7147,
      "step": 275
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 2.4778943061828613,
      "learning_rate": 0.0004853515625,
      "loss": 17.3756,
      "step": 300
    },
    {
      "epoch": 0.15869140625,
      "grad_norm": 2.5457561016082764,
      "learning_rate": 0.000484130859375,
      "loss": 17.86,
      "step": 325
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 2.7168874740600586,
      "learning_rate": 0.00048291015625,
      "loss": 18.2123,
      "step": 350
    },
    {
      "epoch": 0.18310546875,
      "grad_norm": 2.7220711708068848,
      "learning_rate": 0.000481689453125,
      "loss": 18.6073,
      "step": 375
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 2.793246030807495,
      "learning_rate": 0.00048046875,
      "loss": 18.8434,
      "step": 400
    },
    {
      "epoch": 0.20751953125,
      "grad_norm": 2.8063738346099854,
      "learning_rate": 0.000479248046875,
      "loss": 18.9409,
      "step": 425
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 2.932191848754883,
      "learning_rate": 0.00047802734375,
      "loss": 19.0882,
      "step": 450
    },
    {
      "epoch": 0.23193359375,
      "grad_norm": 2.891045570373535,
      "learning_rate": 0.000476806640625,
      "loss": 18.9871,
      "step": 475
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 2.7938005924224854,
      "learning_rate": 0.0004755859375,
      "loss": 18.9607,
      "step": 500
    },
    {
      "epoch": 0.25634765625,
      "grad_norm": 2.7559051513671875,
      "learning_rate": 0.000474365234375,
      "loss": 18.8081,
      "step": 525
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 2.8782355785369873,
      "learning_rate": 0.00047314453125,
      "loss": 18.5983,
      "step": 550
    },
    {
      "epoch": 0.28076171875,
      "grad_norm": 2.785182237625122,
      "learning_rate": 0.000471923828125,
      "loss": 18.3059,
      "step": 575
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 2.77950382232666,
      "learning_rate": 0.000470703125,
      "loss": 18.0452,
      "step": 600
    },
    {
      "epoch": 0.30517578125,
      "grad_norm": 2.7016844749450684,
      "learning_rate": 0.000469482421875,
      "loss": 17.6214,
      "step": 625
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 2.601484775543213,
      "learning_rate": 0.00046826171875000004,
      "loss": 17.2339,
      "step": 650
    },
    {
      "epoch": 0.32958984375,
      "grad_norm": 2.613133430480957,
      "learning_rate": 0.000467041015625,
      "loss": 16.7319,
      "step": 675
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 2.5732409954071045,
      "learning_rate": 0.00046582031250000003,
      "loss": 16.2381,
      "step": 700
    },
    {
      "epoch": 0.35400390625,
      "grad_norm": 2.44563364982605,
      "learning_rate": 0.000464599609375,
      "loss": 15.7039,
      "step": 725
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 2.3178844451904297,
      "learning_rate": 0.00046337890625000003,
      "loss": 15.1083,
      "step": 750
    },
    {
      "epoch": 0.37841796875,
      "grad_norm": 2.4391651153564453,
      "learning_rate": 0.000462158203125,
      "loss": 14.6158,
      "step": 775
    },
    {
      "epoch": 0.390625,
      "grad_norm": 2.3971595764160156,
      "learning_rate": 0.00046093750000000003,
      "loss": 14.0354,
      "step": 800
    },
    {
      "epoch": 0.40283203125,
      "grad_norm": 2.314319372177124,
      "learning_rate": 0.000459716796875,
      "loss": 13.4461,
      "step": 825
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 2.242135524749756,
      "learning_rate": 0.00045849609375000003,
      "loss": 12.8617,
      "step": 850
    },
    {
      "epoch": 0.42724609375,
      "grad_norm": 2.1786410808563232,
      "learning_rate": 0.000457275390625,
      "loss": 12.1883,
      "step": 875
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 2.1477489471435547,
      "learning_rate": 0.0004560546875,
      "loss": 11.623,
      "step": 900
    },
    {
      "epoch": 0.45166015625,
      "grad_norm": 2.0372612476348877,
      "learning_rate": 0.000454833984375,
      "loss": 11.1004,
      "step": 925
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 1.938842535018921,
      "learning_rate": 0.00045361328125,
      "loss": 10.5022,
      "step": 950
    },
    {
      "epoch": 0.47607421875,
      "grad_norm": 1.843306303024292,
      "learning_rate": 0.000452392578125,
      "loss": 9.9969,
      "step": 975
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 1.921451449394226,
      "learning_rate": 0.000451171875,
      "loss": 9.508,
      "step": 1000
    },
    {
      "epoch": 0.50048828125,
      "grad_norm": 1.9339933395385742,
      "learning_rate": 0.000449951171875,
      "loss": 9.0433,
      "step": 1025
    },
    {
      "epoch": 0.5126953125,
      "grad_norm": 1.8009002208709717,
      "learning_rate": 0.00044873046875,
      "loss": 8.5698,
      "step": 1050
    },
    {
      "epoch": 0.52490234375,
      "grad_norm": 1.762533187866211,
      "learning_rate": 0.000447509765625,
      "loss": 8.2155,
      "step": 1075
    },
    {
      "epoch": 0.537109375,
      "grad_norm": 1.5845860242843628,
      "learning_rate": 0.0004462890625,
      "loss": 7.913,
      "step": 1100
    },
    {
      "epoch": 0.54931640625,
      "grad_norm": 1.6266746520996094,
      "learning_rate": 0.000445068359375,
      "loss": 7.681,
      "step": 1125
    },
    {
      "epoch": 0.5615234375,
      "grad_norm": 1.689366340637207,
      "learning_rate": 0.00044384765625,
      "loss": 7.5432,
      "step": 1150
    },
    {
      "epoch": 0.57373046875,
      "grad_norm": 1.6578093767166138,
      "learning_rate": 0.000442626953125,
      "loss": 7.3482,
      "step": 1175
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 1.5965425968170166,
      "learning_rate": 0.00044140625,
      "loss": 7.247,
      "step": 1200
    },
    {
      "epoch": 0.59814453125,
      "grad_norm": 1.7554923295974731,
      "learning_rate": 0.000440185546875,
      "loss": 7.2283,
      "step": 1225
    },
    {
      "epoch": 0.6103515625,
      "grad_norm": 1.7992993593215942,
      "learning_rate": 0.00043896484375,
      "loss": 7.191,
      "step": 1250
    },
    {
      "epoch": 0.62255859375,
      "grad_norm": 1.8683816194534302,
      "learning_rate": 0.000437744140625,
      "loss": 7.2773,
      "step": 1275
    },
    {
      "epoch": 0.634765625,
      "grad_norm": 1.726030945777893,
      "learning_rate": 0.0004365234375,
      "loss": 7.2445,
      "step": 1300
    },
    {
      "epoch": 0.64697265625,
      "grad_norm": 1.815232276916504,
      "learning_rate": 0.00043530273437500003,
      "loss": 7.2089,
      "step": 1325
    },
    {
      "epoch": 0.6591796875,
      "grad_norm": 1.7655106782913208,
      "learning_rate": 0.00043408203125,
      "loss": 7.1276,
      "step": 1350
    },
    {
      "epoch": 0.67138671875,
      "grad_norm": 1.6099517345428467,
      "learning_rate": 0.00043286132812500003,
      "loss": 7.0191,
      "step": 1375
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 1.5803403854370117,
      "learning_rate": 0.000431640625,
      "loss": 6.8172,
      "step": 1400
    },
    {
      "epoch": 0.69580078125,
      "grad_norm": 1.6778866052627563,
      "learning_rate": 0.00043041992187500003,
      "loss": 6.6432,
      "step": 1425
    },
    {
      "epoch": 0.7080078125,
      "grad_norm": 1.4861059188842773,
      "learning_rate": 0.00042919921875,
      "loss": 6.4709,
      "step": 1450
    },
    {
      "epoch": 0.72021484375,
      "grad_norm": 1.4291993379592896,
      "learning_rate": 0.00042797851562500003,
      "loss": 6.35,
      "step": 1475
    },
    {
      "epoch": 0.732421875,
      "grad_norm": 1.4884625673294067,
      "learning_rate": 0.0004267578125,
      "loss": 6.1963,
      "step": 1500
    },
    {
      "epoch": 0.74462890625,
      "grad_norm": 1.5323296785354614,
      "learning_rate": 0.000425537109375,
      "loss": 6.0489,
      "step": 1525
    },
    {
      "epoch": 0.7568359375,
      "grad_norm": 1.410713791847229,
      "learning_rate": 0.00042431640625,
      "loss": 5.8898,
      "step": 1550
    },
    {
      "epoch": 0.76904296875,
      "grad_norm": 1.426456332206726,
      "learning_rate": 0.000423095703125,
      "loss": 5.7545,
      "step": 1575
    },
    {
      "epoch": 0.78125,
      "grad_norm": 1.4823347330093384,
      "learning_rate": 0.000421875,
      "loss": 5.6366,
      "step": 1600
    },
    {
      "epoch": 0.79345703125,
      "grad_norm": 1.3850840330123901,
      "learning_rate": 0.000420654296875,
      "loss": 5.5349,
      "step": 1625
    },
    {
      "epoch": 0.8056640625,
      "grad_norm": 1.464263916015625,
      "learning_rate": 0.00041943359375,
      "loss": 5.4273,
      "step": 1650
    },
    {
      "epoch": 0.81787109375,
      "grad_norm": 1.5350360870361328,
      "learning_rate": 0.000418212890625,
      "loss": 5.4347,
      "step": 1675
    },
    {
      "epoch": 0.830078125,
      "grad_norm": 1.5618149042129517,
      "learning_rate": 0.0004169921875,
      "loss": 5.3725,
      "step": 1700
    },
    {
      "epoch": 0.84228515625,
      "grad_norm": 1.4787187576293945,
      "learning_rate": 0.000415771484375,
      "loss": 5.3379,
      "step": 1725
    },
    {
      "epoch": 0.8544921875,
      "grad_norm": 1.4672054052352905,
      "learning_rate": 0.00041455078125,
      "loss": 5.2637,
      "step": 1750
    },
    {
      "epoch": 0.86669921875,
      "grad_norm": 1.3447754383087158,
      "learning_rate": 0.000413330078125,
      "loss": 5.1026,
      "step": 1775
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 1.3800005912780762,
      "learning_rate": 0.000412109375,
      "loss": 4.9934,
      "step": 1800
    },
    {
      "epoch": 0.89111328125,
      "grad_norm": 1.4059219360351562,
      "learning_rate": 0.000410888671875,
      "loss": 4.8694,
      "step": 1825
    },
    {
      "epoch": 0.9033203125,
      "grad_norm": 1.4132870435714722,
      "learning_rate": 0.00040966796875,
      "loss": 4.7721,
      "step": 1850
    },
    {
      "epoch": 0.91552734375,
      "grad_norm": 1.2335070371627808,
      "learning_rate": 0.000408447265625,
      "loss": 4.6886,
      "step": 1875
    },
    {
      "epoch": 0.927734375,
      "grad_norm": 1.4547797441482544,
      "learning_rate": 0.0004072265625,
      "loss": 4.6127,
      "step": 1900
    },
    {
      "epoch": 0.93994140625,
      "grad_norm": 1.3075995445251465,
      "learning_rate": 0.000406005859375,
      "loss": 4.5044,
      "step": 1925
    },
    {
      "epoch": 0.9521484375,
      "grad_norm": 1.3882778882980347,
      "learning_rate": 0.00040478515625000003,
      "loss": 4.46,
      "step": 1950
    },
    {
      "epoch": 0.96435546875,
      "grad_norm": 1.295457124710083,
      "learning_rate": 0.000403564453125,
      "loss": 4.4196,
      "step": 1975
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 1.2171674966812134,
      "learning_rate": 0.00040234375000000003,
      "loss": 4.3902,
      "step": 2000
    },
    {
      "epoch": 0.98876953125,
      "grad_norm": 1.3721072673797607,
      "learning_rate": 0.000401123046875,
      "loss": 4.4812,
      "step": 2025
    },
    {
      "epoch": 1.0009765625,
      "grad_norm": 1.2832496166229248,
      "learning_rate": 0.00039990234375000003,
      "loss": 4.5445,
      "step": 2050
    },
    {
      "epoch": 1.01318359375,
      "grad_norm": 1.3672022819519043,
      "learning_rate": 0.000398681640625,
      "loss": 4.4061,
      "step": 2075
    },
    {
      "epoch": 1.025390625,
      "grad_norm": 1.293253779411316,
      "learning_rate": 0.00039746093750000003,
      "loss": 4.2444,
      "step": 2100
    },
    {
      "epoch": 1.03759765625,
      "grad_norm": 1.2333214282989502,
      "learning_rate": 0.000396240234375,
      "loss": 4.0342,
      "step": 2125
    },
    {
      "epoch": 1.0498046875,
      "grad_norm": 1.259413480758667,
      "learning_rate": 0.00039501953125,
      "loss": 3.9021,
      "step": 2150
    },
    {
      "epoch": 1.06201171875,
      "grad_norm": 1.1992435455322266,
      "learning_rate": 0.000393798828125,
      "loss": 3.7516,
      "step": 2175
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 1.1766871213912964,
      "learning_rate": 0.000392578125,
      "loss": 3.6131,
      "step": 2200
    },
    {
      "epoch": 1.08642578125,
      "grad_norm": 1.1218645572662354,
      "learning_rate": 0.000391357421875,
      "loss": 3.4909,
      "step": 2225
    },
    {
      "epoch": 1.0986328125,
      "grad_norm": 1.0437967777252197,
      "learning_rate": 0.00039013671875,
      "loss": 3.3325,
      "step": 2250
    },
    {
      "epoch": 1.11083984375,
      "grad_norm": 1.0376393795013428,
      "learning_rate": 0.000388916015625,
      "loss": 3.2256,
      "step": 2275
    },
    {
      "epoch": 1.123046875,
      "grad_norm": 1.0534439086914062,
      "learning_rate": 0.0003876953125,
      "loss": 3.1242,
      "step": 2300
    },
    {
      "epoch": 1.13525390625,
      "grad_norm": 1.0040616989135742,
      "learning_rate": 0.000386474609375,
      "loss": 3.0751,
      "step": 2325
    },
    {
      "epoch": 1.1474609375,
      "grad_norm": 1.119323492050171,
      "learning_rate": 0.00038525390625,
      "loss": 3.037,
      "step": 2350
    },
    {
      "epoch": 1.15966796875,
      "grad_norm": 1.136643409729004,
      "learning_rate": 0.000384033203125,
      "loss": 3.0284,
      "step": 2375
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.9725725054740906,
      "learning_rate": 0.0003828125,
      "loss": 2.9844,
      "step": 2400
    },
    {
      "epoch": 1.18408203125,
      "grad_norm": 1.031272292137146,
      "learning_rate": 0.000381591796875,
      "loss": 2.9474,
      "step": 2425
    },
    {
      "epoch": 1.1962890625,
      "grad_norm": 0.9603325128555298,
      "learning_rate": 0.00038037109375,
      "loss": 2.923,
      "step": 2450
    },
    {
      "epoch": 1.20849609375,
      "grad_norm": 0.9582106471061707,
      "learning_rate": 0.000379150390625,
      "loss": 2.8688,
      "step": 2475
    },
    {
      "epoch": 1.220703125,
      "grad_norm": 0.9646413326263428,
      "learning_rate": 0.0003779296875,
      "loss": 2.7711,
      "step": 2500
    },
    {
      "epoch": 1.23291015625,
      "grad_norm": 0.9526754021644592,
      "learning_rate": 0.000376708984375,
      "loss": 2.7199,
      "step": 2525
    },
    {
      "epoch": 1.2451171875,
      "grad_norm": 1.002960443496704,
      "learning_rate": 0.00037548828125,
      "loss": 2.7823,
      "step": 2550
    },
    {
      "epoch": 1.25732421875,
      "grad_norm": 0.935559868812561,
      "learning_rate": 0.00037426757812500003,
      "loss": 2.821,
      "step": 2575
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.9103900194168091,
      "learning_rate": 0.000373046875,
      "loss": 2.7792,
      "step": 2600
    },
    {
      "epoch": 1.28173828125,
      "grad_norm": 0.9607958793640137,
      "learning_rate": 0.00037182617187500003,
      "loss": 2.6938,
      "step": 2625
    },
    {
      "epoch": 1.2939453125,
      "grad_norm": 0.822388231754303,
      "learning_rate": 0.00037060546875,
      "loss": 2.592,
      "step": 2650
    },
    {
      "epoch": 1.30615234375,
      "grad_norm": 0.8660368919372559,
      "learning_rate": 0.00036938476562500003,
      "loss": 2.5006,
      "step": 2675
    },
    {
      "epoch": 1.318359375,
      "grad_norm": 0.8446725010871887,
      "learning_rate": 0.0003681640625,
      "loss": 2.4222,
      "step": 2700
    },
    {
      "epoch": 1.33056640625,
      "grad_norm": 0.7576677203178406,
      "learning_rate": 0.00036694335937500003,
      "loss": 2.3379,
      "step": 2725
    },
    {
      "epoch": 1.3427734375,
      "grad_norm": 0.7930042743682861,
      "learning_rate": 0.00036572265625,
      "loss": 2.2841,
      "step": 2750
    },
    {
      "epoch": 1.35498046875,
      "grad_norm": 0.769636332988739,
      "learning_rate": 0.000364501953125,
      "loss": 2.2672,
      "step": 2775
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.7619089484214783,
      "learning_rate": 0.00036328125,
      "loss": 2.2544,
      "step": 2800
    },
    {
      "epoch": 1.37939453125,
      "grad_norm": 0.7834571003913879,
      "learning_rate": 0.000362060546875,
      "loss": 2.2877,
      "step": 2825
    },
    {
      "epoch": 1.3916015625,
      "grad_norm": 0.7240144610404968,
      "learning_rate": 0.00036083984375,
      "loss": 2.3036,
      "step": 2850
    },
    {
      "epoch": 1.40380859375,
      "grad_norm": 0.7293920516967773,
      "learning_rate": 0.000359619140625,
      "loss": 2.326,
      "step": 2875
    },
    {
      "epoch": 1.416015625,
      "grad_norm": 0.7609175443649292,
      "learning_rate": 0.0003583984375,
      "loss": 2.288,
      "step": 2900
    },
    {
      "epoch": 1.42822265625,
      "grad_norm": 0.8371946215629578,
      "learning_rate": 0.000357177734375,
      "loss": 2.2598,
      "step": 2925
    },
    {
      "epoch": 1.4404296875,
      "grad_norm": 0.7351792454719543,
      "learning_rate": 0.00035595703125,
      "loss": 2.2234,
      "step": 2950
    },
    {
      "epoch": 1.45263671875,
      "grad_norm": 0.739033043384552,
      "learning_rate": 0.000354736328125,
      "loss": 2.242,
      "step": 2975
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.7768763899803162,
      "learning_rate": 0.000353515625,
      "loss": 2.2659,
      "step": 3000
    },
    {
      "epoch": 1.47705078125,
      "grad_norm": 0.7715385556221008,
      "learning_rate": 0.000352294921875,
      "loss": 2.255,
      "step": 3025
    },
    {
      "epoch": 1.4892578125,
      "grad_norm": 0.7345869541168213,
      "learning_rate": 0.00035107421875,
      "loss": 2.2613,
      "step": 3050
    },
    {
      "epoch": 1.50146484375,
      "grad_norm": 0.6507449150085449,
      "learning_rate": 0.000349853515625,
      "loss": 2.2625,
      "step": 3075
    },
    {
      "epoch": 1.513671875,
      "grad_norm": 0.7068443298339844,
      "learning_rate": 0.0003486328125,
      "loss": 2.2445,
      "step": 3100
    },
    {
      "epoch": 1.52587890625,
      "grad_norm": 0.7169345021247864,
      "learning_rate": 0.000347412109375,
      "loss": 2.2053,
      "step": 3125
    },
    {
      "epoch": 1.5380859375,
      "grad_norm": 0.6653280258178711,
      "learning_rate": 0.00034619140625,
      "loss": 2.1586,
      "step": 3150
    },
    {
      "epoch": 1.55029296875,
      "grad_norm": 0.6813910603523254,
      "learning_rate": 0.000344970703125,
      "loss": 2.1087,
      "step": 3175
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.643806517124176,
      "learning_rate": 0.00034375,
      "loss": 2.0497,
      "step": 3200
    },
    {
      "epoch": 1.57470703125,
      "grad_norm": 0.6243625283241272,
      "learning_rate": 0.000342529296875,
      "loss": 2.0041,
      "step": 3225
    },
    {
      "epoch": 1.5869140625,
      "grad_norm": 0.5771732926368713,
      "learning_rate": 0.00034130859375000003,
      "loss": 1.9388,
      "step": 3250
    },
    {
      "epoch": 1.59912109375,
      "grad_norm": 0.6211227178573608,
      "learning_rate": 0.000340087890625,
      "loss": 1.9303,
      "step": 3275
    },
    {
      "epoch": 1.611328125,
      "grad_norm": 0.6181690096855164,
      "learning_rate": 0.00033886718750000003,
      "loss": 1.8973,
      "step": 3300
    },
    {
      "epoch": 1.62353515625,
      "grad_norm": 0.6223039627075195,
      "learning_rate": 0.000337646484375,
      "loss": 1.8676,
      "step": 3325
    },
    {
      "epoch": 1.6357421875,
      "grad_norm": 0.6741294860839844,
      "learning_rate": 0.00033642578125000003,
      "loss": 1.8807,
      "step": 3350
    },
    {
      "epoch": 1.64794921875,
      "grad_norm": 0.6701013445854187,
      "learning_rate": 0.000335205078125,
      "loss": 1.8706,
      "step": 3375
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.6452453136444092,
      "learning_rate": 0.000333984375,
      "loss": 1.875,
      "step": 3400
    },
    {
      "epoch": 1.67236328125,
      "grad_norm": 0.6429584622383118,
      "learning_rate": 0.000332763671875,
      "loss": 1.856,
      "step": 3425
    },
    {
      "epoch": 1.6845703125,
      "grad_norm": 0.6413944363594055,
      "learning_rate": 0.00033154296875,
      "loss": 1.8677,
      "step": 3450
    },
    {
      "epoch": 1.69677734375,
      "grad_norm": 0.6056715846061707,
      "learning_rate": 0.000330322265625,
      "loss": 1.8178,
      "step": 3475
    },
    {
      "epoch": 1.708984375,
      "grad_norm": 0.5945419669151306,
      "learning_rate": 0.0003291015625,
      "loss": 1.8073,
      "step": 3500
    },
    {
      "epoch": 1.72119140625,
      "grad_norm": 0.595634937286377,
      "learning_rate": 0.000327880859375,
      "loss": 1.7666,
      "step": 3525
    },
    {
      "epoch": 1.7333984375,
      "grad_norm": 0.5389770269393921,
      "learning_rate": 0.00032666015625,
      "loss": 1.7246,
      "step": 3550
    },
    {
      "epoch": 1.74560546875,
      "grad_norm": 0.5634756088256836,
      "learning_rate": 0.000325439453125,
      "loss": 1.6846,
      "step": 3575
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.5337067246437073,
      "learning_rate": 0.00032421875,
      "loss": 1.6524,
      "step": 3600
    },
    {
      "epoch": 1.77001953125,
      "grad_norm": 0.5358978509902954,
      "learning_rate": 0.000322998046875,
      "loss": 1.5977,
      "step": 3625
    },
    {
      "epoch": 1.7822265625,
      "grad_norm": 0.5148997902870178,
      "learning_rate": 0.00032177734375,
      "loss": 1.5662,
      "step": 3650
    },
    {
      "epoch": 1.79443359375,
      "grad_norm": 0.5446272492408752,
      "learning_rate": 0.000320556640625,
      "loss": 1.5426,
      "step": 3675
    },
    {
      "epoch": 1.806640625,
      "grad_norm": 0.5005388855934143,
      "learning_rate": 0.0003193359375,
      "loss": 1.5061,
      "step": 3700
    },
    {
      "epoch": 1.81884765625,
      "grad_norm": 0.5211232304573059,
      "learning_rate": 0.000318115234375,
      "loss": 1.492,
      "step": 3725
    },
    {
      "epoch": 1.8310546875,
      "grad_norm": 0.5380396842956543,
      "learning_rate": 0.00031689453125,
      "loss": 1.4694,
      "step": 3750
    },
    {
      "epoch": 1.84326171875,
      "grad_norm": 0.4760851562023163,
      "learning_rate": 0.000315673828125,
      "loss": 1.466,
      "step": 3775
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.48777949810028076,
      "learning_rate": 0.000314453125,
      "loss": 1.4774,
      "step": 3800
    },
    {
      "epoch": 1.86767578125,
      "grad_norm": 0.4817429184913635,
      "learning_rate": 0.000313232421875,
      "loss": 1.4722,
      "step": 3825
    },
    {
      "epoch": 1.8798828125,
      "grad_norm": 0.4607439637184143,
      "learning_rate": 0.00031201171875,
      "loss": 1.4258,
      "step": 3850
    },
    {
      "epoch": 1.89208984375,
      "grad_norm": 0.4842556118965149,
      "learning_rate": 0.00031079101562500003,
      "loss": 1.4144,
      "step": 3875
    },
    {
      "epoch": 1.904296875,
      "grad_norm": 0.4927111566066742,
      "learning_rate": 0.0003095703125,
      "loss": 1.4096,
      "step": 3900
    },
    {
      "epoch": 1.91650390625,
      "grad_norm": 0.504899263381958,
      "learning_rate": 0.00030834960937500003,
      "loss": 1.3922,
      "step": 3925
    },
    {
      "epoch": 1.9287109375,
      "grad_norm": 0.5029426217079163,
      "learning_rate": 0.00030712890625,
      "loss": 1.395,
      "step": 3950
    },
    {
      "epoch": 1.94091796875,
      "grad_norm": 0.4711444675922394,
      "learning_rate": 0.00030590820312500003,
      "loss": 1.3901,
      "step": 3975
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.47403484582901,
      "learning_rate": 0.0003046875,
      "loss": 1.3892,
      "step": 4000
    }
  ],
  "logging_steps": 25,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
