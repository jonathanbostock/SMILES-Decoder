{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.48828125,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01220703125,
      "grad_norm": 1.3326678276062012,
      "learning_rate": 0.000498779296875,
      "loss": 38.361,
      "step": 25
    },
    {
      "epoch": 0.0244140625,
      "grad_norm": 0.5136749148368835,
      "learning_rate": 0.0004975585937500001,
      "loss": 4.998,
      "step": 50
    },
    {
      "epoch": 0.03662109375,
      "grad_norm": 0.8903566002845764,
      "learning_rate": 0.000496337890625,
      "loss": 5.3903,
      "step": 75
    },
    {
      "epoch": 0.048828125,
      "grad_norm": 1.1837118864059448,
      "learning_rate": 0.0004951171875,
      "loss": 8.5075,
      "step": 100
    },
    {
      "epoch": 0.06103515625,
      "grad_norm": 1.457871913909912,
      "learning_rate": 0.000493896484375,
      "loss": 10.4259,
      "step": 125
    },
    {
      "epoch": 0.0732421875,
      "grad_norm": 1.6656646728515625,
      "learning_rate": 0.0004926757812500001,
      "loss": 11.7846,
      "step": 150
    },
    {
      "epoch": 0.08544921875,
      "grad_norm": 1.7859668731689453,
      "learning_rate": 0.000491455078125,
      "loss": 13.1132,
      "step": 175
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 2.127591133117676,
      "learning_rate": 0.000490234375,
      "loss": 14.2343,
      "step": 200
    },
    {
      "epoch": 0.10986328125,
      "grad_norm": 2.1554505825042725,
      "learning_rate": 0.000489013671875,
      "loss": 15.1889,
      "step": 225
    },
    {
      "epoch": 0.1220703125,
      "grad_norm": 2.2897493839263916,
      "learning_rate": 0.00048779296875,
      "loss": 16.034,
      "step": 250
    },
    {
      "epoch": 0.13427734375,
      "grad_norm": 2.413649320602417,
      "learning_rate": 0.000486572265625,
      "loss": 16.7147,
      "step": 275
    },
    {
      "epoch": 0.146484375,
      "grad_norm": 2.4778943061828613,
      "learning_rate": 0.0004853515625,
      "loss": 17.3756,
      "step": 300
    },
    {
      "epoch": 0.15869140625,
      "grad_norm": 2.5457561016082764,
      "learning_rate": 0.000484130859375,
      "loss": 17.86,
      "step": 325
    },
    {
      "epoch": 0.1708984375,
      "grad_norm": 2.7168874740600586,
      "learning_rate": 0.00048291015625,
      "loss": 18.2123,
      "step": 350
    },
    {
      "epoch": 0.18310546875,
      "grad_norm": 2.7220711708068848,
      "learning_rate": 0.000481689453125,
      "loss": 18.6073,
      "step": 375
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 2.793246030807495,
      "learning_rate": 0.00048046875,
      "loss": 18.8434,
      "step": 400
    },
    {
      "epoch": 0.20751953125,
      "grad_norm": 2.8063738346099854,
      "learning_rate": 0.000479248046875,
      "loss": 18.9409,
      "step": 425
    },
    {
      "epoch": 0.2197265625,
      "grad_norm": 2.932191848754883,
      "learning_rate": 0.00047802734375,
      "loss": 19.0882,
      "step": 450
    },
    {
      "epoch": 0.23193359375,
      "grad_norm": 2.891045570373535,
      "learning_rate": 0.000476806640625,
      "loss": 18.9871,
      "step": 475
    },
    {
      "epoch": 0.244140625,
      "grad_norm": 2.7938005924224854,
      "learning_rate": 0.0004755859375,
      "loss": 18.9607,
      "step": 500
    },
    {
      "epoch": 0.25634765625,
      "grad_norm": 2.7559051513671875,
      "learning_rate": 0.000474365234375,
      "loss": 18.8081,
      "step": 525
    },
    {
      "epoch": 0.2685546875,
      "grad_norm": 2.8782355785369873,
      "learning_rate": 0.00047314453125,
      "loss": 18.5983,
      "step": 550
    },
    {
      "epoch": 0.28076171875,
      "grad_norm": 2.785182237625122,
      "learning_rate": 0.000471923828125,
      "loss": 18.3059,
      "step": 575
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 2.77950382232666,
      "learning_rate": 0.000470703125,
      "loss": 18.0452,
      "step": 600
    },
    {
      "epoch": 0.30517578125,
      "grad_norm": 2.7016844749450684,
      "learning_rate": 0.000469482421875,
      "loss": 17.6214,
      "step": 625
    },
    {
      "epoch": 0.3173828125,
      "grad_norm": 2.601484775543213,
      "learning_rate": 0.00046826171875000004,
      "loss": 17.2339,
      "step": 650
    },
    {
      "epoch": 0.32958984375,
      "grad_norm": 2.613133430480957,
      "learning_rate": 0.000467041015625,
      "loss": 16.7319,
      "step": 675
    },
    {
      "epoch": 0.341796875,
      "grad_norm": 2.5732409954071045,
      "learning_rate": 0.00046582031250000003,
      "loss": 16.2381,
      "step": 700
    },
    {
      "epoch": 0.35400390625,
      "grad_norm": 2.44563364982605,
      "learning_rate": 0.000464599609375,
      "loss": 15.7039,
      "step": 725
    },
    {
      "epoch": 0.3662109375,
      "grad_norm": 2.3178844451904297,
      "learning_rate": 0.00046337890625000003,
      "loss": 15.1083,
      "step": 750
    },
    {
      "epoch": 0.37841796875,
      "grad_norm": 2.4391651153564453,
      "learning_rate": 0.000462158203125,
      "loss": 14.6158,
      "step": 775
    },
    {
      "epoch": 0.390625,
      "grad_norm": 2.3971595764160156,
      "learning_rate": 0.00046093750000000003,
      "loss": 14.0354,
      "step": 800
    },
    {
      "epoch": 0.40283203125,
      "grad_norm": 2.314319372177124,
      "learning_rate": 0.000459716796875,
      "loss": 13.4461,
      "step": 825
    },
    {
      "epoch": 0.4150390625,
      "grad_norm": 2.242135524749756,
      "learning_rate": 0.00045849609375000003,
      "loss": 12.8617,
      "step": 850
    },
    {
      "epoch": 0.42724609375,
      "grad_norm": 2.1786410808563232,
      "learning_rate": 0.000457275390625,
      "loss": 12.1883,
      "step": 875
    },
    {
      "epoch": 0.439453125,
      "grad_norm": 2.1477489471435547,
      "learning_rate": 0.0004560546875,
      "loss": 11.623,
      "step": 900
    },
    {
      "epoch": 0.45166015625,
      "grad_norm": 2.0372612476348877,
      "learning_rate": 0.000454833984375,
      "loss": 11.1004,
      "step": 925
    },
    {
      "epoch": 0.4638671875,
      "grad_norm": 1.938842535018921,
      "learning_rate": 0.00045361328125,
      "loss": 10.5022,
      "step": 950
    },
    {
      "epoch": 0.47607421875,
      "grad_norm": 1.843306303024292,
      "learning_rate": 0.000452392578125,
      "loss": 9.9969,
      "step": 975
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 1.921451449394226,
      "learning_rate": 0.000451171875,
      "loss": 9.508,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 10240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
